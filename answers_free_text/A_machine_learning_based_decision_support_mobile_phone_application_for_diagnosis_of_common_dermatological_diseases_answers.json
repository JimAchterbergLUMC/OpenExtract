{
  "paper": "A machine learning-based, decision support, mobile phone application for diagnosis of common dermatological diseases.pdf",
  "answers": [
    {
      "id": "Q1",
      "question": "Is the aim of this study to predict future events (prognostic) or current disease status (diagnostic)?",
      "answer": "Diagnostic",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        9,
        2,
        16
      ],
      "chunks_str": [
        " to calculate the true positive rate (same as\nsensitivity) and the false-positive rate (1 – speciﬁcity). ROC\ncurve was the plot of the true positive rate versus the false-\npositive rate.\nClinical validation study\nWe tested our mobile app against dermatologists’ diagnosis in\nthree different clinical settings, namely, at a tertiary care centre\nData \ncollection\nAlgorithm \nfinetuning & \nvalidation\nApp \ndevelopment\nClinical \nvalidation of \nApp\nPublic database of annotated images for \n40 skin diseases + normal skin + nonspecific\nN = 9,203\nPrivate data classified by board certified \ndermatologists\nN = 8,205\nCNN training images N =12,350\nCNN testing images N =3,068\n(1990 nonspecific images not included)\nComparison of model diagnosis against \npredetermined classification\n15,418 images used for training of model to \ngenerate smartphone app\nApp tested by physicians and compared with \ndermatologists’ diagnosis. N = 5,014 \nDetermination of app’s overall sensitivity and \ndisease-specific sensitivity, specificity, PPV, \nNPV and AUC values\nApp testing on rural primary-care patients\nN = 932\nApp testing on urban, private clinic patients\nN = 383\nApp testing on urban tertiary hospital patients\nN = 3,699\nFigure 1 This ﬂowchart depicts the different steps in data collection, algorithm generation, algorithm testing, app generation and app\nvalidation in clinical studies.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 539\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosaceaMelasma\nAcne\nVitiligo/Leucoderma\nTinea pedis\nAnogenital wartsKeratoacanthoma\nMolluscum contagiosumHidradenitis suppurativa\nHerpes zosterTinea capitis\nImpetigo and Pyodermas\nAlopecia\nMilia\nBasal cell carcinoma\nMelanoma\nMelanocytic nevi/Mole\nIchthyosis\nPityriasis r\nosea\nActin\nic keratosis\nTinea cruris  corporis or faciei\nKeloid/Hype\nrtrophic scar\nSeborrheic\n keratosis\nFixed d\nrug eruption\nLichen sclerosus et atrophicus\nCh\nicken pox\nTinea ma\nnuum\nLichen planus\nUrticaria\nPityriasis ve\nrsicolorPsoriasis\nPe\nmphigus\nCandid\niasis\nBowens disease\nViral warts\nSquamous cell c\narcino\nma\nBullous pe\nmphigoidEcze\nma\nDis\ncoid lupus erythematosus\nPercentage\nSensitivity\nSpecificity\nPPV\nNPV\nSensitivity and specificity of five fold validation data(a)\n(b)\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosacea\nKeloid/Hypertrophic scar\nFixed drug eruption\nHerpes zoster\nVitiligo/Leucoderma\nIchthyosis\nHidradenitis suppurativa\nMelasma\nKeratoacanthoma\n",
        " validation studies of AI-\nbased algorithms related to dermatology in clinical settings.\nMaterial and methods\nThe study aimed to develop a convolutional neural network\n(CNN)-based algorithm trained with clinical images of 40 differ-\nent skin diseases. A user-friendly, smartphone app was also gen-\nerated, and a clinical validation study on 5014 patients was done\nby physicians in urban, rural primary care and tertiary care set-\ntings. The app’s analysis of a single image of the lesion was com-\npared to the consensus diagnosis made by two board-certiﬁed\ndermatologists. Only patients, for whom the treating board-cer-\ntiﬁed dermatologist was conﬁdent of the diagnosis and the diag-\nnosis was cross-veriﬁed by another board-certiﬁed\ndermatologist, were included. If there was no consensus then the\npatient was excluded from the study.\nGeneration of the CNN-based algorithm\nThe CNN architecture used was a modiﬁed version of Densenet-\n161 with optimized augmentation and inference pipelines.\n16\nThese optimizations were derived through rigorous experiments\nand were attuned to clinical skin images. All training and testing\nimages were annotated and segmented so a bounding box sur-\nrounded lesion of interest and irrelevant features such as rulers\nand surgical markings were discarded. The 17 718 raw images\nwere sourced from public databases (http://www.hellenicderma\ntlas.com/en and http://www.danderm.dk/atlas), after obtaining\npermission from them, as well as images from dermatologists in\nIndia. Of these, 310 images were discarded during the\npreprocessing stage due to poor resolution or multiple lesions.\nOut of the remaining 17 408 images, 1990 images belonged to\nthe non-speciﬁc category and 15 418 images were within the 40\nselected disease categories (Table 1). These images were split\ninto ﬁve equal parts (folds) and ﬁve iterations of training and\nvalidation were performed in a manner so that within each itera-\ntion, a different fold of the data was held-out for validation while\nthe remaining fourfolds were used for learning. The training\nimages were 12 350 and testing images were 3068. Since the\ndataset was imbalanced, a custom modiﬁed version of the\nweighted focal loss function was used to train the network. The\nweights for each class were calculated using the inverse sample\nsize method. Our test images were either in-distribution images\ni.e. images within 40 training classes or out-of-distribution sets\nthat we named as non-speciﬁc set.\nWe initially used Inception-v4, which was one of the most\npopular CNN models at the time. For 10 diseases, a sensitivity of\naround 85% was achieved, but for the 20-disease class model,\nthis fell to around 65%. We experimented with many parameters\nlike learning rate and choice of optimizer etc. with no signiﬁcant\nimprovements. It was felt that as the architectures became dee-\nper, there could be problems related to over-ﬁtting. According\nto Huanget al.,convolutional networks can be substantially dee-\nper, more accurate and efﬁcient to train if they contain shorter\nconnections between layers close to the input and those close to\nthe output.\n17 Their implementation of this architecture is called\nDenseNet. In this architecture, to ensure maximum information\nﬂow between layers, each layer obtains additional inputs from all\npreceding layers and passes on its own feature-maps to all subse-\nquent layers.\n17 We found that the DenseNet architecture pro-\nvided better results than the other contemporary architectures\nsuch as Inception-Resnet-V2, Resnets-50, Resnet-101 and Res-\nnet-152. We tried several DenseNet variants",
        "/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nFigure 4 (a) Confusion matrix from the top-1 prediction of clinical data by the app. The numbers in each row are normalized to 100. The\nactual patient numbers for each disease class are shown in parenthesis. The actual labels are depicted on the y-axis and predicted labels\nare on the x-axis. (b) Confusion matrix from the top-3 prediction of clinical data by the app. The numbers in each row are normalized to\n100. The actual patient numbers for each disease class are shown in parenthesis.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 543\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nto diagnose 26 common skin conditions from clinical images\nplus associated medical histories.25 During validation, Liuet al\nachieved a 71% top-1 accuracy and their algorithm surpassed\ndermatologists, PCPs and nurse practitioners in a clinical data-\nset.\n25 Our Top-1 accuracy was 77% and the mean AUC was 0.95\nfor algorithmic validation of 40 diseases.\nThere are no precedents for studies in which an AI-based, skin\ndisease diagnosis app has been tested in clinical settings. In our\nwork, a top-1 accuracy of 75% and a top-3 accuracy of 90% was\nachieved by the app for 35 skin diseases and was largely similar to\nour model validation results. Some differences in diagnostic per-\nformance (in terms of disease AUCs) between model and app\nwere noted and may be attributable to either fewer clinical valida-\ntion images for some diseases like Bowen’s disease, anogenital\nwarts, tinea pedis, rosacea, candidiasis, herpes zoster (Fig. 4a and\nSupplementary Figure S1) and/or differences in disease morphol-\nogy between white and pigmented skin. Eczema is a broad disease\ncategory, incorporating diseases with varied morphology such as\nlichen simplex chronicus, atopic dermatitis, nummular eczema\nand contact dermatitis. Training of the model with speciﬁc dis-\nease classes rather than a broad category of eczema may improve\nsensitivity. As shown in the confusion matrix, eczema was often\nconfused with psoriasis, lichen planus and tinea corporis, cruris\nor faciei (Figs 4a, b). To some extent, this mirrors the diagnostic\nconfusion faced by many physicians as well.\n2,25,26 A few melano-\ncytic nevi lesions were mistaken for BCC possibly because of their\nresemblance with pigmented BCC, which is more commonly seen\nin skin of colour. Besides, it was observed that diseases with dis-\ntinct morphology and predilection for certain sites (in a similar\nrecognizable background) such as melasma and tinea unguium\nhad better accuracies.\nIn this study, we found a high top-3 sensitivity for BCC\n(97.58%, n = 124) and SCC (92.86%,n = 14"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2563
    },
    {
      "id": "Q2",
      "question": "On what basis were eligible participants included in this study (symptoms, previous tests, registry, etc.)?",
      "answer": "Consecutive patients with confident dermatologist diagnosis.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        11,
        16,
        18
      ],
      "chunks_str": [
        " diversity in the patient populations that\nconsult physicians in urban versus rural areas. The study was\napproved by the Ethics Committee of All India Institute of Med-\nical Sciences. We included consecutive patients presenting to a\nparticular investigator in the Outpatient Department, where the\ndermatologists were conﬁdent of the diagnosis, either by clinical\nexamination, laboratory investigation, and/or histopathological\nexamination. Dermatologists were blinded to the app results. A\nsingle representative image from each patient was tested on the\napp by a separate physician.\nResults\nThe overall scheme for this study is outlined in Figure 1.\nTable 2 shows th number of patients, AUC, Top‐1/Top‐3 sensitivity, speciﬁcity, positive predictive and negative predictive values for\ncombined clinical data from three different clinical settings.\nS.no. Disease class Number\nof patients\nAUC-\nclinic\nTop-1 sensitivity\n% (CI)\nTop-3\nsensitivity %\nTop-1\nspeciﬁcity %\nTop-1 PPV Top-1 NPV\n1 Acne 592 0.98 89.86 (87.15 –92.18) 97.97 98.19 86.92 98.64\n2 Alopecia 184 0.97 88.11 (82.55 –92.36) 96.22 99.28 82.32 99.54\n3 Anogenital warts 34 0.85 57.14 (39.35 –73.68) 71.43 99.70 57.14 99.70\n4 Basal cell carcinoma 123 0.98 93.55 (87.68 –97.17) 97.58 98.51 61.38 99.83\n5 Bowen ’s disease 11 0.77 45.45 (16.75 –76.62) 54.54 99.90 50.00 99.88\n6 Bullous pemphigoid 16 0.73 35.29 (14.21 –61.67) 47.06 100.00 100.00 99.78\n7 Candidiasis 16 0.81 41.18 (18.44 –67.10) 64.71 99.80 41.18 99.80\n8 Discoid lupus\nerythematosus\n47 0.90 60.42 (45.27 –74.23) 83.33 99.20 42.03 99.61\n9 Eczema 432 0.87 54.29 (49.46 –59.10) 81.90 97.58 67.83 95.78\n10 Fixed drug eruption 12 0.87 41.67 (15.16 –72.33) 75.00 99.70 25.00 99.86\n11 Herpes zoster 38 0.89 66.67 (49.78 –80.91) 79.49 99.60 56.52 99.74\n12 Hidradenitis suppurativa 32 0.97 93.94(79.78 –99.26) 93.94 99.62 62.00 99.96\n13 Ichthyosis 21 0.93 81.81 (59.72 –94.81) 86.36 99.78 62.07 99.92\n14 Impetigo and Pyodermas 109 0.89 57.27 (47.48 –66.66) 82.72 99.04 57.27 99.04\n15",
        "/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nFigure 4 (a) Confusion matrix from the top-1 prediction of clinical data by the app. The numbers in each row are normalized to 100. The\nactual patient numbers for each disease class are shown in parenthesis. The actual labels are depicted on the y-axis and predicted labels\nare on the x-axis. (b) Confusion matrix from the top-3 prediction of clinical data by the app. The numbers in each row are normalized to\n100. The actual patient numbers for each disease class are shown in parenthesis.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 543\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nto diagnose 26 common skin conditions from clinical images\nplus associated medical histories.25 During validation, Liuet al\nachieved a 71% top-1 accuracy and their algorithm surpassed\ndermatologists, PCPs and nurse practitioners in a clinical data-\nset.\n25 Our Top-1 accuracy was 77% and the mean AUC was 0.95\nfor algorithmic validation of 40 diseases.\nThere are no precedents for studies in which an AI-based, skin\ndisease diagnosis app has been tested in clinical settings. In our\nwork, a top-1 accuracy of 75% and a top-3 accuracy of 90% was\nachieved by the app for 35 skin diseases and was largely similar to\nour model validation results. Some differences in diagnostic per-\nformance (in terms of disease AUCs) between model and app\nwere noted and may be attributable to either fewer clinical valida-\ntion images for some diseases like Bowen’s disease, anogenital\nwarts, tinea pedis, rosacea, candidiasis, herpes zoster (Fig. 4a and\nSupplementary Figure S1) and/or differences in disease morphol-\nogy between white and pigmented skin. Eczema is a broad disease\ncategory, incorporating diseases with varied morphology such as\nlichen simplex chronicus, atopic dermatitis, nummular eczema\nand contact dermatitis. Training of the model with speciﬁc dis-\nease classes rather than a broad category of eczema may improve\nsensitivity. As shown in the confusion matrix, eczema was often\nconfused with psoriasis, lichen planus and tinea corporis, cruris\nor faciei (Figs 4a, b). To some extent, this mirrors the diagnostic\nconfusion faced by many physicians as well.\n2,25,26 A few melano-\ncytic nevi lesions were mistaken for BCC possibly because of their\nresemblance with pigmented BCC, which is more commonly seen\nin skin of colour. Besides, it was observed that diseases with dis-\ntinct morphology and predilection for certain sites (in a similar\nrecognizable background) such as melasma and tinea unguium\nhad better accuracies.\nIn this study, we found a high top-3 sensitivity for BCC\n(97.58%, n = 124) and SCC (92.86%,n = 14",
        " the reuse of the same\npublic datasets from white-skinned individuals for training, eval-\nuating or comparing models in nearly all studies.\n30 Therefore,\nwe used several thousand new patient images for training and all\ndistinct images for validation. To enable our app to make deci-\nsions on clinically relevant features, we also trained our model\non images of normal skin from individuals as a control.\nOne limitation of this study was the absence of integration of\nmedical history with image analysis by the app. The dermatolo-\ngists had the advantage of having access to relevant additional\ninformation as they had a face-to-face interaction with the\npatient, making it easier for them to arrive at a diagnosis. A few\nimportant relevant points in the analysis, such as the duration of\nthe lesion, sites(s) involved, symptoms, and evolution of the\nlesions can improve the accuracy. The image analysis does not\ntake into consideration the distribution of skin lesions, which is\nas important a clue for the diagnosis of certain diseases as is the\nmorphology. For example, pityriasis rosea and herpes zoster\nhave a patterned distribution. Future versions of such apps need\nto reﬁne the image-based diagnosis with automated analyses of\npatient metadata.\nIn conclusion, this is the ﬁrst study where an app designed to\ndetect 40 dermatological diseases was tested in actual clinical set-\ntings on patients with skin of colour. Our data suggest that the\nAI-driven app has high diagnostic accuracy compared to a der-\nmatologist, and is, therefore, a useful, point-of-care, clinical\ndecision support tool for dermatological diagnosis for a range of\ncommon skin conditions.\nReferences\n1 Hollestein LM, Nijsten T. An insight into the global burden of skin dis-\neases. J Invest Dermatol2014; 134: 1499–1501.\n2 Karimkhani C, Dellavalle RP, Coffeng LEet al. Global skin disease mor-\nbidity and mortality: an update from the global burden of disease study\n2013. JAMA Dermatol2017; 153: 406–412.\n3 Skin diseases to grow in India by 2015: Report, May 2014. (https://www.b\niospectrumindia.com/news/73/8437/skin-diseases-to-grow-in-india-by-\n2015-report.html)Accessed on April 10, 2020.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\n544 Pangti et al.\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\n4 Yoo JY, Rigel DS. Trends in dermatology: geographic density of US der-\nmatologists. Arch Dermatol2010; 146: 779.\n5 Ehrlich A, Kostecki J, Olkaba H. Trends in dermatology practices and the\nimplications for the workforce.J Am Acad Dermatol2017; 77: 746–752.\n6 Lim HW, Collins SAB, Resneck JS, Jret al. The burden of skin disease in\nthe United States.J Am Acad Dermatol2017; 76: 958–972.e2.\n7 Patro BK, Tripathy JP, De D, Sinha S, Singh A, Kanwar AJ. Diagnostic\nagreement between a primary care physician and a teledermatologist for\ncommon dermatological conditions in North India."
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2566
    },
    {
      "id": "Q3",
      "question": "How were participants sampled in this study: by convenience, randomly, or consecutively?",
      "answer": "Consecutively.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        11,
        16,
        9
      ],
      "chunks_str": [
        " diversity in the patient populations that\nconsult physicians in urban versus rural areas. The study was\napproved by the Ethics Committee of All India Institute of Med-\nical Sciences. We included consecutive patients presenting to a\nparticular investigator in the Outpatient Department, where the\ndermatologists were conﬁdent of the diagnosis, either by clinical\nexamination, laboratory investigation, and/or histopathological\nexamination. Dermatologists were blinded to the app results. A\nsingle representative image from each patient was tested on the\napp by a separate physician.\nResults\nThe overall scheme for this study is outlined in Figure 1.\nTable 2 shows th number of patients, AUC, Top‐1/Top‐3 sensitivity, speciﬁcity, positive predictive and negative predictive values for\ncombined clinical data from three different clinical settings.\nS.no. Disease class Number\nof patients\nAUC-\nclinic\nTop-1 sensitivity\n% (CI)\nTop-3\nsensitivity %\nTop-1\nspeciﬁcity %\nTop-1 PPV Top-1 NPV\n1 Acne 592 0.98 89.86 (87.15 –92.18) 97.97 98.19 86.92 98.64\n2 Alopecia 184 0.97 88.11 (82.55 –92.36) 96.22 99.28 82.32 99.54\n3 Anogenital warts 34 0.85 57.14 (39.35 –73.68) 71.43 99.70 57.14 99.70\n4 Basal cell carcinoma 123 0.98 93.55 (87.68 –97.17) 97.58 98.51 61.38 99.83\n5 Bowen ’s disease 11 0.77 45.45 (16.75 –76.62) 54.54 99.90 50.00 99.88\n6 Bullous pemphigoid 16 0.73 35.29 (14.21 –61.67) 47.06 100.00 100.00 99.78\n7 Candidiasis 16 0.81 41.18 (18.44 –67.10) 64.71 99.80 41.18 99.80\n8 Discoid lupus\nerythematosus\n47 0.90 60.42 (45.27 –74.23) 83.33 99.20 42.03 99.61\n9 Eczema 432 0.87 54.29 (49.46 –59.10) 81.90 97.58 67.83 95.78\n10 Fixed drug eruption 12 0.87 41.67 (15.16 –72.33) 75.00 99.70 25.00 99.86\n11 Herpes zoster 38 0.89 66.67 (49.78 –80.91) 79.49 99.60 56.52 99.74\n12 Hidradenitis suppurativa 32 0.97 93.94(79.78 –99.26) 93.94 99.62 62.00 99.96\n13 Ichthyosis 21 0.93 81.81 (59.72 –94.81) 86.36 99.78 62.07 99.92\n14 Impetigo and Pyodermas 109 0.89 57.27 (47.48 –66.66) 82.72 99.04 57.27 99.04\n15",
        "/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nFigure 4 (a) Confusion matrix from the top-1 prediction of clinical data by the app. The numbers in each row are normalized to 100. The\nactual patient numbers for each disease class are shown in parenthesis. The actual labels are depicted on the y-axis and predicted labels\nare on the x-axis. (b) Confusion matrix from the top-3 prediction of clinical data by the app. The numbers in each row are normalized to\n100. The actual patient numbers for each disease class are shown in parenthesis.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 543\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nto diagnose 26 common skin conditions from clinical images\nplus associated medical histories.25 During validation, Liuet al\nachieved a 71% top-1 accuracy and their algorithm surpassed\ndermatologists, PCPs and nurse practitioners in a clinical data-\nset.\n25 Our Top-1 accuracy was 77% and the mean AUC was 0.95\nfor algorithmic validation of 40 diseases.\nThere are no precedents for studies in which an AI-based, skin\ndisease diagnosis app has been tested in clinical settings. In our\nwork, a top-1 accuracy of 75% and a top-3 accuracy of 90% was\nachieved by the app for 35 skin diseases and was largely similar to\nour model validation results. Some differences in diagnostic per-\nformance (in terms of disease AUCs) between model and app\nwere noted and may be attributable to either fewer clinical valida-\ntion images for some diseases like Bowen’s disease, anogenital\nwarts, tinea pedis, rosacea, candidiasis, herpes zoster (Fig. 4a and\nSupplementary Figure S1) and/or differences in disease morphol-\nogy between white and pigmented skin. Eczema is a broad disease\ncategory, incorporating diseases with varied morphology such as\nlichen simplex chronicus, atopic dermatitis, nummular eczema\nand contact dermatitis. Training of the model with speciﬁc dis-\nease classes rather than a broad category of eczema may improve\nsensitivity. As shown in the confusion matrix, eczema was often\nconfused with psoriasis, lichen planus and tinea corporis, cruris\nor faciei (Figs 4a, b). To some extent, this mirrors the diagnostic\nconfusion faced by many physicians as well.\n2,25,26 A few melano-\ncytic nevi lesions were mistaken for BCC possibly because of their\nresemblance with pigmented BCC, which is more commonly seen\nin skin of colour. Besides, it was observed that diseases with dis-\ntinct morphology and predilection for certain sites (in a similar\nrecognizable background) such as melasma and tinea unguium\nhad better accuracies.\nIn this study, we found a high top-3 sensitivity for BCC\n(97.58%, n = 124) and SCC (92.86%,n = 14",
        " to calculate the true positive rate (same as\nsensitivity) and the false-positive rate (1 – speciﬁcity). ROC\ncurve was the plot of the true positive rate versus the false-\npositive rate.\nClinical validation study\nWe tested our mobile app against dermatologists’ diagnosis in\nthree different clinical settings, namely, at a tertiary care centre\nData \ncollection\nAlgorithm \nfinetuning & \nvalidation\nApp \ndevelopment\nClinical \nvalidation of \nApp\nPublic database of annotated images for \n40 skin diseases + normal skin + nonspecific\nN = 9,203\nPrivate data classified by board certified \ndermatologists\nN = 8,205\nCNN training images N =12,350\nCNN testing images N =3,068\n(1990 nonspecific images not included)\nComparison of model diagnosis against \npredetermined classification\n15,418 images used for training of model to \ngenerate smartphone app\nApp tested by physicians and compared with \ndermatologists’ diagnosis. N = 5,014 \nDetermination of app’s overall sensitivity and \ndisease-specific sensitivity, specificity, PPV, \nNPV and AUC values\nApp testing on rural primary-care patients\nN = 932\nApp testing on urban, private clinic patients\nN = 383\nApp testing on urban tertiary hospital patients\nN = 3,699\nFigure 1 This ﬂowchart depicts the different steps in data collection, algorithm generation, algorithm testing, app generation and app\nvalidation in clinical studies.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 539\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosaceaMelasma\nAcne\nVitiligo/Leucoderma\nTinea pedis\nAnogenital wartsKeratoacanthoma\nMolluscum contagiosumHidradenitis suppurativa\nHerpes zosterTinea capitis\nImpetigo and Pyodermas\nAlopecia\nMilia\nBasal cell carcinoma\nMelanoma\nMelanocytic nevi/Mole\nIchthyosis\nPityriasis r\nosea\nActin\nic keratosis\nTinea cruris  corporis or faciei\nKeloid/Hype\nrtrophic scar\nSeborrheic\n keratosis\nFixed d\nrug eruption\nLichen sclerosus et atrophicus\nCh\nicken pox\nTinea ma\nnuum\nLichen planus\nUrticaria\nPityriasis ve\nrsicolorPsoriasis\nPe\nmphigus\nCandid\niasis\nBowens disease\nViral warts\nSquamous cell c\narcino\nma\nBullous pe\nmphigoidEcze\nma\nDis\ncoid lupus erythematosus\nPercentage\nSensitivity\nSpecificity\nPPV\nNPV\nSensitivity and specificity of five fold validation data(a)\n(b)\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosacea\nKeloid/Hypertrophic scar\nFixed drug eruption\nHerpes zoster\nVitiligo/Leucoderma\nIchthyosis\nHidradenitis suppurativa\nMelasma\nKeratoacanthoma\n"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2549
    },
    {
      "id": "Q4",
      "question": "How was the dataset described in this study before predictive modeling was performed?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        14,
        16,
        11
      ],
      "chunks_str": [
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,",
        "/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nFigure 4 (a) Confusion matrix from the top-1 prediction of clinical data by the app. The numbers in each row are normalized to 100. The\nactual patient numbers for each disease class are shown in parenthesis. The actual labels are depicted on the y-axis and predicted labels\nare on the x-axis. (b) Confusion matrix from the top-3 prediction of clinical data by the app. The numbers in each row are normalized to\n100. The actual patient numbers for each disease class are shown in parenthesis.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 543\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nto diagnose 26 common skin conditions from clinical images\nplus associated medical histories.25 During validation, Liuet al\nachieved a 71% top-1 accuracy and their algorithm surpassed\ndermatologists, PCPs and nurse practitioners in a clinical data-\nset.\n25 Our Top-1 accuracy was 77% and the mean AUC was 0.95\nfor algorithmic validation of 40 diseases.\nThere are no precedents for studies in which an AI-based, skin\ndisease diagnosis app has been tested in clinical settings. In our\nwork, a top-1 accuracy of 75% and a top-3 accuracy of 90% was\nachieved by the app for 35 skin diseases and was largely similar to\nour model validation results. Some differences in diagnostic per-\nformance (in terms of disease AUCs) between model and app\nwere noted and may be attributable to either fewer clinical valida-\ntion images for some diseases like Bowen’s disease, anogenital\nwarts, tinea pedis, rosacea, candidiasis, herpes zoster (Fig. 4a and\nSupplementary Figure S1) and/or differences in disease morphol-\nogy between white and pigmented skin. Eczema is a broad disease\ncategory, incorporating diseases with varied morphology such as\nlichen simplex chronicus, atopic dermatitis, nummular eczema\nand contact dermatitis. Training of the model with speciﬁc dis-\nease classes rather than a broad category of eczema may improve\nsensitivity. As shown in the confusion matrix, eczema was often\nconfused with psoriasis, lichen planus and tinea corporis, cruris\nor faciei (Figs 4a, b). To some extent, this mirrors the diagnostic\nconfusion faced by many physicians as well.\n2,25,26 A few melano-\ncytic nevi lesions were mistaken for BCC possibly because of their\nresemblance with pigmented BCC, which is more commonly seen\nin skin of colour. Besides, it was observed that diseases with dis-\ntinct morphology and predilection for certain sites (in a similar\nrecognizable background) such as melasma and tinea unguium\nhad better accuracies.\nIn this study, we found a high top-3 sensitivity for BCC\n(97.58%, n = 124) and SCC (92.86%,n = 14",
        " diversity in the patient populations that\nconsult physicians in urban versus rural areas. The study was\napproved by the Ethics Committee of All India Institute of Med-\nical Sciences. We included consecutive patients presenting to a\nparticular investigator in the Outpatient Department, where the\ndermatologists were conﬁdent of the diagnosis, either by clinical\nexamination, laboratory investigation, and/or histopathological\nexamination. Dermatologists were blinded to the app results. A\nsingle representative image from each patient was tested on the\napp by a separate physician.\nResults\nThe overall scheme for this study is outlined in Figure 1.\nTable 2 shows th number of patients, AUC, Top‐1/Top‐3 sensitivity, speciﬁcity, positive predictive and negative predictive values for\ncombined clinical data from three different clinical settings.\nS.no. Disease class Number\nof patients\nAUC-\nclinic\nTop-1 sensitivity\n% (CI)\nTop-3\nsensitivity %\nTop-1\nspeciﬁcity %\nTop-1 PPV Top-1 NPV\n1 Acne 592 0.98 89.86 (87.15 –92.18) 97.97 98.19 86.92 98.64\n2 Alopecia 184 0.97 88.11 (82.55 –92.36) 96.22 99.28 82.32 99.54\n3 Anogenital warts 34 0.85 57.14 (39.35 –73.68) 71.43 99.70 57.14 99.70\n4 Basal cell carcinoma 123 0.98 93.55 (87.68 –97.17) 97.58 98.51 61.38 99.83\n5 Bowen ’s disease 11 0.77 45.45 (16.75 –76.62) 54.54 99.90 50.00 99.88\n6 Bullous pemphigoid 16 0.73 35.29 (14.21 –61.67) 47.06 100.00 100.00 99.78\n7 Candidiasis 16 0.81 41.18 (18.44 –67.10) 64.71 99.80 41.18 99.80\n8 Discoid lupus\nerythematosus\n47 0.90 60.42 (45.27 –74.23) 83.33 99.20 42.03 99.61\n9 Eczema 432 0.87 54.29 (49.46 –59.10) 81.90 97.58 67.83 95.78\n10 Fixed drug eruption 12 0.87 41.67 (15.16 –72.33) 75.00 99.70 25.00 99.86\n11 Herpes zoster 38 0.89 66.67 (49.78 –80.91) 79.49 99.60 56.52 99.74\n12 Hidradenitis suppurativa 32 0.97 93.94(79.78 –99.26) 93.94 99.62 62.00 99.96\n13 Ichthyosis 21 0.93 81.81 (59.72 –94.81) 86.36 99.78 62.07 99.92\n14 Impetigo and Pyodermas 109 0.89 57.27 (47.48 –66.66) 82.72 99.04 57.27 99.04\n15"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2540
    },
    {
      "id": "Q5",
      "question": "What was the proedure for splitting the dataset into training, validation, and test sets in this study?",
      "answer": "Split into five folds for cross-validation.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        14,
        2,
        16
      ],
      "chunks_str": [
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,",
        " validation studies of AI-\nbased algorithms related to dermatology in clinical settings.\nMaterial and methods\nThe study aimed to develop a convolutional neural network\n(CNN)-based algorithm trained with clinical images of 40 differ-\nent skin diseases. A user-friendly, smartphone app was also gen-\nerated, and a clinical validation study on 5014 patients was done\nby physicians in urban, rural primary care and tertiary care set-\ntings. The app’s analysis of a single image of the lesion was com-\npared to the consensus diagnosis made by two board-certiﬁed\ndermatologists. Only patients, for whom the treating board-cer-\ntiﬁed dermatologist was conﬁdent of the diagnosis and the diag-\nnosis was cross-veriﬁed by another board-certiﬁed\ndermatologist, were included. If there was no consensus then the\npatient was excluded from the study.\nGeneration of the CNN-based algorithm\nThe CNN architecture used was a modiﬁed version of Densenet-\n161 with optimized augmentation and inference pipelines.\n16\nThese optimizations were derived through rigorous experiments\nand were attuned to clinical skin images. All training and testing\nimages were annotated and segmented so a bounding box sur-\nrounded lesion of interest and irrelevant features such as rulers\nand surgical markings were discarded. The 17 718 raw images\nwere sourced from public databases (http://www.hellenicderma\ntlas.com/en and http://www.danderm.dk/atlas), after obtaining\npermission from them, as well as images from dermatologists in\nIndia. Of these, 310 images were discarded during the\npreprocessing stage due to poor resolution or multiple lesions.\nOut of the remaining 17 408 images, 1990 images belonged to\nthe non-speciﬁc category and 15 418 images were within the 40\nselected disease categories (Table 1). These images were split\ninto ﬁve equal parts (folds) and ﬁve iterations of training and\nvalidation were performed in a manner so that within each itera-\ntion, a different fold of the data was held-out for validation while\nthe remaining fourfolds were used for learning. The training\nimages were 12 350 and testing images were 3068. Since the\ndataset was imbalanced, a custom modiﬁed version of the\nweighted focal loss function was used to train the network. The\nweights for each class were calculated using the inverse sample\nsize method. Our test images were either in-distribution images\ni.e. images within 40 training classes or out-of-distribution sets\nthat we named as non-speciﬁc set.\nWe initially used Inception-v4, which was one of the most\npopular CNN models at the time. For 10 diseases, a sensitivity of\naround 85% was achieved, but for the 20-disease class model,\nthis fell to around 65%. We experimented with many parameters\nlike learning rate and choice of optimizer etc. with no signiﬁcant\nimprovements. It was felt that as the architectures became dee-\nper, there could be problems related to over-ﬁtting. According\nto Huanget al.,convolutional networks can be substantially dee-\nper, more accurate and efﬁcient to train if they contain shorter\nconnections between layers close to the input and those close to\nthe output.\n17 Their implementation of this architecture is called\nDenseNet. In this architecture, to ensure maximum information\nﬂow between layers, each layer obtains additional inputs from all\npreceding layers and passes on its own feature-maps to all subse-\nquent layers.\n17 We found that the DenseNet architecture pro-\nvided better results than the other contemporary architectures\nsuch as Inception-Resnet-V2, Resnets-50, Resnet-101 and Res-\nnet-152. We tried several DenseNet variants",
        "/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nFigure 4 (a) Confusion matrix from the top-1 prediction of clinical data by the app. The numbers in each row are normalized to 100. The\nactual patient numbers for each disease class are shown in parenthesis. The actual labels are depicted on the y-axis and predicted labels\nare on the x-axis. (b) Confusion matrix from the top-3 prediction of clinical data by the app. The numbers in each row are normalized to\n100. The actual patient numbers for each disease class are shown in parenthesis.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 543\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nto diagnose 26 common skin conditions from clinical images\nplus associated medical histories.25 During validation, Liuet al\nachieved a 71% top-1 accuracy and their algorithm surpassed\ndermatologists, PCPs and nurse practitioners in a clinical data-\nset.\n25 Our Top-1 accuracy was 77% and the mean AUC was 0.95\nfor algorithmic validation of 40 diseases.\nThere are no precedents for studies in which an AI-based, skin\ndisease diagnosis app has been tested in clinical settings. In our\nwork, a top-1 accuracy of 75% and a top-3 accuracy of 90% was\nachieved by the app for 35 skin diseases and was largely similar to\nour model validation results. Some differences in diagnostic per-\nformance (in terms of disease AUCs) between model and app\nwere noted and may be attributable to either fewer clinical valida-\ntion images for some diseases like Bowen’s disease, anogenital\nwarts, tinea pedis, rosacea, candidiasis, herpes zoster (Fig. 4a and\nSupplementary Figure S1) and/or differences in disease morphol-\nogy between white and pigmented skin. Eczema is a broad disease\ncategory, incorporating diseases with varied morphology such as\nlichen simplex chronicus, atopic dermatitis, nummular eczema\nand contact dermatitis. Training of the model with speciﬁc dis-\nease classes rather than a broad category of eczema may improve\nsensitivity. As shown in the confusion matrix, eczema was often\nconfused with psoriasis, lichen planus and tinea corporis, cruris\nor faciei (Figs 4a, b). To some extent, this mirrors the diagnostic\nconfusion faced by many physicians as well.\n2,25,26 A few melano-\ncytic nevi lesions were mistaken for BCC possibly because of their\nresemblance with pigmented BCC, which is more commonly seen\nin skin of colour. Besides, it was observed that diseases with dis-\ntinct morphology and predilection for certain sites (in a similar\nrecognizable background) such as melasma and tinea unguium\nhad better accuracies.\nIn this study, we found a high top-3 sensitivity for BCC\n(97.58%, n = 124) and SCC (92.86%,n = 14"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2561
    },
    {
      "id": "Q6",
      "question": "What preprocessing techniques on the included variables/features were applied in this study?",
      "answer": "Image crop, color balance, flips, rotations, Gaussian normalization.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        14,
        15,
        3
      ],
      "chunks_str": [
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,",
        " as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation, mainly for skin cancers. However, only\na few researchers have used clinical/macroscopic images for mul-\nti-class skin disease identiﬁcation, representative of a real-world\nclinical scenario. In a study by Estevaet al., CNN performedat\npar with dermatologists for classiﬁcation of 9 skin disease cate-\ngories, skin cancers and their precursors, using clinical images\nwith an accuracy of 55.4%.\n22 Mendes et al. generated a CNN\nclassiﬁcation model for 12 skin cancers and related benign and\npremalignant skin conditions and achieved a total accuracy of\n78%.\n23 Han et al. reported a mean AUC of 0.91 and top-1 accu-\nracy between~55–57% on the same set of 12 diseases and, inter-\nestingly, found a substantial difference in speciﬁcities of skin\ncancer between an Asian skin dataset and Caucasian skin data-\nset.\n24 More recently, Liuet al. developed a deep learning system\n76.55\n90.51\n80.33\n94.33\n74.9\n89.22\n75.07\n89.62\n0\n25\n50\n75\n100\nUrban private\npractice\nRural Tertiary\nCombined\nClinical setting\nAccuracy\nTop_1_accuracy\nTop_3_accuracy\n(a)\n(b)\nFigure 3 (a) Overall Top-1 and Top-3 accuracies from clinical vali-\ndation of app in a private urban clinicN = 383), rural hospital\n(N = 932), tertiary hospital (N = 3699) and combined data\n(N = 5014). (b) Disease-speciﬁc Top-1 sensitivities, Top-3 sensitiv-\nities and Top-1 speciﬁcities. The length of the dotted line depicts\nan increase in sensitivity betweenﬁrst and third predictions of the\napp. The size of the icons depicts the number of patients for that\ndisease class.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\n542 Pangti et al.\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nFigure 4 (a) Confusion matrix from the top-1 prediction of clinical data by the app. The numbers in each row are normalized to 100. The\nactual patient numbers for each disease class are shown in parenthesis. The actual labels are depicted on the y-axis and predicted labels\nare on the x-axis. (b) Confusion matrix from the top-3 prediction of clinical data by the app. The numbers in each row are normalized to\n100.",
        " could be problems related to over-ﬁtting. According\nto Huanget al.,convolutional networks can be substantially dee-\nper, more accurate and efﬁcient to train if they contain shorter\nconnections between layers close to the input and those close to\nthe output.\n17 Their implementation of this architecture is called\nDenseNet. In this architecture, to ensure maximum information\nﬂow between layers, each layer obtains additional inputs from all\npreceding layers and passes on its own feature-maps to all subse-\nquent layers.\n17 We found that the DenseNet architecture pro-\nvided better results than the other contemporary architectures\nsuch as Inception-Resnet-V2, Resnets-50, Resnet-101 and Res-\nnet-152. We tried several DenseNet variants such as Densenet-\n169, Densenet-121, Densenet-161 and densenet-201, but selected\nDensenet-161 as it achieved the best balance of sensitivity versus\nspeciﬁcity for the 40 disease classes. In future, as the disease list\nexpands and as newer CNN architectures evolve, this search for\nan optimal model will need to be revisited.\nOur optimizations included three stages. In the preprocessing\nstage, via iterative experiments, we identiﬁed a set of speciﬁc\nimage processing and augmentation algorithms that improve the\noverall model performance. We determined that for skin lesions\nrandom image crop selection within a targeted area range, slight\ncolour balance adjustment, image ﬂips (vertical and horizontal)\nand 90° rotations lead to an improvement in results. Few algo-\nrithms like heavy colour balance adjustment, random rotations\nlead to no improvements or even slight degradation in perfor-\nmance. We also did several experiments with normalization\nalgorithms and selected the best performing Gaussian normal-\nization algorithm on our dataset. In the postprocessing stage for\nprediction, we used several copies of the same model to generate\nthe ﬁnal prediction. The raw outputs from each of the model\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 537\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\ncopies were then combined to generate ﬁnal predictions. We\nadditionally made custom changes in the loss function. Focal\nloss is used for multi-class classiﬁcation whereas log loss for bin-\nary classiﬁcation. We implemented a new loss function that led\nto better results from either of them individually. Our custom\nloss function is a hybrid implementation of focal loss and log\nloss.\n18,19 We also accounted for class imbalances. The mathemat-\nical expression of the loss function used by us is described\nbelow.\nFLðp\ntÞ¼/C0 αt ð1 /C0 ptÞγlogðptÞ\nLLðpÞ¼/C0 ð ylogðpÞþð 1 /C0 yÞlogð1 /C0 pÞÞ\nFCLðptÞ¼/C0 αtðytð1 /C0 ptÞγlogðptÞþð 1 /C0 ytÞpγ\nt logð1 /C0 ptÞÞ\nFL = Focal loss; LL = Log Loss; FCL = Our loss function\nimplementation.\nTable 1 shows number of images and diagnostic parameters fromﬁvefold algorithm"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2544
    },
    {
      "id": "Q7",
      "question": "How is missing data handled in this study?",
      "answer": "Unknown from this paper",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        4,
        16,
        11
      ],
      "chunks_str": [
        " imbalances. The mathemat-\nical expression of the loss function used by us is described\nbelow.\nFLðp\ntÞ¼/C0 αt ð1 /C0 ptÞγlogðptÞ\nLLðpÞ¼/C0 ð ylogðpÞþð 1 /C0 yÞlogð1 /C0 pÞÞ\nFCLðptÞ¼/C0 αtðytð1 /C0 ptÞγlogðptÞþð 1 /C0 ytÞpγ\nt logð1 /C0 ptÞÞ\nFL = Focal loss; LL = Log Loss; FCL = Our loss function\nimplementation.\nTable 1 shows number of images and diagnostic parameters fromﬁvefold algorithmic validation of 41 skin conditions\nS.S Disease class N, Private N, Public AUC-model Sensitivity Speci ﬁcity PPV NPV\n1 Acne 337 240 0.98 86.23 /C6 3.26 99.56 /C6 0.13 86.32 /C6 4.22 99.46 /C6 0.19\n2 Actinic keratosis 249 372 0.97 76.49 /C6 3.25 99.04 /C6 0.22 82.83 /C6 3.72 98.85 /C6 0.19\n3 Alopecia 109 152 0.97 78.38 /C6 6.25 99.74 /C6 0.09 86.60 /C6 5.39 99.65 /C6 0.08\n4 Anogenital warts 86 96 0.95 80.22 /C6 1.96 99.92 /C6 0.04 85.69 /C6 6.51 99.73 /C6 0.10\n5 Basal cell carcinoma 365 506 0.97 77.77 /C6 3.58 99.10 /C6 0.13 83.89 /C6 1.09 98.50 /C6 0.27\n6 Bowen ’s disease 130 179 0.92 61.31 /C6 10.78 99.60 /C6 0.14 79.31 /C6 8.58 99.06 /C6 0.11\n7 Bullous pemphigoid 54 92 0.91 58.22 /C6 13.60 99.90 /C6 0.05 82.86 /C6 8.45 99.60 /C6 0.14\n8 Candidiasis 118 187 0.94 65.24 /C6 6.39 99.54 /C6 0.13 77.47 /C6 4.65 99.35 /C6 0.11\n9 Chicken pox 77 108 0.94 72.43 /C6 6.99 99.77 /C6 0.07 80.94 /C6 9.67 99.59 /C6 0.12\n10 Discoid lupus erythematosus 85 134 0.89 49.78 /C6 6.70 99.83 /C6 0.07 73.06 /C6 6.84 99.36 /C6 0.07\n11 Eczema 560 336 0.92 57.52 /C6 3.37 99.00 /",
        "/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nFigure 4 (a) Confusion matrix from the top-1 prediction of clinical data by the app. The numbers in each row are normalized to 100. The\nactual patient numbers for each disease class are shown in parenthesis. The actual labels are depicted on the y-axis and predicted labels\nare on the x-axis. (b) Confusion matrix from the top-3 prediction of clinical data by the app. The numbers in each row are normalized to\n100. The actual patient numbers for each disease class are shown in parenthesis.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 543\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nto diagnose 26 common skin conditions from clinical images\nplus associated medical histories.25 During validation, Liuet al\nachieved a 71% top-1 accuracy and their algorithm surpassed\ndermatologists, PCPs and nurse practitioners in a clinical data-\nset.\n25 Our Top-1 accuracy was 77% and the mean AUC was 0.95\nfor algorithmic validation of 40 diseases.\nThere are no precedents for studies in which an AI-based, skin\ndisease diagnosis app has been tested in clinical settings. In our\nwork, a top-1 accuracy of 75% and a top-3 accuracy of 90% was\nachieved by the app for 35 skin diseases and was largely similar to\nour model validation results. Some differences in diagnostic per-\nformance (in terms of disease AUCs) between model and app\nwere noted and may be attributable to either fewer clinical valida-\ntion images for some diseases like Bowen’s disease, anogenital\nwarts, tinea pedis, rosacea, candidiasis, herpes zoster (Fig. 4a and\nSupplementary Figure S1) and/or differences in disease morphol-\nogy between white and pigmented skin. Eczema is a broad disease\ncategory, incorporating diseases with varied morphology such as\nlichen simplex chronicus, atopic dermatitis, nummular eczema\nand contact dermatitis. Training of the model with speciﬁc dis-\nease classes rather than a broad category of eczema may improve\nsensitivity. As shown in the confusion matrix, eczema was often\nconfused with psoriasis, lichen planus and tinea corporis, cruris\nor faciei (Figs 4a, b). To some extent, this mirrors the diagnostic\nconfusion faced by many physicians as well.\n2,25,26 A few melano-\ncytic nevi lesions were mistaken for BCC possibly because of their\nresemblance with pigmented BCC, which is more commonly seen\nin skin of colour. Besides, it was observed that diseases with dis-\ntinct morphology and predilection for certain sites (in a similar\nrecognizable background) such as melasma and tinea unguium\nhad better accuracies.\nIn this study, we found a high top-3 sensitivity for BCC\n(97.58%, n = 124) and SCC (92.86%,n = 14",
        " diversity in the patient populations that\nconsult physicians in urban versus rural areas. The study was\napproved by the Ethics Committee of All India Institute of Med-\nical Sciences. We included consecutive patients presenting to a\nparticular investigator in the Outpatient Department, where the\ndermatologists were conﬁdent of the diagnosis, either by clinical\nexamination, laboratory investigation, and/or histopathological\nexamination. Dermatologists were blinded to the app results. A\nsingle representative image from each patient was tested on the\napp by a separate physician.\nResults\nThe overall scheme for this study is outlined in Figure 1.\nTable 2 shows th number of patients, AUC, Top‐1/Top‐3 sensitivity, speciﬁcity, positive predictive and negative predictive values for\ncombined clinical data from three different clinical settings.\nS.no. Disease class Number\nof patients\nAUC-\nclinic\nTop-1 sensitivity\n% (CI)\nTop-3\nsensitivity %\nTop-1\nspeciﬁcity %\nTop-1 PPV Top-1 NPV\n1 Acne 592 0.98 89.86 (87.15 –92.18) 97.97 98.19 86.92 98.64\n2 Alopecia 184 0.97 88.11 (82.55 –92.36) 96.22 99.28 82.32 99.54\n3 Anogenital warts 34 0.85 57.14 (39.35 –73.68) 71.43 99.70 57.14 99.70\n4 Basal cell carcinoma 123 0.98 93.55 (87.68 –97.17) 97.58 98.51 61.38 99.83\n5 Bowen ’s disease 11 0.77 45.45 (16.75 –76.62) 54.54 99.90 50.00 99.88\n6 Bullous pemphigoid 16 0.73 35.29 (14.21 –61.67) 47.06 100.00 100.00 99.78\n7 Candidiasis 16 0.81 41.18 (18.44 –67.10) 64.71 99.80 41.18 99.80\n8 Discoid lupus\nerythematosus\n47 0.90 60.42 (45.27 –74.23) 83.33 99.20 42.03 99.61\n9 Eczema 432 0.87 54.29 (49.46 –59.10) 81.90 97.58 67.83 95.78\n10 Fixed drug eruption 12 0.87 41.67 (15.16 –72.33) 75.00 99.70 25.00 99.86\n11 Herpes zoster 38 0.89 66.67 (49.78 –80.91) 79.49 99.60 56.52 99.74\n12 Hidradenitis suppurativa 32 0.97 93.94(79.78 –99.26) 93.94 99.62 62.00 99.96\n13 Ichthyosis 21 0.93 81.81 (59.72 –94.81) 86.36 99.78 62.07 99.92\n14 Impetigo and Pyodermas 109 0.89 57.27 (47.48 –66.66) 82.72 99.04 57.27 99.04\n15"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE"
    },
    {
      "id": "Q8",
      "question": "How are outliers handled in this study?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        19,
        21,
        20
      ],
      "chunks_str": [
        " Trends in dermatology: geographic density of US der-\nmatologists. Arch Dermatol2010; 146: 779.\n5 Ehrlich A, Kostecki J, Olkaba H. Trends in dermatology practices and the\nimplications for the workforce.J Am Acad Dermatol2017; 77: 746–752.\n6 Lim HW, Collins SAB, Resneck JS, Jret al. The burden of skin disease in\nthe United States.J Am Acad Dermatol2017; 76: 958–972.e2.\n7 Patro BK, Tripathy JP, De D, Sinha S, Singh A, Kanwar AJ. Diagnostic\nagreement between a primary care physician and a teledermatologist for\ncommon dermatological conditions in North India.Indian Dermatol\nOnline J2015; 6:2 1–26.\n8 Bahelah SO, Bahelah R, Bahelah M, Albatineh AN. Primary care physi-\ncians’ knowledge and self-perception of competency in dermatology: An\nevaluation study from Yemen.Cogent Med2015; 2: 1119948.\n9 Ramsay DL, Fox AB. The ability of primary care physicians to recognize\nthe common dermatoses.Arch Dermatol1981; 117: 620–622.\n10 Tran H, Chen K, Lim AC, Jabbour J, Shumack S. Assessing diagnostic\nskill in dermatology: a comparison between general practitioners and der-\nmatologists. Australas J Dermatol2005; 46: 230–234.\n11 Pickett K, Loveman E, Kalita N, Frampton GK, Jones J. Educational inter-\nventions to improve quality of life in people with chronic inﬂammatory\nskin diseases: systematic reviews of clinical effectiveness and cost-effec-\ntiveness. Health Technol Assess2015; 19: 1-176,v-vi.\n12 Gordon WJ, Landman A, Zhang H, Bates DW. Beyond validation: getting\nhealth apps into clinical practice.NPJ Digit Med2020; 3: 14.\n13 Newzoo’s Global Mobile Market Report: Insights into the World’s 3.2\nBillion Smartphone Users, the Devices They use & the Mobile Games\nThey Play. (https://newzoo.com/insights/articles/newzoos-global-mobile-\nmarket-report-insights-into-the-worlds-3-2-billion-smartphone-users-\nthe-devices-they-use-the-mobile-games-they-play/)(Accessed on April 10,\n2020).\n14 Sanders SF, Terwiesch M, Gordon WJ, Stern AD. How artiﬁcial intelli-\ngence is changing health care delivery.N Engl J Med Catalyst2019.\n(https://catalyst.nejm.org/health-care-ai-systems-changing-delivery/)\n(Accessed: April 10, 2020).\n15 Chuchu N, Takwoingi Y, Dinnes Jet al. Cochrane Skin Cancer Diagnostic\nTest Accuracy Group. Smartphone applications for triaging adults with\nskin lesions that are suspicious for melanoma.Cochrane Database Syst\nRev 2018; 12: CD013192.\n16 Huang G, Liu Z, MaatenLvd WKQ.Densely connected convolutional net-\nworks 2017 IEEE conference on computer vision and pattern recognition\n(CVPR), Honolulu, HI, 2017;2261–9. (http://ieeexplore.ieee.org/stamp/\nstamp.jsp?tp=&arnumber=8099726&isnumber=8099483) (Accessed on\nApril 10, 2020).\n17 Huang G, Liu Z, van der Maaten L, Weinberger KQ.Densely connected\nconvolutional networks. August 201",
        "917.\n28 Al Hasan M, Fitzgerald SM, Saoudian M, Krishnaswamy G. Dermatology\nfor the practicing allergist: Tinea pedis and its complications.Clin Mol\nAllergy 2004; 2:5 .\n29 Verma SB, Vasani R. Male genital dermatophytosis– clinical features and\nthe effects of the misuse of topical steroids and steroid combinations– an\nalarming problem in India.Mycoses 2016; 59: 606–614.\n30 Bissoto A, Fornacialli M, Valle E, Avila S.(De)Constructing bias on skin\nlesions datasets. April 2019 (arXiv:1904.08818) (Accessed on April 2020).\nSupporting information\nAdditional Supporting Information may be found in the online\nversion of this article:\nSupplementary Material\nSupplementary Figure 1. ROC curve of Machine and clinical val-\nidation studies of individual disease classes.\nSupplementary Methods: Formulae of the metrics used in the\nstudy.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 545\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n",
        " triaging adults with\nskin lesions that are suspicious for melanoma.Cochrane Database Syst\nRev 2018; 12: CD013192.\n16 Huang G, Liu Z, MaatenLvd WKQ.Densely connected convolutional net-\nworks 2017 IEEE conference on computer vision and pattern recognition\n(CVPR), Honolulu, HI, 2017;2261–9. (http://ieeexplore.ieee.org/stamp/\nstamp.jsp?tp=&arnumber=8099726&isnumber=8099483) (Accessed on\nApril 10, 2020).\n17 Huang G, Liu Z, van der Maaten L, Weinberger KQ.Densely connected\nconvolutional networks. August 2016(arXiv:1608.06993[cs.CV]).\n18 Lin T-Y, Goyal P, Girshick R, He K, Doll´ar P.Focal Loss for Dense Object\nDetection. August 2017 (arXiv:1708.02002 [cs.CV]).\n19 Log loss. February 2017 (http://wiki.fast.ai/index.php/Log_Loss).\nAccessed on: May 13, 2020.\n20 Pedregosa F, Varoquaux G, Gramfort Aet al. Scikit-learn: machine learn-\ning in Python.\nJ Mach Learn Res2011; 12: 2825–2830.\n21 Topol R. Deep Medicine: how artiﬁcial intelligence can make healthcare\nhuman again Ch, 5th edn, Basic Books, New York, 2019.\n22 Esteva A, Kuprel B, Novoa RAet al. Dermatologist-level classiﬁcation of\nskin cancer with deep neural networks.Nature 2017; 542: 115–118.\n23 Mendes DB, da Silva NC.Skin lesions classiﬁcation using convolutional\nneural networks in clinical images, December 2018(arXiv:1812.02316\n[cs.CV])(Last accessed: April 10, 2020).\n24 Han SS, Kim MS, Lim W, Park GH, Park I, Chang SE. Classiﬁcation of\nthe clinical images for benign and malignant cutaneous tumors using a\ndeep learning algorithm.J Invest Dermatol2018; 138: 1529–1538.\n25 Liu Y, Jain A, Eng Cet al.A deep learning system for differential diagnosis\nof skin diseases, September 2019(arXiv:1909.05382) (Accessed on April\n2020).\n26 Gorouhi F, Davari P, Fazel N. Cutaneous and mucosal lichen planus: a\ncomprehensive review of clinical subtypes, risk factors, diagnosis, and\nprognosis. Scien World J2014; 2014: 742826.\n27 Siegfried EC, Hebert AA. Diagnosis of atopic dermatitis: mimics, over-\nlaps, and complications.J Clin Med2015; 4: 884–917.\n28 Al Hasan M, Fitzgerald SM, Saoudian M, Krishnaswamy G. Dermatology\nfor the practicing allergist: Tinea pedis and its complications.Clin Mol\nAllergy 2004; 2:5 .\n29 Verma SB, Vasani R. Male genital dermatophytosis– clinical features and\nthe effects of the misuse of topical steroids and steroid combinations– an\nalarming problem in India.Mycoses 2016; 59: 606–614.\n30 Bissoto A, Fornacialli M, Valle E, Avila S.(De)Constructing bias on skin\nlesions datasets. April 2019 (arXiv:1904.08818) (Accessed on April 202"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2065
    },
    {
      "id": "Q9",
      "question": "Which prediction models were used in this study?",
      "answer": "CNN-based algorithm, DenseNet-161",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        14,
        2,
        0
      ],
      "chunks_str": [
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,",
        " validation studies of AI-\nbased algorithms related to dermatology in clinical settings.\nMaterial and methods\nThe study aimed to develop a convolutional neural network\n(CNN)-based algorithm trained with clinical images of 40 differ-\nent skin diseases. A user-friendly, smartphone app was also gen-\nerated, and a clinical validation study on 5014 patients was done\nby physicians in urban, rural primary care and tertiary care set-\ntings. The app’s analysis of a single image of the lesion was com-\npared to the consensus diagnosis made by two board-certiﬁed\ndermatologists. Only patients, for whom the treating board-cer-\ntiﬁed dermatologist was conﬁdent of the diagnosis and the diag-\nnosis was cross-veriﬁed by another board-certiﬁed\ndermatologist, were included. If there was no consensus then the\npatient was excluded from the study.\nGeneration of the CNN-based algorithm\nThe CNN architecture used was a modiﬁed version of Densenet-\n161 with optimized augmentation and inference pipelines.\n16\nThese optimizations were derived through rigorous experiments\nand were attuned to clinical skin images. All training and testing\nimages were annotated and segmented so a bounding box sur-\nrounded lesion of interest and irrelevant features such as rulers\nand surgical markings were discarded. The 17 718 raw images\nwere sourced from public databases (http://www.hellenicderma\ntlas.com/en and http://www.danderm.dk/atlas), after obtaining\npermission from them, as well as images from dermatologists in\nIndia. Of these, 310 images were discarded during the\npreprocessing stage due to poor resolution or multiple lesions.\nOut of the remaining 17 408 images, 1990 images belonged to\nthe non-speciﬁc category and 15 418 images were within the 40\nselected disease categories (Table 1). These images were split\ninto ﬁve equal parts (folds) and ﬁve iterations of training and\nvalidation were performed in a manner so that within each itera-\ntion, a different fold of the data was held-out for validation while\nthe remaining fourfolds were used for learning. The training\nimages were 12 350 and testing images were 3068. Since the\ndataset was imbalanced, a custom modiﬁed version of the\nweighted focal loss function was used to train the network. The\nweights for each class were calculated using the inverse sample\nsize method. Our test images were either in-distribution images\ni.e. images within 40 training classes or out-of-distribution sets\nthat we named as non-speciﬁc set.\nWe initially used Inception-v4, which was one of the most\npopular CNN models at the time. For 10 diseases, a sensitivity of\naround 85% was achieved, but for the 20-disease class model,\nthis fell to around 65%. We experimented with many parameters\nlike learning rate and choice of optimizer etc. with no signiﬁcant\nimprovements. It was felt that as the architectures became dee-\nper, there could be problems related to over-ﬁtting. According\nto Huanget al.,convolutional networks can be substantially dee-\nper, more accurate and efﬁcient to train if they contain shorter\nconnections between layers close to the input and those close to\nthe output.\n17 Their implementation of this architecture is called\nDenseNet. In this architecture, to ensure maximum information\nﬂow between layers, each layer obtains additional inputs from all\npreceding layers and passes on its own feature-maps to all subse-\nquent layers.\n17 We found that the DenseNet architecture pro-\nvided better results than the other contemporary architectures\nsuch as Inception-Resnet-V2, Resnets-50, Resnet-101 and Res-\nnet-152. We tried several DenseNet variants",
        "ORIGINAL ARTICLE\nA machine learning-based, decision support, mobile phone\napplication for diagnosis of common dermatological\ndiseases\nR. Pangti,1 J. Mathur,2 V. Chouhan,2 S. Kumar,2 L. Rajput,1 S. Shah,1 A. Gupta,3 A. Dixit,1\nD. Dholakia,4,5 S. Gupta,6 S. Gupta,1 M. George,7 V.K. Sharma,1 S. Gupta1,*\n1Department of Dermatology and Venereology, All India Institute of Medical Science, New Delhi, India\n2Nurithm Labs Private Limited, Noida, India\n3Skin Aid Clinic, Cross Point Mall, Gurugram, India\n4Genomics and Molecular Medicine Unit, Academy of Scientiﬁc and Innovative Research, New Delhi, India\n5Academy of Scientiﬁc and Innovative Research, Ghaziabad, Uttar Pradesh, India\n6Maharishi Markandeshwar Institute of Medical Sciences and Research, Mullana, Ambala, India\n7Sahrudya Hospital, Alappuzha, India\n*Correspondence: S. Gupta. E-mail: someshgupta@hotmail.com\nAbstract\nBackground The integration of machine learning algorithms in decision support tools for physicians is gaining popular-\nity. These tools can tackle the disparities in healthcare access as the technology can be implemented on smartphones.\nWe present theﬁrst, large-scale study on patients with skin of colour, in which the feasibility of a novel mobile health\napplication (mHealth app) was investigated in actual clinical workﬂows.\nObjective To develop a mHealth app to diagnose 40 common skin diseases and test it in clinical settings.\nMethods A convolutional neural network-based algorithm was trained with clinical images of 40 skin diseases. A\nsmartphone app was generated and validated on 5014 patients, attending rural and urban outpatient dermatology\ndepartments in India. The results of this mHealth app were compared against the dermatologists’ diagnoses.\nResults The machine–learning model, in an in silico validation study, demonstrated an overall top-1 accuracy of\n76.93 /C6 0.88% and mean area-under-curve of 0.95/C6 0.02 on a set of clinical images. In the clinical study, on patients\nwith skin of colour, the app achieved an overall top-1 accuracy of 75.07% (95% CI= 73.75–76.36), top-3 accuracy of\n89.62% (95% CI= 88.67–90.52) and mean area-under-curve of 0.90/C6 0.07.\nConclusion This study underscores the utility of artiﬁcial intelligence-driven smartphone applications as a point-of-\ncare, clinical decision support tool for dermatological diagnosis for a wide spectrum of skin diseases in patients of the\nskin of colour.\nReceived: 11 April 2020; revised: 22 June 2020; Accepted: 5 August 2020\nConﬂict of interests\nJyoti Mathur and Sharad Kumar are direct beneﬁciaries of any proﬁts acquired by the smartphone application developed\nat Nurithm Labs Private Limited and Vikas Chouhan is a salaried employee at Nurithm Labs Private Limited.\nFunding sources\nNone.\nIntroduction\nSkin diseases are the fourth leading cause of non-fatal disease\nburden across 188 countries in both low and high-income coun-\ntries.\n1,2 There is less than one dermatologist per 100 000 people\nin India and less than three dermatologists per 100 000 of the\npopulation in the United States and the ratios are expected to\ndecline further.\n3,4 In a survey by the American Academy of Der-\nmatology, 33%"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2548
    },
    {
      "id": "Q10",
      "question": "What considerations were given to model selection and hyperparameter tuning in this study?",
      "answer": "DenseNet-161 selected; preprocessing, augmentation, custom loss function.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        3,
        14,
        18
      ],
      "chunks_str": [
        " could be problems related to over-ﬁtting. According\nto Huanget al.,convolutional networks can be substantially dee-\nper, more accurate and efﬁcient to train if they contain shorter\nconnections between layers close to the input and those close to\nthe output.\n17 Their implementation of this architecture is called\nDenseNet. In this architecture, to ensure maximum information\nﬂow between layers, each layer obtains additional inputs from all\npreceding layers and passes on its own feature-maps to all subse-\nquent layers.\n17 We found that the DenseNet architecture pro-\nvided better results than the other contemporary architectures\nsuch as Inception-Resnet-V2, Resnets-50, Resnet-101 and Res-\nnet-152. We tried several DenseNet variants such as Densenet-\n169, Densenet-121, Densenet-161 and densenet-201, but selected\nDensenet-161 as it achieved the best balance of sensitivity versus\nspeciﬁcity for the 40 disease classes. In future, as the disease list\nexpands and as newer CNN architectures evolve, this search for\nan optimal model will need to be revisited.\nOur optimizations included three stages. In the preprocessing\nstage, via iterative experiments, we identiﬁed a set of speciﬁc\nimage processing and augmentation algorithms that improve the\noverall model performance. We determined that for skin lesions\nrandom image crop selection within a targeted area range, slight\ncolour balance adjustment, image ﬂips (vertical and horizontal)\nand 90° rotations lead to an improvement in results. Few algo-\nrithms like heavy colour balance adjustment, random rotations\nlead to no improvements or even slight degradation in perfor-\nmance. We also did several experiments with normalization\nalgorithms and selected the best performing Gaussian normal-\nization algorithm on our dataset. In the postprocessing stage for\nprediction, we used several copies of the same model to generate\nthe ﬁnal prediction. The raw outputs from each of the model\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 537\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\ncopies were then combined to generate ﬁnal predictions. We\nadditionally made custom changes in the loss function. Focal\nloss is used for multi-class classiﬁcation whereas log loss for bin-\nary classiﬁcation. We implemented a new loss function that led\nto better results from either of them individually. Our custom\nloss function is a hybrid implementation of focal loss and log\nloss.\n18,19 We also accounted for class imbalances. The mathemat-\nical expression of the loss function used by us is described\nbelow.\nFLðp\ntÞ¼/C0 αt ð1 /C0 ptÞγlogðptÞ\nLLðpÞ¼/C0 ð ylogðpÞþð 1 /C0 yÞlogð1 /C0 pÞÞ\nFCLðptÞ¼/C0 αtðytð1 /C0 ptÞγlogðptÞþð 1 /C0 ytÞpγ\nt logð1 /C0 ptÞÞ\nFL = Focal loss; LL = Log Loss; FCL = Our loss function\nimplementation.\nTable 1 shows number of images and diagnostic parameters fromﬁvefold algorithm",
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,",
        " the reuse of the same\npublic datasets from white-skinned individuals for training, eval-\nuating or comparing models in nearly all studies.\n30 Therefore,\nwe used several thousand new patient images for training and all\ndistinct images for validation. To enable our app to make deci-\nsions on clinically relevant features, we also trained our model\non images of normal skin from individuals as a control.\nOne limitation of this study was the absence of integration of\nmedical history with image analysis by the app. The dermatolo-\ngists had the advantage of having access to relevant additional\ninformation as they had a face-to-face interaction with the\npatient, making it easier for them to arrive at a diagnosis. A few\nimportant relevant points in the analysis, such as the duration of\nthe lesion, sites(s) involved, symptoms, and evolution of the\nlesions can improve the accuracy. The image analysis does not\ntake into consideration the distribution of skin lesions, which is\nas important a clue for the diagnosis of certain diseases as is the\nmorphology. For example, pityriasis rosea and herpes zoster\nhave a patterned distribution. Future versions of such apps need\nto reﬁne the image-based diagnosis with automated analyses of\npatient metadata.\nIn conclusion, this is the ﬁrst study where an app designed to\ndetect 40 dermatological diseases was tested in actual clinical set-\ntings on patients with skin of colour. Our data suggest that the\nAI-driven app has high diagnostic accuracy compared to a der-\nmatologist, and is, therefore, a useful, point-of-care, clinical\ndecision support tool for dermatological diagnosis for a range of\ncommon skin conditions.\nReferences\n1 Hollestein LM, Nijsten T. An insight into the global burden of skin dis-\neases. J Invest Dermatol2014; 134: 1499–1501.\n2 Karimkhani C, Dellavalle RP, Coffeng LEet al. Global skin disease mor-\nbidity and mortality: an update from the global burden of disease study\n2013. JAMA Dermatol2017; 153: 406–412.\n3 Skin diseases to grow in India by 2015: Report, May 2014. (https://www.b\niospectrumindia.com/news/73/8437/skin-diseases-to-grow-in-india-by-\n2015-report.html)Accessed on April 10, 2020.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\n544 Pangti et al.\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\n4 Yoo JY, Rigel DS. Trends in dermatology: geographic density of US der-\nmatologists. Arch Dermatol2010; 146: 779.\n5 Ehrlich A, Kostecki J, Olkaba H. Trends in dermatology practices and the\nimplications for the workforce.J Am Acad Dermatol2017; 77: 746–752.\n6 Lim HW, Collins SAB, Resneck JS, Jret al. The burden of skin disease in\nthe United States.J Am Acad Dermatol2017; 76: 958–972.e2.\n7 Patro BK, Tripathy JP, De D, Sinha S, Singh A, Kanwar AJ. Diagnostic\nagreement between a primary care physician and a teledermatologist for\ncommon dermatological conditions in North India."
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2554
    },
    {
      "id": "Q11",
      "question": "How was data augmentation or generation used in this study?",
      "answer": "Used new patient images and normal skin controls.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        18,
        20,
        9
      ],
      "chunks_str": [
        " the reuse of the same\npublic datasets from white-skinned individuals for training, eval-\nuating or comparing models in nearly all studies.\n30 Therefore,\nwe used several thousand new patient images for training and all\ndistinct images for validation. To enable our app to make deci-\nsions on clinically relevant features, we also trained our model\non images of normal skin from individuals as a control.\nOne limitation of this study was the absence of integration of\nmedical history with image analysis by the app. The dermatolo-\ngists had the advantage of having access to relevant additional\ninformation as they had a face-to-face interaction with the\npatient, making it easier for them to arrive at a diagnosis. A few\nimportant relevant points in the analysis, such as the duration of\nthe lesion, sites(s) involved, symptoms, and evolution of the\nlesions can improve the accuracy. The image analysis does not\ntake into consideration the distribution of skin lesions, which is\nas important a clue for the diagnosis of certain diseases as is the\nmorphology. For example, pityriasis rosea and herpes zoster\nhave a patterned distribution. Future versions of such apps need\nto reﬁne the image-based diagnosis with automated analyses of\npatient metadata.\nIn conclusion, this is the ﬁrst study where an app designed to\ndetect 40 dermatological diseases was tested in actual clinical set-\ntings on patients with skin of colour. Our data suggest that the\nAI-driven app has high diagnostic accuracy compared to a der-\nmatologist, and is, therefore, a useful, point-of-care, clinical\ndecision support tool for dermatological diagnosis for a range of\ncommon skin conditions.\nReferences\n1 Hollestein LM, Nijsten T. An insight into the global burden of skin dis-\neases. J Invest Dermatol2014; 134: 1499–1501.\n2 Karimkhani C, Dellavalle RP, Coffeng LEet al. Global skin disease mor-\nbidity and mortality: an update from the global burden of disease study\n2013. JAMA Dermatol2017; 153: 406–412.\n3 Skin diseases to grow in India by 2015: Report, May 2014. (https://www.b\niospectrumindia.com/news/73/8437/skin-diseases-to-grow-in-india-by-\n2015-report.html)Accessed on April 10, 2020.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\n544 Pangti et al.\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\n4 Yoo JY, Rigel DS. Trends in dermatology: geographic density of US der-\nmatologists. Arch Dermatol2010; 146: 779.\n5 Ehrlich A, Kostecki J, Olkaba H. Trends in dermatology practices and the\nimplications for the workforce.J Am Acad Dermatol2017; 77: 746–752.\n6 Lim HW, Collins SAB, Resneck JS, Jret al. The burden of skin disease in\nthe United States.J Am Acad Dermatol2017; 76: 958–972.e2.\n7 Patro BK, Tripathy JP, De D, Sinha S, Singh A, Kanwar AJ. Diagnostic\nagreement between a primary care physician and a teledermatologist for\ncommon dermatological conditions in North India.",
        " triaging adults with\nskin lesions that are suspicious for melanoma.Cochrane Database Syst\nRev 2018; 12: CD013192.\n16 Huang G, Liu Z, MaatenLvd WKQ.Densely connected convolutional net-\nworks 2017 IEEE conference on computer vision and pattern recognition\n(CVPR), Honolulu, HI, 2017;2261–9. (http://ieeexplore.ieee.org/stamp/\nstamp.jsp?tp=&arnumber=8099726&isnumber=8099483) (Accessed on\nApril 10, 2020).\n17 Huang G, Liu Z, van der Maaten L, Weinberger KQ.Densely connected\nconvolutional networks. August 2016(arXiv:1608.06993[cs.CV]).\n18 Lin T-Y, Goyal P, Girshick R, He K, Doll´ar P.Focal Loss for Dense Object\nDetection. August 2017 (arXiv:1708.02002 [cs.CV]).\n19 Log loss. February 2017 (http://wiki.fast.ai/index.php/Log_Loss).\nAccessed on: May 13, 2020.\n20 Pedregosa F, Varoquaux G, Gramfort Aet al. Scikit-learn: machine learn-\ning in Python.\nJ Mach Learn Res2011; 12: 2825–2830.\n21 Topol R. Deep Medicine: how artiﬁcial intelligence can make healthcare\nhuman again Ch, 5th edn, Basic Books, New York, 2019.\n22 Esteva A, Kuprel B, Novoa RAet al. Dermatologist-level classiﬁcation of\nskin cancer with deep neural networks.Nature 2017; 542: 115–118.\n23 Mendes DB, da Silva NC.Skin lesions classiﬁcation using convolutional\nneural networks in clinical images, December 2018(arXiv:1812.02316\n[cs.CV])(Last accessed: April 10, 2020).\n24 Han SS, Kim MS, Lim W, Park GH, Park I, Chang SE. Classiﬁcation of\nthe clinical images for benign and malignant cutaneous tumors using a\ndeep learning algorithm.J Invest Dermatol2018; 138: 1529–1538.\n25 Liu Y, Jain A, Eng Cet al.A deep learning system for differential diagnosis\nof skin diseases, September 2019(arXiv:1909.05382) (Accessed on April\n2020).\n26 Gorouhi F, Davari P, Fazel N. Cutaneous and mucosal lichen planus: a\ncomprehensive review of clinical subtypes, risk factors, diagnosis, and\nprognosis. Scien World J2014; 2014: 742826.\n27 Siegfried EC, Hebert AA. Diagnosis of atopic dermatitis: mimics, over-\nlaps, and complications.J Clin Med2015; 4: 884–917.\n28 Al Hasan M, Fitzgerald SM, Saoudian M, Krishnaswamy G. Dermatology\nfor the practicing allergist: Tinea pedis and its complications.Clin Mol\nAllergy 2004; 2:5 .\n29 Verma SB, Vasani R. Male genital dermatophytosis– clinical features and\nthe effects of the misuse of topical steroids and steroid combinations– an\nalarming problem in India.Mycoses 2016; 59: 606–614.\n30 Bissoto A, Fornacialli M, Valle E, Avila S.(De)Constructing bias on skin\nlesions datasets. April 2019 (arXiv:1904.08818) (Accessed on April 202",
        " to calculate the true positive rate (same as\nsensitivity) and the false-positive rate (1 – speciﬁcity). ROC\ncurve was the plot of the true positive rate versus the false-\npositive rate.\nClinical validation study\nWe tested our mobile app against dermatologists’ diagnosis in\nthree different clinical settings, namely, at a tertiary care centre\nData \ncollection\nAlgorithm \nfinetuning & \nvalidation\nApp \ndevelopment\nClinical \nvalidation of \nApp\nPublic database of annotated images for \n40 skin diseases + normal skin + nonspecific\nN = 9,203\nPrivate data classified by board certified \ndermatologists\nN = 8,205\nCNN training images N =12,350\nCNN testing images N =3,068\n(1990 nonspecific images not included)\nComparison of model diagnosis against \npredetermined classification\n15,418 images used for training of model to \ngenerate smartphone app\nApp tested by physicians and compared with \ndermatologists’ diagnosis. N = 5,014 \nDetermination of app’s overall sensitivity and \ndisease-specific sensitivity, specificity, PPV, \nNPV and AUC values\nApp testing on rural primary-care patients\nN = 932\nApp testing on urban, private clinic patients\nN = 383\nApp testing on urban tertiary hospital patients\nN = 3,699\nFigure 1 This ﬂowchart depicts the different steps in data collection, algorithm generation, algorithm testing, app generation and app\nvalidation in clinical studies.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 539\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosaceaMelasma\nAcne\nVitiligo/Leucoderma\nTinea pedis\nAnogenital wartsKeratoacanthoma\nMolluscum contagiosumHidradenitis suppurativa\nHerpes zosterTinea capitis\nImpetigo and Pyodermas\nAlopecia\nMilia\nBasal cell carcinoma\nMelanoma\nMelanocytic nevi/Mole\nIchthyosis\nPityriasis r\nosea\nActin\nic keratosis\nTinea cruris  corporis or faciei\nKeloid/Hype\nrtrophic scar\nSeborrheic\n keratosis\nFixed d\nrug eruption\nLichen sclerosus et atrophicus\nCh\nicken pox\nTinea ma\nnuum\nLichen planus\nUrticaria\nPityriasis ve\nrsicolorPsoriasis\nPe\nmphigus\nCandid\niasis\nBowens disease\nViral warts\nSquamous cell c\narcino\nma\nBullous pe\nmphigoidEcze\nma\nDis\ncoid lupus erythematosus\nPercentage\nSensitivity\nSpecificity\nPPV\nNPV\nSensitivity and specificity of five fold validation data(a)\n(b)\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosacea\nKeloid/Hypertrophic scar\nFixed drug eruption\nHerpes zoster\nVitiligo/Leucoderma\nIchthyosis\nHidradenitis suppurativa\nMelasma\nKeratoacanthoma\n"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2531
    },
    {
      "id": "Q12",
      "question": "Is the performance of the predictive models benchmarked or compared to a baseline?",
      "answer": "Yes, compared to dermatologists' consensus diagnosis.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        2,
        14,
        9
      ],
      "chunks_str": [
        " validation studies of AI-\nbased algorithms related to dermatology in clinical settings.\nMaterial and methods\nThe study aimed to develop a convolutional neural network\n(CNN)-based algorithm trained with clinical images of 40 differ-\nent skin diseases. A user-friendly, smartphone app was also gen-\nerated, and a clinical validation study on 5014 patients was done\nby physicians in urban, rural primary care and tertiary care set-\ntings. The app’s analysis of a single image of the lesion was com-\npared to the consensus diagnosis made by two board-certiﬁed\ndermatologists. Only patients, for whom the treating board-cer-\ntiﬁed dermatologist was conﬁdent of the diagnosis and the diag-\nnosis was cross-veriﬁed by another board-certiﬁed\ndermatologist, were included. If there was no consensus then the\npatient was excluded from the study.\nGeneration of the CNN-based algorithm\nThe CNN architecture used was a modiﬁed version of Densenet-\n161 with optimized augmentation and inference pipelines.\n16\nThese optimizations were derived through rigorous experiments\nand were attuned to clinical skin images. All training and testing\nimages were annotated and segmented so a bounding box sur-\nrounded lesion of interest and irrelevant features such as rulers\nand surgical markings were discarded. The 17 718 raw images\nwere sourced from public databases (http://www.hellenicderma\ntlas.com/en and http://www.danderm.dk/atlas), after obtaining\npermission from them, as well as images from dermatologists in\nIndia. Of these, 310 images were discarded during the\npreprocessing stage due to poor resolution or multiple lesions.\nOut of the remaining 17 408 images, 1990 images belonged to\nthe non-speciﬁc category and 15 418 images were within the 40\nselected disease categories (Table 1). These images were split\ninto ﬁve equal parts (folds) and ﬁve iterations of training and\nvalidation were performed in a manner so that within each itera-\ntion, a different fold of the data was held-out for validation while\nthe remaining fourfolds were used for learning. The training\nimages were 12 350 and testing images were 3068. Since the\ndataset was imbalanced, a custom modiﬁed version of the\nweighted focal loss function was used to train the network. The\nweights for each class were calculated using the inverse sample\nsize method. Our test images were either in-distribution images\ni.e. images within 40 training classes or out-of-distribution sets\nthat we named as non-speciﬁc set.\nWe initially used Inception-v4, which was one of the most\npopular CNN models at the time. For 10 diseases, a sensitivity of\naround 85% was achieved, but for the 20-disease class model,\nthis fell to around 65%. We experimented with many parameters\nlike learning rate and choice of optimizer etc. with no signiﬁcant\nimprovements. It was felt that as the architectures became dee-\nper, there could be problems related to over-ﬁtting. According\nto Huanget al.,convolutional networks can be substantially dee-\nper, more accurate and efﬁcient to train if they contain shorter\nconnections between layers close to the input and those close to\nthe output.\n17 Their implementation of this architecture is called\nDenseNet. In this architecture, to ensure maximum information\nﬂow between layers, each layer obtains additional inputs from all\npreceding layers and passes on its own feature-maps to all subse-\nquent layers.\n17 We found that the DenseNet architecture pro-\nvided better results than the other contemporary architectures\nsuch as Inception-Resnet-V2, Resnets-50, Resnet-101 and Res-\nnet-152. We tried several DenseNet variants",
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,",
        " to calculate the true positive rate (same as\nsensitivity) and the false-positive rate (1 – speciﬁcity). ROC\ncurve was the plot of the true positive rate versus the false-\npositive rate.\nClinical validation study\nWe tested our mobile app against dermatologists’ diagnosis in\nthree different clinical settings, namely, at a tertiary care centre\nData \ncollection\nAlgorithm \nfinetuning & \nvalidation\nApp \ndevelopment\nClinical \nvalidation of \nApp\nPublic database of annotated images for \n40 skin diseases + normal skin + nonspecific\nN = 9,203\nPrivate data classified by board certified \ndermatologists\nN = 8,205\nCNN training images N =12,350\nCNN testing images N =3,068\n(1990 nonspecific images not included)\nComparison of model diagnosis against \npredetermined classification\n15,418 images used for training of model to \ngenerate smartphone app\nApp tested by physicians and compared with \ndermatologists’ diagnosis. N = 5,014 \nDetermination of app’s overall sensitivity and \ndisease-specific sensitivity, specificity, PPV, \nNPV and AUC values\nApp testing on rural primary-care patients\nN = 932\nApp testing on urban, private clinic patients\nN = 383\nApp testing on urban tertiary hospital patients\nN = 3,699\nFigure 1 This ﬂowchart depicts the different steps in data collection, algorithm generation, algorithm testing, app generation and app\nvalidation in clinical studies.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 539\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosaceaMelasma\nAcne\nVitiligo/Leucoderma\nTinea pedis\nAnogenital wartsKeratoacanthoma\nMolluscum contagiosumHidradenitis suppurativa\nHerpes zosterTinea capitis\nImpetigo and Pyodermas\nAlopecia\nMilia\nBasal cell carcinoma\nMelanoma\nMelanocytic nevi/Mole\nIchthyosis\nPityriasis r\nosea\nActin\nic keratosis\nTinea cruris  corporis or faciei\nKeloid/Hype\nrtrophic scar\nSeborrheic\n keratosis\nFixed d\nrug eruption\nLichen sclerosus et atrophicus\nCh\nicken pox\nTinea ma\nnuum\nLichen planus\nUrticaria\nPityriasis ve\nrsicolorPsoriasis\nPe\nmphigus\nCandid\niasis\nBowens disease\nViral warts\nSquamous cell c\narcino\nma\nBullous pe\nmphigoidEcze\nma\nDis\ncoid lupus erythematosus\nPercentage\nSensitivity\nSpecificity\nPPV\nNPV\nSensitivity and specificity of five fold validation data(a)\n(b)\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosacea\nKeloid/Hypertrophic scar\nFixed drug eruption\nHerpes zoster\nVitiligo/Leucoderma\nIchthyosis\nHidradenitis suppurativa\nMelasma\nKeratoacanthoma\n"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2552
    },
    {
      "id": "Q13",
      "question": "Which type of explainability techniques are used?",
      "answer": "Unknown from this paper",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        3,
        14,
        4
      ],
      "chunks_str": [
        " could be problems related to over-ﬁtting. According\nto Huanget al.,convolutional networks can be substantially dee-\nper, more accurate and efﬁcient to train if they contain shorter\nconnections between layers close to the input and those close to\nthe output.\n17 Their implementation of this architecture is called\nDenseNet. In this architecture, to ensure maximum information\nﬂow between layers, each layer obtains additional inputs from all\npreceding layers and passes on its own feature-maps to all subse-\nquent layers.\n17 We found that the DenseNet architecture pro-\nvided better results than the other contemporary architectures\nsuch as Inception-Resnet-V2, Resnets-50, Resnet-101 and Res-\nnet-152. We tried several DenseNet variants such as Densenet-\n169, Densenet-121, Densenet-161 and densenet-201, but selected\nDensenet-161 as it achieved the best balance of sensitivity versus\nspeciﬁcity for the 40 disease classes. In future, as the disease list\nexpands and as newer CNN architectures evolve, this search for\nan optimal model will need to be revisited.\nOur optimizations included three stages. In the preprocessing\nstage, via iterative experiments, we identiﬁed a set of speciﬁc\nimage processing and augmentation algorithms that improve the\noverall model performance. We determined that for skin lesions\nrandom image crop selection within a targeted area range, slight\ncolour balance adjustment, image ﬂips (vertical and horizontal)\nand 90° rotations lead to an improvement in results. Few algo-\nrithms like heavy colour balance adjustment, random rotations\nlead to no improvements or even slight degradation in perfor-\nmance. We also did several experiments with normalization\nalgorithms and selected the best performing Gaussian normal-\nization algorithm on our dataset. In the postprocessing stage for\nprediction, we used several copies of the same model to generate\nthe ﬁnal prediction. The raw outputs from each of the model\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 537\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\ncopies were then combined to generate ﬁnal predictions. We\nadditionally made custom changes in the loss function. Focal\nloss is used for multi-class classiﬁcation whereas log loss for bin-\nary classiﬁcation. We implemented a new loss function that led\nto better results from either of them individually. Our custom\nloss function is a hybrid implementation of focal loss and log\nloss.\n18,19 We also accounted for class imbalances. The mathemat-\nical expression of the loss function used by us is described\nbelow.\nFLðp\ntÞ¼/C0 αt ð1 /C0 ptÞγlogðptÞ\nLLðpÞ¼/C0 ð ylogðpÞþð 1 /C0 yÞlogð1 /C0 pÞÞ\nFCLðptÞ¼/C0 αtðytð1 /C0 ptÞγlogðptÞþð 1 /C0 ytÞpγ\nt logð1 /C0 ptÞÞ\nFL = Focal loss; LL = Log Loss; FCL = Our loss function\nimplementation.\nTable 1 shows number of images and diagnostic parameters fromﬁvefold algorithm",
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,",
        " imbalances. The mathemat-\nical expression of the loss function used by us is described\nbelow.\nFLðp\ntÞ¼/C0 αt ð1 /C0 ptÞγlogðptÞ\nLLðpÞ¼/C0 ð ylogðpÞþð 1 /C0 yÞlogð1 /C0 pÞÞ\nFCLðptÞ¼/C0 αtðytð1 /C0 ptÞγlogðptÞþð 1 /C0 ytÞpγ\nt logð1 /C0 ptÞÞ\nFL = Focal loss; LL = Log Loss; FCL = Our loss function\nimplementation.\nTable 1 shows number of images and diagnostic parameters fromﬁvefold algorithmic validation of 41 skin conditions\nS.S Disease class N, Private N, Public AUC-model Sensitivity Speci ﬁcity PPV NPV\n1 Acne 337 240 0.98 86.23 /C6 3.26 99.56 /C6 0.13 86.32 /C6 4.22 99.46 /C6 0.19\n2 Actinic keratosis 249 372 0.97 76.49 /C6 3.25 99.04 /C6 0.22 82.83 /C6 3.72 98.85 /C6 0.19\n3 Alopecia 109 152 0.97 78.38 /C6 6.25 99.74 /C6 0.09 86.60 /C6 5.39 99.65 /C6 0.08\n4 Anogenital warts 86 96 0.95 80.22 /C6 1.96 99.92 /C6 0.04 85.69 /C6 6.51 99.73 /C6 0.10\n5 Basal cell carcinoma 365 506 0.97 77.77 /C6 3.58 99.10 /C6 0.13 83.89 /C6 1.09 98.50 /C6 0.27\n6 Bowen ’s disease 130 179 0.92 61.31 /C6 10.78 99.60 /C6 0.14 79.31 /C6 8.58 99.06 /C6 0.11\n7 Bullous pemphigoid 54 92 0.91 58.22 /C6 13.60 99.90 /C6 0.05 82.86 /C6 8.45 99.60 /C6 0.14\n8 Candidiasis 118 187 0.94 65.24 /C6 6.39 99.54 /C6 0.13 77.47 /C6 4.65 99.35 /C6 0.11\n9 Chicken pox 77 108 0.94 72.43 /C6 6.99 99.77 /C6 0.07 80.94 /C6 9.67 99.59 /C6 0.12\n10 Discoid lupus erythematosus 85 134 0.89 49.78 /C6 6.70 99.83 /C6 0.07 73.06 /C6 6.84 99.36 /C6 0.07\n11 Eczema 560 336 0.92 57.52 /C6 3.37 99.00 /"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2530
    },
    {
      "id": "Q14",
      "question": "Which evaluation metrics or outcome measures are used to assess the predictive models?",
      "answer": "accuracy, AUC, sensitivity, specificity, PPV, NPV",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        14,
        9,
        2
      ],
      "chunks_str": [
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,",
        " to calculate the true positive rate (same as\nsensitivity) and the false-positive rate (1 – speciﬁcity). ROC\ncurve was the plot of the true positive rate versus the false-\npositive rate.\nClinical validation study\nWe tested our mobile app against dermatologists’ diagnosis in\nthree different clinical settings, namely, at a tertiary care centre\nData \ncollection\nAlgorithm \nfinetuning & \nvalidation\nApp \ndevelopment\nClinical \nvalidation of \nApp\nPublic database of annotated images for \n40 skin diseases + normal skin + nonspecific\nN = 9,203\nPrivate data classified by board certified \ndermatologists\nN = 8,205\nCNN training images N =12,350\nCNN testing images N =3,068\n(1990 nonspecific images not included)\nComparison of model diagnosis against \npredetermined classification\n15,418 images used for training of model to \ngenerate smartphone app\nApp tested by physicians and compared with \ndermatologists’ diagnosis. N = 5,014 \nDetermination of app’s overall sensitivity and \ndisease-specific sensitivity, specificity, PPV, \nNPV and AUC values\nApp testing on rural primary-care patients\nN = 932\nApp testing on urban, private clinic patients\nN = 383\nApp testing on urban tertiary hospital patients\nN = 3,699\nFigure 1 This ﬂowchart depicts the different steps in data collection, algorithm generation, algorithm testing, app generation and app\nvalidation in clinical studies.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 539\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosaceaMelasma\nAcne\nVitiligo/Leucoderma\nTinea pedis\nAnogenital wartsKeratoacanthoma\nMolluscum contagiosumHidradenitis suppurativa\nHerpes zosterTinea capitis\nImpetigo and Pyodermas\nAlopecia\nMilia\nBasal cell carcinoma\nMelanoma\nMelanocytic nevi/Mole\nIchthyosis\nPityriasis r\nosea\nActin\nic keratosis\nTinea cruris  corporis or faciei\nKeloid/Hype\nrtrophic scar\nSeborrheic\n keratosis\nFixed d\nrug eruption\nLichen sclerosus et atrophicus\nCh\nicken pox\nTinea ma\nnuum\nLichen planus\nUrticaria\nPityriasis ve\nrsicolorPsoriasis\nPe\nmphigus\nCandid\niasis\nBowens disease\nViral warts\nSquamous cell c\narcino\nma\nBullous pe\nmphigoidEcze\nma\nDis\ncoid lupus erythematosus\nPercentage\nSensitivity\nSpecificity\nPPV\nNPV\nSensitivity and specificity of five fold validation data(a)\n(b)\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosacea\nKeloid/Hypertrophic scar\nFixed drug eruption\nHerpes zoster\nVitiligo/Leucoderma\nIchthyosis\nHidradenitis suppurativa\nMelasma\nKeratoacanthoma\n",
        " validation studies of AI-\nbased algorithms related to dermatology in clinical settings.\nMaterial and methods\nThe study aimed to develop a convolutional neural network\n(CNN)-based algorithm trained with clinical images of 40 differ-\nent skin diseases. A user-friendly, smartphone app was also gen-\nerated, and a clinical validation study on 5014 patients was done\nby physicians in urban, rural primary care and tertiary care set-\ntings. The app’s analysis of a single image of the lesion was com-\npared to the consensus diagnosis made by two board-certiﬁed\ndermatologists. Only patients, for whom the treating board-cer-\ntiﬁed dermatologist was conﬁdent of the diagnosis and the diag-\nnosis was cross-veriﬁed by another board-certiﬁed\ndermatologist, were included. If there was no consensus then the\npatient was excluded from the study.\nGeneration of the CNN-based algorithm\nThe CNN architecture used was a modiﬁed version of Densenet-\n161 with optimized augmentation and inference pipelines.\n16\nThese optimizations were derived through rigorous experiments\nand were attuned to clinical skin images. All training and testing\nimages were annotated and segmented so a bounding box sur-\nrounded lesion of interest and irrelevant features such as rulers\nand surgical markings were discarded. The 17 718 raw images\nwere sourced from public databases (http://www.hellenicderma\ntlas.com/en and http://www.danderm.dk/atlas), after obtaining\npermission from them, as well as images from dermatologists in\nIndia. Of these, 310 images were discarded during the\npreprocessing stage due to poor resolution or multiple lesions.\nOut of the remaining 17 408 images, 1990 images belonged to\nthe non-speciﬁc category and 15 418 images were within the 40\nselected disease categories (Table 1). These images were split\ninto ﬁve equal parts (folds) and ﬁve iterations of training and\nvalidation were performed in a manner so that within each itera-\ntion, a different fold of the data was held-out for validation while\nthe remaining fourfolds were used for learning. The training\nimages were 12 350 and testing images were 3068. Since the\ndataset was imbalanced, a custom modiﬁed version of the\nweighted focal loss function was used to train the network. The\nweights for each class were calculated using the inverse sample\nsize method. Our test images were either in-distribution images\ni.e. images within 40 training classes or out-of-distribution sets\nthat we named as non-speciﬁc set.\nWe initially used Inception-v4, which was one of the most\npopular CNN models at the time. For 10 diseases, a sensitivity of\naround 85% was achieved, but for the 20-disease class model,\nthis fell to around 65%. We experimented with many parameters\nlike learning rate and choice of optimizer etc. with no signiﬁcant\nimprovements. It was felt that as the architectures became dee-\nper, there could be problems related to over-ﬁtting. According\nto Huanget al.,convolutional networks can be substantially dee-\nper, more accurate and efﬁcient to train if they contain shorter\nconnections between layers close to the input and those close to\nthe output.\n17 Their implementation of this architecture is called\nDenseNet. In this architecture, to ensure maximum information\nﬂow between layers, each layer obtains additional inputs from all\npreceding layers and passes on its own feature-maps to all subse-\nquent layers.\n17 We found that the DenseNet architecture pro-\nvided better results than the other contemporary architectures\nsuch as Inception-Resnet-V2, Resnets-50, Resnet-101 and Res-\nnet-152. We tried several DenseNet variants"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2553
    },
    {
      "id": "Q15",
      "question": "What considerations were given to selected evaluation metrics or outcome measures in this study?",
      "answer": "Accuracy, AUC, sensitivity, specificity, PPV, NPV.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        14,
        6,
        11
      ],
      "chunks_str": [
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,",
        " 78.96 /C6 8.07 99.31 /C6 0.09\n20 Lichen sclerosus 83 137 0.93 73.18 /C6 8.41 99.88 /C6 0.08 87.50 /C6 7.48 99.68 /C6 0.10\n21 Melanocytic nevi /Mole 153 134 0.95 77.02 /C6 8.37 99.73 /C6 0.11 84.78 /C6 6.35 99.65 /C6 0.12\n22 Melanoma 99 211 0.95 77.74 /C6 2.10 99.81 /C6 0.08 82.41 /C6 3.91 99.45 /C6 0.09\n23 Melasma 88 77 0.99 87.50 /C6 6.25 99.78 /C6 0.08 88.00 /C6 6.43 99.94 /C6 0.06\n24 Milia 52 60 0.94 77.86 /C6 12.92 99.95 /C6 0.02 85.43 /C6 10.1 99.75 /C6 0.10\n25 Molluscum contagiosum 48 234 0.97 79.75 /C6 7.72 99.81 /C6 0.08 85.41 /C6 4.63 99.58 /C6 0.13\n26 Pemphigus 99 137 0.94 66.51 /C6 1.96 99.76 /C6 0.07 80.81 /C6 4.33 99.59 /C6 0.07\n27 Pityriasis rosea 95 155 0.95 76.80 /C6 5.21 99.75 /C6 0.08 82.42 /C6 4.68 99.61 /C6 0.06\n28 Pityriasis versicolour 67 108 0.95 69.71 /C6 5.92 99.83 /C6 0.07 83.51 /C6 5.90 99.64 /C6 0.07\n29 Psoriasis 452 421 0.94 68.00 /C6 5.06 99.18 /C6 0.13 80.40 /C6 6.34 98.41 /C6 0.20\n30 Rosacea 184 255 0.98 90.17 /C6 4.40 99.62 /C6 0.13 92.44 /C6 2.47 99.70- /C6 0.06\n31 Seborrhoeic keratosis 211 238 0.97 74.39 /C6 3.92 99.39 /C6 0.17 86.66 /C6 3.35 99.47 /C6 0.16\n32 Squamous cell carcinoma 157 212 0.92 58.29 /C6 4.65 99.41 /C6 0.08 75.74 /C6 5.82 99.03 /C6 0.06\n33 Tinea capitis 4 153 0.96 79.",
        " diversity in the patient populations that\nconsult physicians in urban versus rural areas. The study was\napproved by the Ethics Committee of All India Institute of Med-\nical Sciences. We included consecutive patients presenting to a\nparticular investigator in the Outpatient Department, where the\ndermatologists were conﬁdent of the diagnosis, either by clinical\nexamination, laboratory investigation, and/or histopathological\nexamination. Dermatologists were blinded to the app results. A\nsingle representative image from each patient was tested on the\napp by a separate physician.\nResults\nThe overall scheme for this study is outlined in Figure 1.\nTable 2 shows th number of patients, AUC, Top‐1/Top‐3 sensitivity, speciﬁcity, positive predictive and negative predictive values for\ncombined clinical data from three different clinical settings.\nS.no. Disease class Number\nof patients\nAUC-\nclinic\nTop-1 sensitivity\n% (CI)\nTop-3\nsensitivity %\nTop-1\nspeciﬁcity %\nTop-1 PPV Top-1 NPV\n1 Acne 592 0.98 89.86 (87.15 –92.18) 97.97 98.19 86.92 98.64\n2 Alopecia 184 0.97 88.11 (82.55 –92.36) 96.22 99.28 82.32 99.54\n3 Anogenital warts 34 0.85 57.14 (39.35 –73.68) 71.43 99.70 57.14 99.70\n4 Basal cell carcinoma 123 0.98 93.55 (87.68 –97.17) 97.58 98.51 61.38 99.83\n5 Bowen ’s disease 11 0.77 45.45 (16.75 –76.62) 54.54 99.90 50.00 99.88\n6 Bullous pemphigoid 16 0.73 35.29 (14.21 –61.67) 47.06 100.00 100.00 99.78\n7 Candidiasis 16 0.81 41.18 (18.44 –67.10) 64.71 99.80 41.18 99.80\n8 Discoid lupus\nerythematosus\n47 0.90 60.42 (45.27 –74.23) 83.33 99.20 42.03 99.61\n9 Eczema 432 0.87 54.29 (49.46 –59.10) 81.90 97.58 67.83 95.78\n10 Fixed drug eruption 12 0.87 41.67 (15.16 –72.33) 75.00 99.70 25.00 99.86\n11 Herpes zoster 38 0.89 66.67 (49.78 –80.91) 79.49 99.60 56.52 99.74\n12 Hidradenitis suppurativa 32 0.97 93.94(79.78 –99.26) 93.94 99.62 62.00 99.96\n13 Ichthyosis 21 0.93 81.81 (59.72 –94.81) 86.36 99.78 62.07 99.92\n14 Impetigo and Pyodermas 109 0.89 57.27 (47.48 –66.66) 82.72 99.04 57.27 99.04\n15"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2546
    },
    {
      "id": "Q16",
      "question": "How were robustness, confidence or statistical significance of the results assessed in this study?",
      "answer": "AUC, accuracy, specificity, sensitivity, PPV, NPV.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        14,
        9,
        15
      ],
      "chunks_str": [
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,",
        " to calculate the true positive rate (same as\nsensitivity) and the false-positive rate (1 – speciﬁcity). ROC\ncurve was the plot of the true positive rate versus the false-\npositive rate.\nClinical validation study\nWe tested our mobile app against dermatologists’ diagnosis in\nthree different clinical settings, namely, at a tertiary care centre\nData \ncollection\nAlgorithm \nfinetuning & \nvalidation\nApp \ndevelopment\nClinical \nvalidation of \nApp\nPublic database of annotated images for \n40 skin diseases + normal skin + nonspecific\nN = 9,203\nPrivate data classified by board certified \ndermatologists\nN = 8,205\nCNN training images N =12,350\nCNN testing images N =3,068\n(1990 nonspecific images not included)\nComparison of model diagnosis against \npredetermined classification\n15,418 images used for training of model to \ngenerate smartphone app\nApp tested by physicians and compared with \ndermatologists’ diagnosis. N = 5,014 \nDetermination of app’s overall sensitivity and \ndisease-specific sensitivity, specificity, PPV, \nNPV and AUC values\nApp testing on rural primary-care patients\nN = 932\nApp testing on urban, private clinic patients\nN = 383\nApp testing on urban tertiary hospital patients\nN = 3,699\nFigure 1 This ﬂowchart depicts the different steps in data collection, algorithm generation, algorithm testing, app generation and app\nvalidation in clinical studies.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 539\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosaceaMelasma\nAcne\nVitiligo/Leucoderma\nTinea pedis\nAnogenital wartsKeratoacanthoma\nMolluscum contagiosumHidradenitis suppurativa\nHerpes zosterTinea capitis\nImpetigo and Pyodermas\nAlopecia\nMilia\nBasal cell carcinoma\nMelanoma\nMelanocytic nevi/Mole\nIchthyosis\nPityriasis r\nosea\nActin\nic keratosis\nTinea cruris  corporis or faciei\nKeloid/Hype\nrtrophic scar\nSeborrheic\n keratosis\nFixed d\nrug eruption\nLichen sclerosus et atrophicus\nCh\nicken pox\nTinea ma\nnuum\nLichen planus\nUrticaria\nPityriasis ve\nrsicolorPsoriasis\nPe\nmphigus\nCandid\niasis\nBowens disease\nViral warts\nSquamous cell c\narcino\nma\nBullous pe\nmphigoidEcze\nma\nDis\ncoid lupus erythematosus\nPercentage\nSensitivity\nSpecificity\nPPV\nNPV\nSensitivity and specificity of five fold validation data(a)\n(b)\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosacea\nKeloid/Hypertrophic scar\nFixed drug eruption\nHerpes zoster\nVitiligo/Leucoderma\nIchthyosis\nHidradenitis suppurativa\nMelasma\nKeratoacanthoma\n",
        " as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation, mainly for skin cancers. However, only\na few researchers have used clinical/macroscopic images for mul-\nti-class skin disease identiﬁcation, representative of a real-world\nclinical scenario. In a study by Estevaet al., CNN performedat\npar with dermatologists for classiﬁcation of 9 skin disease cate-\ngories, skin cancers and their precursors, using clinical images\nwith an accuracy of 55.4%.\n22 Mendes et al. generated a CNN\nclassiﬁcation model for 12 skin cancers and related benign and\npremalignant skin conditions and achieved a total accuracy of\n78%.\n23 Han et al. reported a mean AUC of 0.91 and top-1 accu-\nracy between~55–57% on the same set of 12 diseases and, inter-\nestingly, found a substantial difference in speciﬁcities of skin\ncancer between an Asian skin dataset and Caucasian skin data-\nset.\n24 More recently, Liuet al. developed a deep learning system\n76.55\n90.51\n80.33\n94.33\n74.9\n89.22\n75.07\n89.62\n0\n25\n50\n75\n100\nUrban private\npractice\nRural Tertiary\nCombined\nClinical setting\nAccuracy\nTop_1_accuracy\nTop_3_accuracy\n(a)\n(b)\nFigure 3 (a) Overall Top-1 and Top-3 accuracies from clinical vali-\ndation of app in a private urban clinicN = 383), rural hospital\n(N = 932), tertiary hospital (N = 3699) and combined data\n(N = 5014). (b) Disease-speciﬁc Top-1 sensitivities, Top-3 sensitiv-\nities and Top-1 speciﬁcities. The length of the dotted line depicts\nan increase in sensitivity betweenﬁrst and third predictions of the\napp. The size of the icons depicts the number of patients for that\ndisease class.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\n542 Pangti et al.\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nFigure 4 (a) Confusion matrix from the top-1 prediction of clinical data by the app. The numbers in each row are normalized to 100. The\nactual patient numbers for each disease class are shown in parenthesis. The actual labels are depicted on the y-axis and predicted labels\nare on the x-axis. (b) Confusion matrix from the top-3 prediction of clinical data by the app. The numbers in each row are normalized to\n100."
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2541
    },
    {
      "id": "Q17",
      "question": "What limitations of the study were discussed?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        11,
        16,
        4
      ],
      "chunks_str": [
        " diversity in the patient populations that\nconsult physicians in urban versus rural areas. The study was\napproved by the Ethics Committee of All India Institute of Med-\nical Sciences. We included consecutive patients presenting to a\nparticular investigator in the Outpatient Department, where the\ndermatologists were conﬁdent of the diagnosis, either by clinical\nexamination, laboratory investigation, and/or histopathological\nexamination. Dermatologists were blinded to the app results. A\nsingle representative image from each patient was tested on the\napp by a separate physician.\nResults\nThe overall scheme for this study is outlined in Figure 1.\nTable 2 shows th number of patients, AUC, Top‐1/Top‐3 sensitivity, speciﬁcity, positive predictive and negative predictive values for\ncombined clinical data from three different clinical settings.\nS.no. Disease class Number\nof patients\nAUC-\nclinic\nTop-1 sensitivity\n% (CI)\nTop-3\nsensitivity %\nTop-1\nspeciﬁcity %\nTop-1 PPV Top-1 NPV\n1 Acne 592 0.98 89.86 (87.15 –92.18) 97.97 98.19 86.92 98.64\n2 Alopecia 184 0.97 88.11 (82.55 –92.36) 96.22 99.28 82.32 99.54\n3 Anogenital warts 34 0.85 57.14 (39.35 –73.68) 71.43 99.70 57.14 99.70\n4 Basal cell carcinoma 123 0.98 93.55 (87.68 –97.17) 97.58 98.51 61.38 99.83\n5 Bowen ’s disease 11 0.77 45.45 (16.75 –76.62) 54.54 99.90 50.00 99.88\n6 Bullous pemphigoid 16 0.73 35.29 (14.21 –61.67) 47.06 100.00 100.00 99.78\n7 Candidiasis 16 0.81 41.18 (18.44 –67.10) 64.71 99.80 41.18 99.80\n8 Discoid lupus\nerythematosus\n47 0.90 60.42 (45.27 –74.23) 83.33 99.20 42.03 99.61\n9 Eczema 432 0.87 54.29 (49.46 –59.10) 81.90 97.58 67.83 95.78\n10 Fixed drug eruption 12 0.87 41.67 (15.16 –72.33) 75.00 99.70 25.00 99.86\n11 Herpes zoster 38 0.89 66.67 (49.78 –80.91) 79.49 99.60 56.52 99.74\n12 Hidradenitis suppurativa 32 0.97 93.94(79.78 –99.26) 93.94 99.62 62.00 99.96\n13 Ichthyosis 21 0.93 81.81 (59.72 –94.81) 86.36 99.78 62.07 99.92\n14 Impetigo and Pyodermas 109 0.89 57.27 (47.48 –66.66) 82.72 99.04 57.27 99.04\n15",
        "/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nFigure 4 (a) Confusion matrix from the top-1 prediction of clinical data by the app. The numbers in each row are normalized to 100. The\nactual patient numbers for each disease class are shown in parenthesis. The actual labels are depicted on the y-axis and predicted labels\nare on the x-axis. (b) Confusion matrix from the top-3 prediction of clinical data by the app. The numbers in each row are normalized to\n100. The actual patient numbers for each disease class are shown in parenthesis.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 543\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nto diagnose 26 common skin conditions from clinical images\nplus associated medical histories.25 During validation, Liuet al\nachieved a 71% top-1 accuracy and their algorithm surpassed\ndermatologists, PCPs and nurse practitioners in a clinical data-\nset.\n25 Our Top-1 accuracy was 77% and the mean AUC was 0.95\nfor algorithmic validation of 40 diseases.\nThere are no precedents for studies in which an AI-based, skin\ndisease diagnosis app has been tested in clinical settings. In our\nwork, a top-1 accuracy of 75% and a top-3 accuracy of 90% was\nachieved by the app for 35 skin diseases and was largely similar to\nour model validation results. Some differences in diagnostic per-\nformance (in terms of disease AUCs) between model and app\nwere noted and may be attributable to either fewer clinical valida-\ntion images for some diseases like Bowen’s disease, anogenital\nwarts, tinea pedis, rosacea, candidiasis, herpes zoster (Fig. 4a and\nSupplementary Figure S1) and/or differences in disease morphol-\nogy between white and pigmented skin. Eczema is a broad disease\ncategory, incorporating diseases with varied morphology such as\nlichen simplex chronicus, atopic dermatitis, nummular eczema\nand contact dermatitis. Training of the model with speciﬁc dis-\nease classes rather than a broad category of eczema may improve\nsensitivity. As shown in the confusion matrix, eczema was often\nconfused with psoriasis, lichen planus and tinea corporis, cruris\nor faciei (Figs 4a, b). To some extent, this mirrors the diagnostic\nconfusion faced by many physicians as well.\n2,25,26 A few melano-\ncytic nevi lesions were mistaken for BCC possibly because of their\nresemblance with pigmented BCC, which is more commonly seen\nin skin of colour. Besides, it was observed that diseases with dis-\ntinct morphology and predilection for certain sites (in a similar\nrecognizable background) such as melasma and tinea unguium\nhad better accuracies.\nIn this study, we found a high top-3 sensitivity for BCC\n(97.58%, n = 124) and SCC (92.86%,n = 14",
        " imbalances. The mathemat-\nical expression of the loss function used by us is described\nbelow.\nFLðp\ntÞ¼/C0 αt ð1 /C0 ptÞγlogðptÞ\nLLðpÞ¼/C0 ð ylogðpÞþð 1 /C0 yÞlogð1 /C0 pÞÞ\nFCLðptÞ¼/C0 αtðytð1 /C0 ptÞγlogðptÞþð 1 /C0 ytÞpγ\nt logð1 /C0 ptÞÞ\nFL = Focal loss; LL = Log Loss; FCL = Our loss function\nimplementation.\nTable 1 shows number of images and diagnostic parameters fromﬁvefold algorithmic validation of 41 skin conditions\nS.S Disease class N, Private N, Public AUC-model Sensitivity Speci ﬁcity PPV NPV\n1 Acne 337 240 0.98 86.23 /C6 3.26 99.56 /C6 0.13 86.32 /C6 4.22 99.46 /C6 0.19\n2 Actinic keratosis 249 372 0.97 76.49 /C6 3.25 99.04 /C6 0.22 82.83 /C6 3.72 98.85 /C6 0.19\n3 Alopecia 109 152 0.97 78.38 /C6 6.25 99.74 /C6 0.09 86.60 /C6 5.39 99.65 /C6 0.08\n4 Anogenital warts 86 96 0.95 80.22 /C6 1.96 99.92 /C6 0.04 85.69 /C6 6.51 99.73 /C6 0.10\n5 Basal cell carcinoma 365 506 0.97 77.77 /C6 3.58 99.10 /C6 0.13 83.89 /C6 1.09 98.50 /C6 0.27\n6 Bowen ’s disease 130 179 0.92 61.31 /C6 10.78 99.60 /C6 0.14 79.31 /C6 8.58 99.06 /C6 0.11\n7 Bullous pemphigoid 54 92 0.91 58.22 /C6 13.60 99.90 /C6 0.05 82.86 /C6 8.45 99.60 /C6 0.14\n8 Candidiasis 118 187 0.94 65.24 /C6 6.39 99.54 /C6 0.13 77.47 /C6 4.65 99.35 /C6 0.11\n9 Chicken pox 77 108 0.94 72.43 /C6 6.99 99.77 /C6 0.07 80.94 /C6 9.67 99.59 /C6 0.12\n10 Discoid lupus erythematosus 85 134 0.89 49.78 /C6 6.70 99.83 /C6 0.07 73.06 /C6 6.84 99.36 /C6 0.07\n11 Eczema 560 336 0.92 57.52 /C6 3.37 99.00 /"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2540
    }
  ]
}