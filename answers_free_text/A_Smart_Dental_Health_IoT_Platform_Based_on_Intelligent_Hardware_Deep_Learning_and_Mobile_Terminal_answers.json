{
  "paper": "A Smart Dental Health-IoT Platform Based on Intelligent Hardware, Deep Learning, and Mobile Terminal.pdf",
  "answers": [
    {
      "id": "Q1",
      "question": "Is the aim of this study to predict future events (prognostic) or current disease status (diagnostic)?",
      "answer": "Diagnostic.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        7,
        12,
        3
      ],
      "chunks_str": [
        "3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through articial selection, along with the possible adding of\nthe undetected target images. The nished data is applied as the\ntraining sample data for the detection and classication of dental\ndiseases, ending up with the summary of the recorded frame\nimages to establish the dental training sample set.\nC. Model Training\nCommon target detection algorithms including RCNN,\nYOLO, SSD [19] only classify the target in the image. However,\nthe accurate target segmentation is benecial to the auxiliary med-\nical diagnosis, to achieve the aim of fast and accurate detection\nof dental diseases and dental area accurate segmentation. Based\non the established dental sample library, the MASK R-CNN\nmethod is chosen for the accurate detection and segmentation\nof the dental target.\nThe designed MASK R-CNN network is shown in the left\nof Fig. 6 , in which, MASK R-CNN adds a branch predicting\nthe segmentation mask in each interested area based on Faster\nR-CNN [20]. In Faster R-CNN, region of interest (RoI) pool\nis used to extract the small features from each RoI. Firstly,\nRoIPool scales the RoI represented by oating point numbers to\nFig. 7. Left: MASK R-CNN network. Right: example detections using\nMASK R-CNN on dental images test.\nthe granularity matching the feature graph, followed by parti-\ntioning of the scaled ROI, ending up with the summary of the\ncharacteristic value of each block coverage area. Such calcula-\ntions misplace the ROI and the extracted features, which, though\npossibly not affecting the classication, for the classication has\nthe certain robustness to the small amplitude transformation,\nexerts a great negative impact on the prediction of the precise\nmask of pixel level. Mask R-CNN proposes the RoI Align layer\nto remove the dislocation of RoIPool and aligns the extracted\nfeatures with the input accurately. In RoI Align, a bilinear in-\nterpolation is used to calculate the exact value of each position,\nalong with the summary of the results by using the maximum\nor average pooling, and the extracted features and input can be\naligned with the pixel to pixel, thereby improving the segmen-\ntation accuracy effectively. For the lower convolution network\nused for feature extraction on the whole image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN AN",
        "iﬁcant impact on the anal-\nysis of artiﬁcial intelligence. Therefore, the future work will\ngive more priority to the improvement of the hardware design\nand the efﬁciency of image acquisition device, and further work\nwill focus on improving algorithm efﬁciency and recognition\nrate, reducing false alarm rate, and setting up a larger image\ndata set for dental diseases.\nV. C ONCLUSION\nThis paper proposes an iHome smart dental Health-IoT sys-\ntem based on intelligent hardware, deep learning and mobile\nterminal, aiming to regulate as well as optimize the accessibil-\nity of dental treatment and provide home-based dental health\ncare service more efciently. The trained model was used to\nrealize the detection and classication of dental diseases, and\napplication software (Apps) on mobile terminal was designed\nfor client-side and dentist-side. The software platform with the\nfunctions including pre-examination of dental disease, consulta-\ntion, appointment, and evaluation, etc, made the service docking\nbetween the patient and the dentist resources a reality. The AI\nalgorithm achieved more than 90% recognition rate for seven\ndental diseases., which has greatly improved the patient rate and\nthe resource utilization rate of the dental clinic through a one-\nmonth systematic testing in 10 private dental clinics, showing\nhigh reliability in practical application.\nREFERENCES\n[1] Z. Qian, “Opportunities abound for dental care in China,” China\nBrieﬁng, Feb. 2015. [Online]. Available: http://www.china-brieﬁng.com/\nnews/2015/02/27/opportunities-abound-dental-care-china.html\n[2] P . J. Pussinen, P . Jousilahti, G. Alfthan, T. Palosuo, S. Asikainen, and V .\nSalomaa, “Antibodies to periodontal pathogens are associated with coro-\nnary heart disease,” Arteriosclerosis Thrombosis V ascular Biol. , vol. 23,\nno. 7, 2003, pp. 1250–1254.\n[3] H. Jansson et al. , “Type 2 diabetes and risk for periodontal disease: A\nrole for dental health awareness,” J. Clinical Periodontol. , vol. 33, no. 6,\npp. 408–414, 2006.\n[4] N. W. Johnson, “The mouth in HIV/AIDS: Markers of disease status and\nmanagement challenges for the dental profession,” Australian Dental J. ,\nvol. 55, no. s1, pp. 85–102, 2010.\n[5] L. Atzori, A. Iera, and G. Morabito, The Internet of Things: A Survey .\nAmsterdam, The Netherlands: Elsevier, 2010.\n[6] D. Metcalf, S. T. Milliard, M. Gomez, and M. Schwartz, “Wearables and\nthe internet of things for health: Wearable, interconnected devices promise\nmore efﬁcient and comprehensive health care,” IEEE Pulse , vol. 7, no. 5,\npp. 35–39, Sep./Oct. 2016.\n[7] P . Sundaravadivel, E. Kougianos, S. P . Mohanty, and M. K. Ganapathiraju,\n“Everything you wanted to know about smart health care: Evaluating the\ndifferent technologies and components of the internet of things for better\nhealth,” IEEE Consum. Electron. Mag. , vol. 7, no. 1, pp. 18–28, Jan. 2017.\n[8] J. Arevalo, F. A. Gonzalez, R. Ramos-Pollan, J. L.",
        "long-term development of children.\nr Second, the cost of dental treatment is relatively high.\nr Third, dental disease, due to the characteristics of elective\ntreatment, is difﬁcult to get timely treatment.\nBased on what is discussed above, a promising trend in health-\ncare is to move routine medical checks and other healthcare ser-\nvices from hospital (Hospital-Centric) to the home environment\n(Home-centric) [15], through which, the patients can get seam-\nless health care at any time in a comfortable home environment.\nEven more, it can ensure that the overall iHome dental health-\ncare system including three partspersonalized services, dental\nservices and intelligent and interactive service could be opti-\nmized to a large extent. Based on this platform, the closed-loop\nsystem of pre-screening, consultation, appointment, treatment\nand evaluation of dental disease is established, thereby mak-\nFig. 1. The network architecture of the iHome dental health-IoT\nsystem.\ning the rapid and effective relationship between patients and\ndoctors’ resources a reality.\nA. The Architecture of iHome DentalHealth-IoT System\nThe network architecture of the iHome dental health-IoT sys-\ntem is shown in Fig. 1 , which consists of three network layers:\n1) dental medical service layer; 2) smart dental service layer; 3)\ndental image data acquisition layer.\nThe dental medical service layer is directly connected to pro-\nfessional medical facilities such as hospital, dental clinic, regis-\ntered dentist and dental healthcare product supplier.\nThe dental clinics or hospitals equipped with certain quali-\nﬁcations and idle resources can attract customers through their\nown medical technology and price advantage, thereby making\nit possible for them to make an early judgment with the help\nof self-help screening results, and to make a new e-prescription\naccordingly or treatment programs based on that. Additionally,\nbased on the platform, the doctors can not only manage their\npatients, interact with patients and track the effectiveness of\ntreatment effectively, but also identify the patient group whose\nhealth conditions have improved easily, and inform them of their\nprogress, thereby facilitating the building of positive loops of\nrehabilitation and self-care. The dentists can further improve\nservice quality and efﬁciency through patient evaluations.\nThe smart dental service layer is the core layer where data\nprocessing provides the analysis results of dental symptoms or\naesthetic needs, which also serves as an efﬁcient way to meet\nusers’ daily needs in dental health monitoring. This layer has\nthe following three functions:\nr Intelligent diagnosis and treatment recommendation: It\ncan recommend the nearby excellent doctor for those\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n900 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nFig. 2. Application software system diagram.\nconsumers after the AI diagnose, and prompt them to seek\nfor low-price as well as time-saving medical treatment.\nr Group purchase (E-MALL) service: It can classify the cus-\ntomer needs as well as suitable product services and pro-\nmote different group purchase & product services based\non AI diagnosis results.\nr Large data customization service: It can classify the cus-\ntomer needs and provide the customized or personalized\nproducts as well as the services according to AI diagnosis\nresults.\nMainly consisting of dental image data acquisition devices\nand the mobile terminal, local computing, and processing units,\nwireless transmitting modules and display terminal, the dental\nimage data acquisition layer serves as the basis of the entire\nplatform. The dental image data is uploaded to the smart dental\nservice layer via the network (Wi-Fi, 3"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2568
    },
    {
      "id": "Q2",
      "question": "On what basis were eligible participants included in this study (symptoms, previous tests, registry, etc.)?",
      "answer": "consent of subjects with dental diseases",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        6,
        13,
        14
      ],
      "chunks_str": [
        ".\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with the 7 types of dental\ndiseases as follows: dental caries, dental uorosis, periodontal\ndisease, cracked tooth, dental calculus, dental plaque, and tooth\nloss. 4/5 of these data was used in training, while 1/5 of them was\nin model testing, training data set and test data are respectively\nfrom different objects, thus without overlap between the testing\ndataset and the training dataset.\nB. Build Sample Set\nThe semi-automatic labeling method is applied to establish\nthe training sample set to improve the efﬁciency. The dental im-\nages were initially labeled by the design of detector for 7 types\nof dental diseases, as shown in Fig. 5 , the functions of the de-\ntector here include image enhancement, color texture matching,\ncoarse localization and classiﬁcation of disease. Followed by\nthe conﬁrmation of images with labeling error or classiﬁcation\nerror through manual screening method, the training samples\nset were ﬁnally calibrated by 20 dental disease experts, with the\ndetails as follows:\n1) Image Enhancement: In some dental images, the features\nof the tooth disease site without very high contrast are not very\nobvious, thereby making it necessary to enhance the images\nbefore designing the classiﬁcation algorithms. The Retinex al-\ngorithm is used [17], which adaptively prompts various types\nof images to achieve balance in dynamic range, edge, and color.\nThe image enhancement effect in Fig. 6 shows that the color\nand texture details of the dental disease are highlighted after the\nenhancement.\n2) Coarse Localization and Classiﬁcation of Dental Disease\nTarget Area: It is just a preliminary detecting, and only the areas\nclose to the color and texture of the image to be matched will\nbe detected as samples. Firstly, a histogram matching method\nwith fast calculation speed is used to select the region of color\nproximity, followed by the use of the Tamura texture feature\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n902 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through art",
        " interconnected devices promise\nmore efﬁcient and comprehensive health care,” IEEE Pulse , vol. 7, no. 5,\npp. 35–39, Sep./Oct. 2016.\n[7] P . Sundaravadivel, E. Kougianos, S. P . Mohanty, and M. K. Ganapathiraju,\n“Everything you wanted to know about smart health care: Evaluating the\ndifferent technologies and components of the internet of things for better\nhealth,” IEEE Consum. Electron. Mag. , vol. 7, no. 1, pp. 18–28, Jan. 2017.\n[8] J. Arevalo, F. A. Gonzalez, R. Ramos-Pollan, J. L. Oliveira, and M. A.\nGuevara Lopez, “Convolutional neural networks for mammography mass\nlesion classiﬁcation,” in Proc. Conf. IEEE Eng. Med. Biol. Soc. , 2015,\nvol. 2015, pp. 797–800.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n906 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\n[9] H. I. Suk, S. W. Lee, and D. Shen, “Deep sparse multi-task learning for\nfeature selection in alzheimer’s disease diagnosis,” Brain Struct. Funct. ,\nvol. 221, no. 5, pp. 2569–2587, 2016.\n[10] A. Kwasigroch, A. Mikoajczyk, and M. Grochowski, “Deep con-\nvolutional neural networks as a decision support tool in medical\nproblems—Malignant melanoma case study,” in Trends in Advanced\nIntelligent Control, Optimization and Automation (Advances in In-\ntelligent Systems and Computing). New Y ork, NY , USA: Springer,\n2017.\n[11] A. Esteva et al. , “Dermatologist-level classiﬁcation of skin cancer\nwith deep neural networks,” Nature, vol. 542, no. 7639, pp. 115–118,\n2017.\n[12] A. B. Oktay and Y . S. Akgul, “Diagnosis of degenerative intervertebral\ndisc disease with deep networks and SVM,” in Computer and Information\nSciences. New Y ork, NY , USA: Springer, 2016.\n[13] D. H. Wolpert and W. G. Macready, “No free lunch theorems for op-\ntimization,” IEEE Trans. Evol. Comput. , vol. 1, no. 1, pp. 67–82, Apr.\n1997.\n[14] S. A. Prajapati, R. Nagaraj, and S. Mitra, “Classiﬁcation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—",
        "cation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—V olume II (Lecture Notes in\nElectrical Engineering). New Y ork, NY , USA: Springer, 2014, pp. 631–\n639.\n[17] E. Provenzi, C. L. De, A. Rizzi, and D. Marini, “Mathematical deﬁnition\nand analysis of the Retinex algorithm,” J. Opt. Soc. Am. A , vol. 22, no. 12,\npp. 2613–2621, 2005.\n[18] S. Y . Liao and T. Q. Huang, “Video copy-move forgery detection and\nlocalization based on Tamura texture features,” in Proc. Int. Congr . Image\nSignal Process., 2014, pp. 864–868.\n[19] X. Wang, K. Chen, Z. Huang, C. Y ao, and W. Liu, “Point linking network\nfor object detection,” 2017, arXiv preprint arXiv:1706.03646.\n[20] J. Dai, K. He, and J. Sun, “Instance-aware semantic segmentation via\nmulti-task network cascades,” in Proc. IEEE Conf. Comput. Vision Pattern\nRecognit., 2015, pp. 3150–3158.\n[21] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in Proc. IEEE Conf. Comput. Vision Pattern Recognit. , 2015,\npp. 770–778.\n[22] S. Ren, R. Girshick, R. Girshick, and J. Sun, “Faster R-CNN: Towards\nreal-time object detection with region proposal networks,” IEEE Trans.\nPattern Anal. & Mach. Intell. , vol. 39, no. 6, pp. 1137–1149, Jun. 2017.\n[23] Z. Xie, X. Zhang, D. Zeng, X. Chen, and W. Feng, “Design and imple-\nmentation of the remote wireless intraoral endoscope system,” in Proc.\nInt. Ind. Inform. Comput. Eng. Conf. , 2015, pp. 975–980.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. "
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2422
    },
    {
      "id": "Q3",
      "question": "How were participants sampled in this study: by convenience, randomly, or consecutively?",
      "answer": "by convenience",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        6,
        1,
        5
      ],
      "chunks_str": [
        ".\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with the 7 types of dental\ndiseases as follows: dental caries, dental uorosis, periodontal\ndisease, cracked tooth, dental calculus, dental plaque, and tooth\nloss. 4/5 of these data was used in training, while 1/5 of them was\nin model testing, training data set and test data are respectively\nfrom different objects, thus without overlap between the testing\ndataset and the training dataset.\nB. Build Sample Set\nThe semi-automatic labeling method is applied to establish\nthe training sample set to improve the efﬁciency. The dental im-\nages were initially labeled by the design of detector for 7 types\nof dental diseases, as shown in Fig. 5 , the functions of the de-\ntector here include image enhancement, color texture matching,\ncoarse localization and classiﬁcation of disease. Followed by\nthe conﬁrmation of images with labeling error or classiﬁcation\nerror through manual screening method, the training samples\nset were ﬁnally calibrated by 20 dental disease experts, with the\ndetails as follows:\n1) Image Enhancement: In some dental images, the features\nof the tooth disease site without very high contrast are not very\nobvious, thereby making it necessary to enhance the images\nbefore designing the classiﬁcation algorithms. The Retinex al-\ngorithm is used [17], which adaptively prompts various types\nof images to achieve balance in dynamic range, edge, and color.\nThe image enhancement effect in Fig. 6 shows that the color\nand texture details of the dental disease are highlighted after the\nenhancement.\n2) Coarse Localization and Classiﬁcation of Dental Disease\nTarget Area: It is just a preliminary detecting, and only the areas\nclose to the color and texture of the image to be matched will\nbe detected as samples. Firstly, a histogram matching method\nwith fast calculation speed is used to select the region of color\nproximity, followed by the use of the Tamura texture feature\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n902 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through art",
        " part by the Shanghai Pujiang Program under Grant\n17PJ1400800, and in part by Shanghai Institute of Intelligent Electronics\nand Systems. (Corresponding authors: Li-Rong Zheng; Zhuo Zou; Shih-\nChing Y eh.)\nThe authors are with the School of Information Science and T ech-\nnology, Fudan University, Shanghai 200433 China (e-mail: , isreason@\n126.com; jwxu16@fudan.edu.cn; yxhuan@kth.se; zhuo@kth.se; yeshi\nqing@fudan.edu.cn; lirong@kth.se).\nDigital Object Identiﬁer 10.1109/JBHI.2019.2919916\nstrong sense of tooth protection, can be problematic. The latest\nsurvey on oral health shows that a shocking 94% of popula-\ntion suffers from various forms of dental problems in China [1].\nHowever, dental diseases in many cases can be prevented, and\nserious problems can be avoided if teeth are regularly moni-\ntored. Moreover, the monitoring of periodontal, gingival and\noral mucosa can play a signiﬁcant role in monitoring the pa-\ntients’ cardiovascular and cerebrovascular diseases, diabetes,\nAIDS and other problems [2]–[4].\nNowadays, the IoT, a growing ubiquitous concept, has inu-\nenced various aspects of human life [5]. To be more speciﬁc,\nIoT-based healthcare service has been applied to a wide range of\nelds, and various healthcare solutions are thereby provided [6],\n[7]. It is possible to achieve signicant enhancement in healthcare\nsuch as early-detection and prediction. However, with the emer-\ngence of the IoT-based healthcare services, smart HomeCentric\ndental solution can be built to make treatment before getting\nillnessa reality. Speciﬁcally, such studies focus commonly on\nIoT-based healthcare services platforms, with few researches on\nIn-home dental healthcare and services.\nThe rapid development of wireless and mobile networks has\nbeen accompanied by mobile terminals serving as an effective\nsocial platform for everyone, and mobile application software\nis increasingly popular, thereby making it necessary to design\nthe dental healthcare APPs to realize the quick and effective\nconnection between patients and dental doctors.\nRecent years have witnessed deep learning showing potential\nin the versatile and highly variable tasks of a variety of ﬁne-\ngrained object classiﬁcations. Powered by advances in com-\nputation and excessively large datasets, deep learning algo-\nrithms have produced promising results in different medical\ntasks, which have also been applied in medical image analy-\nsis such as MRI, derma to scopic images and standard images.\nDeep neural networks were used to form a mammography mass\nlesion classiﬁcation [8], Alzheimer disease classiﬁcation [9],\nskin lesion and skin cancer classiﬁcation [10], [11] Ayse Betul\nOktay presented a method of detecting teeth in dental panoramic\nX-ray images with Convolutional Neural Network (CNN) [12],\nwhich is also used to implement the automated segmentation of\ngingival diseases from oral images [13]. In [14], the approaches\nof CNN and transfer learning are used in dental diseases, and\nthe above artiﬁcial intelligence methods for dental are based\n2168-2194 © 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\nSee https://www.ieee.org/publications/rights/index.html for more information.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE",
        "namely, client, service platform and doctor at the application\nlogic level. Users capture pictures using intelligent dental im-\nage data acquisition device, and then upload the pictures to the\nservice platform through the mobile terminal, and these den-\ntal image data will be analyzed using AI methods. The system\nwill advise the user to seek for medical care if problems have\nbeen found in teeth after the conﬁrmation of the service by the\nuser. Nearby dental clinics or doctors based on their geographic\nlocation will be recommended at the service platform, thereby\nmaking it possible for users to consult with doctors to make\nappointments and complete ofﬂine medical procedures if the\nappointment is successful.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 901\nFig. 4. The intelligent dental image acquisition device hardware\ndiagram.\nC. Intelligent Hardware\nTraditional dental image collection methods can bring about\nthe inconvenience as follows:\nr Dentists are required to acquire knowledge on more shoot-\ning skills;\nr It is necessary to expand the auxiliary equipment such as\nthe oral expander, along with high cost of the SLR camera.\nr Only partial dental images can be obtained\nDue to the peculiarity of oral structure, the general image\nacquisition equipment (e.g. smart cell-phone) cant meet the im-\nage data collection requirement of 6 surfaces of teeth, thereby\nhelping explain that an intelligent dental image acquisition de-\nvice is designed to photograph dental images. As shown in the\nFig. 4 , the intelligent dental image acquisition device is mainly\ncomposed of an image module and the control board, and the\nmicro exible packaging technology is applied to manufacture\nthe image module. On the exible printed circuit board, it is in-\ntegrated with a 1-megapixel CMOS Sensor, the supplementary\nlighting LEDs, and a macro lens to form a module.\nIncluding processing chip, Wi-Fi module, gyroscope, mem-\nory, keys, LEDs, power management and wireless charger, the\nmain board has functions such as video encoding, interface con-\ntrol, light control and task processing. Additionally, the device\ncan be communicated with the mobile terminal through the Wi-\nFi module. When photographing the teeth, the left-side images\nand right-side images are ﬂipped, with the use of a gyroscope\nsensor in the hardware design [16]. Moreover, In the process\nof shooting, the processor can sense the change signal, and then\ncorrect the image position with the software automatically.\nIII. I NTELLIGENT DENT AL DIAGNOSIS\nA. System Flow and Data Acquisition\nAI detection of dental diseases is the most important part of\nthe intelligent dental Health-IoT platform, and the main steps\nFig. 5. Dental image analysis system ﬂow.\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2559
    },
    {
      "id": "Q4",
      "question": "How was the dataset described in this study before predictive modeling was performed?",
      "answer": "12,600 clinical images classified into 7 dental diseases.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        6,
        7,
        14
      ],
      "chunks_str": [
        ".\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with the 7 types of dental\ndiseases as follows: dental caries, dental uorosis, periodontal\ndisease, cracked tooth, dental calculus, dental plaque, and tooth\nloss. 4/5 of these data was used in training, while 1/5 of them was\nin model testing, training data set and test data are respectively\nfrom different objects, thus without overlap between the testing\ndataset and the training dataset.\nB. Build Sample Set\nThe semi-automatic labeling method is applied to establish\nthe training sample set to improve the efﬁciency. The dental im-\nages were initially labeled by the design of detector for 7 types\nof dental diseases, as shown in Fig. 5 , the functions of the de-\ntector here include image enhancement, color texture matching,\ncoarse localization and classiﬁcation of disease. Followed by\nthe conﬁrmation of images with labeling error or classiﬁcation\nerror through manual screening method, the training samples\nset were ﬁnally calibrated by 20 dental disease experts, with the\ndetails as follows:\n1) Image Enhancement: In some dental images, the features\nof the tooth disease site without very high contrast are not very\nobvious, thereby making it necessary to enhance the images\nbefore designing the classiﬁcation algorithms. The Retinex al-\ngorithm is used [17], which adaptively prompts various types\nof images to achieve balance in dynamic range, edge, and color.\nThe image enhancement effect in Fig. 6 shows that the color\nand texture details of the dental disease are highlighted after the\nenhancement.\n2) Coarse Localization and Classiﬁcation of Dental Disease\nTarget Area: It is just a preliminary detecting, and only the areas\nclose to the color and texture of the image to be matched will\nbe detected as samples. Firstly, a histogram matching method\nwith fast calculation speed is used to select the region of color\nproximity, followed by the use of the Tamura texture feature\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n902 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through art",
        "3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through articial selection, along with the possible adding of\nthe undetected target images. The nished data is applied as the\ntraining sample data for the detection and classication of dental\ndiseases, ending up with the summary of the recorded frame\nimages to establish the dental training sample set.\nC. Model Training\nCommon target detection algorithms including RCNN,\nYOLO, SSD [19] only classify the target in the image. However,\nthe accurate target segmentation is benecial to the auxiliary med-\nical diagnosis, to achieve the aim of fast and accurate detection\nof dental diseases and dental area accurate segmentation. Based\non the established dental sample library, the MASK R-CNN\nmethod is chosen for the accurate detection and segmentation\nof the dental target.\nThe designed MASK R-CNN network is shown in the left\nof Fig. 6 , in which, MASK R-CNN adds a branch predicting\nthe segmentation mask in each interested area based on Faster\nR-CNN [20]. In Faster R-CNN, region of interest (RoI) pool\nis used to extract the small features from each RoI. Firstly,\nRoIPool scales the RoI represented by oating point numbers to\nFig. 7. Left: MASK R-CNN network. Right: example detections using\nMASK R-CNN on dental images test.\nthe granularity matching the feature graph, followed by parti-\ntioning of the scaled ROI, ending up with the summary of the\ncharacteristic value of each block coverage area. Such calcula-\ntions misplace the ROI and the extracted features, which, though\npossibly not affecting the classication, for the classication has\nthe certain robustness to the small amplitude transformation,\nexerts a great negative impact on the prediction of the precise\nmask of pixel level. Mask R-CNN proposes the RoI Align layer\nto remove the dislocation of RoIPool and aligns the extracted\nfeatures with the input accurately. In RoI Align, a bilinear in-\nterpolation is used to calculate the exact value of each position,\nalong with the summary of the results by using the maximum\nor average pooling, and the extracted features and input can be\naligned with the pixel to pixel, thereby improving the segmen-\ntation accuracy effectively. For the lower convolution network\nused for feature extraction on the whole image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN AN",
        "cation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—V olume II (Lecture Notes in\nElectrical Engineering). New Y ork, NY , USA: Springer, 2014, pp. 631–\n639.\n[17] E. Provenzi, C. L. De, A. Rizzi, and D. Marini, “Mathematical deﬁnition\nand analysis of the Retinex algorithm,” J. Opt. Soc. Am. A , vol. 22, no. 12,\npp. 2613–2621, 2005.\n[18] S. Y . Liao and T. Q. Huang, “Video copy-move forgery detection and\nlocalization based on Tamura texture features,” in Proc. Int. Congr . Image\nSignal Process., 2014, pp. 864–868.\n[19] X. Wang, K. Chen, Z. Huang, C. Y ao, and W. Liu, “Point linking network\nfor object detection,” 2017, arXiv preprint arXiv:1706.03646.\n[20] J. Dai, K. He, and J. Sun, “Instance-aware semantic segmentation via\nmulti-task network cascades,” in Proc. IEEE Conf. Comput. Vision Pattern\nRecognit., 2015, pp. 3150–3158.\n[21] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in Proc. IEEE Conf. Comput. Vision Pattern Recognit. , 2015,\npp. 770–778.\n[22] S. Ren, R. Girshick, R. Girshick, and J. Sun, “Faster R-CNN: Towards\nreal-time object detection with region proposal networks,” IEEE Trans.\nPattern Anal. & Mach. Intell. , vol. 39, no. 6, pp. 1137–1149, Jun. 2017.\n[23] Z. Xie, X. Zhang, D. Zeng, X. Chen, and W. Feng, “Design and imple-\nmentation of the remote wireless intraoral endoscope system,” in Proc.\nInt. Ind. Inform. Comput. Eng. Conf. , 2015, pp. 975–980.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. "
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2437
    },
    {
      "id": "Q5",
      "question": "What was the proedure for splitting the dataset into training, validation, and test sets in this study?",
      "answer": "4/5 training, 1/5 testing, from different subjects.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        6,
        8,
        14
      ],
      "chunks_str": [
        ".\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with the 7 types of dental\ndiseases as follows: dental caries, dental uorosis, periodontal\ndisease, cracked tooth, dental calculus, dental plaque, and tooth\nloss. 4/5 of these data was used in training, while 1/5 of them was\nin model testing, training data set and test data are respectively\nfrom different objects, thus without overlap between the testing\ndataset and the training dataset.\nB. Build Sample Set\nThe semi-automatic labeling method is applied to establish\nthe training sample set to improve the efﬁciency. The dental im-\nages were initially labeled by the design of detector for 7 types\nof dental diseases, as shown in Fig. 5 , the functions of the de-\ntector here include image enhancement, color texture matching,\ncoarse localization and classiﬁcation of disease. Followed by\nthe conﬁrmation of images with labeling error or classiﬁcation\nerror through manual screening method, the training samples\nset were ﬁnally calibrated by 20 dental disease experts, with the\ndetails as follows:\n1) Image Enhancement: In some dental images, the features\nof the tooth disease site without very high contrast are not very\nobvious, thereby making it necessary to enhance the images\nbefore designing the classiﬁcation algorithms. The Retinex al-\ngorithm is used [17], which adaptively prompts various types\nof images to achieve balance in dynamic range, edge, and color.\nThe image enhancement effect in Fig. 6 shows that the color\nand texture details of the dental disease are highlighted after the\nenhancement.\n2) Coarse Localization and Classiﬁcation of Dental Disease\nTarget Area: It is just a preliminary detecting, and only the areas\nclose to the color and texture of the image to be matched will\nbe detected as samples. Firstly, a histogram matching method\nwith fast calculation speed is used to select the region of color\nproximity, followed by the use of the Tamura texture feature\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n902 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through art",
        " image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN ANCHOR SCALES are set. The sample\ndata is transferred from the 16-bit grayscale to 8-bit grayscale,\nthen copied to the training directory to execute the training code.\nThe data sets for each dental disease were basically balanced,\nand the method of limiting training time is adopted to avoid\noverﬁtting, with the detection results using MASK R-CNN on\ndental images being shown in the right of Fig. 7 .\nD. Inference\nRecognition rate in this study refers to the rate at which dental\ndiseases can be correctly identiﬁed in these testing image data.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 903\nT ABLE II\nTHE RECOGNITION ACCURACY OF 7T YPES OF DENT AL DISEASES\nFig. 8. A board level prototype of the intelligent dental image acquisition\ndevicet.\nThe algorithm above is followed to train the model following the\n4-step training of Faster R-CNN [22], with the Table II showing\nthe recognition accuracy of each dental disease. The table shows\nthat we can ﬁnd good results achieved by MASK R-CNN even\nunder challenging conditions, such as the reection of saliva,\ntooth gap, etc. The recognition rate of the algorithm is over 90%\nfor these seven major dental diseases, with the recognition rate\nof dental plaque as 100%, and the recognition rate of decayed\ntooth as 90.1%. It is analyzed that relatively low recognition rate\nof decayed tooth is attributed to the device using a xed focus\nlens, which will be affected by the shooting, such as smear\nand defocusing blurring. In addition, coding errors and missing\nframes can also be responsible for it. Compared with the related\nwork in [14], the accuracy of the presented transfer learning\nmethod for the classication of dental caries and periodontitis\nare all 87.5 %. This work achieves an accuracy of 90.1% and\n94.3% respectively, indicating that the classication accuracy of\ncorresponding dental diseases has been greatly improved in our\nwork.\nIV . S YSTEM INTEGRA TION AND PROTOTYPE IMPLEMENT A TION\nA. System Implementation\nThe PCB hardware of the intelligent dental image acquisition\ndevice is designed and completed, as well as the APP soft-\nware for android and apple system, with the motherboard and\nthe phone communicating via Wi-Fi. As shown in Fig. 8 ,t h e\nhardware motherboard is a circular plate with 6cm of diameter,\nwhich is suitable for being held in hands, and can be inserted\ninto the mouth exibly to collect images of the teeth. A small\npercentage of the collected images, due to the lack of",
        "cation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—V olume II (Lecture Notes in\nElectrical Engineering). New Y ork, NY , USA: Springer, 2014, pp. 631–\n639.\n[17] E. Provenzi, C. L. De, A. Rizzi, and D. Marini, “Mathematical deﬁnition\nand analysis of the Retinex algorithm,” J. Opt. Soc. Am. A , vol. 22, no. 12,\npp. 2613–2621, 2005.\n[18] S. Y . Liao and T. Q. Huang, “Video copy-move forgery detection and\nlocalization based on Tamura texture features,” in Proc. Int. Congr . Image\nSignal Process., 2014, pp. 864–868.\n[19] X. Wang, K. Chen, Z. Huang, C. Y ao, and W. Liu, “Point linking network\nfor object detection,” 2017, arXiv preprint arXiv:1706.03646.\n[20] J. Dai, K. He, and J. Sun, “Instance-aware semantic segmentation via\nmulti-task network cascades,” in Proc. IEEE Conf. Comput. Vision Pattern\nRecognit., 2015, pp. 3150–3158.\n[21] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in Proc. IEEE Conf. Comput. Vision Pattern Recognit. , 2015,\npp. 770–778.\n[22] S. Ren, R. Girshick, R. Girshick, and J. Sun, “Faster R-CNN: Towards\nreal-time object detection with region proposal networks,” IEEE Trans.\nPattern Anal. & Mach. Intell. , vol. 39, no. 6, pp. 1137–1149, Jun. 2017.\n[23] Z. Xie, X. Zhang, D. Zeng, X. Chen, and W. Feng, “Design and imple-\nmentation of the remote wireless intraoral endoscope system,” in Proc.\nInt. Ind. Inform. Comput. Eng. Conf. , 2015, pp. 975–980.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. "
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2442
    },
    {
      "id": "Q6",
      "question": "What preprocessing techniques on the included variables/features were applied in this study?",
      "answer": "Image enhancement, grayscale conversion, ResNet-50-C4 backbone.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        6,
        7,
        8
      ],
      "chunks_str": [
        ".\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with the 7 types of dental\ndiseases as follows: dental caries, dental uorosis, periodontal\ndisease, cracked tooth, dental calculus, dental plaque, and tooth\nloss. 4/5 of these data was used in training, while 1/5 of them was\nin model testing, training data set and test data are respectively\nfrom different objects, thus without overlap between the testing\ndataset and the training dataset.\nB. Build Sample Set\nThe semi-automatic labeling method is applied to establish\nthe training sample set to improve the efﬁciency. The dental im-\nages were initially labeled by the design of detector for 7 types\nof dental diseases, as shown in Fig. 5 , the functions of the de-\ntector here include image enhancement, color texture matching,\ncoarse localization and classiﬁcation of disease. Followed by\nthe conﬁrmation of images with labeling error or classiﬁcation\nerror through manual screening method, the training samples\nset were ﬁnally calibrated by 20 dental disease experts, with the\ndetails as follows:\n1) Image Enhancement: In some dental images, the features\nof the tooth disease site without very high contrast are not very\nobvious, thereby making it necessary to enhance the images\nbefore designing the classiﬁcation algorithms. The Retinex al-\ngorithm is used [17], which adaptively prompts various types\nof images to achieve balance in dynamic range, edge, and color.\nThe image enhancement effect in Fig. 6 shows that the color\nand texture details of the dental disease are highlighted after the\nenhancement.\n2) Coarse Localization and Classiﬁcation of Dental Disease\nTarget Area: It is just a preliminary detecting, and only the areas\nclose to the color and texture of the image to be matched will\nbe detected as samples. Firstly, a histogram matching method\nwith fast calculation speed is used to select the region of color\nproximity, followed by the use of the Tamura texture feature\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n902 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through art",
        "3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through articial selection, along with the possible adding of\nthe undetected target images. The nished data is applied as the\ntraining sample data for the detection and classication of dental\ndiseases, ending up with the summary of the recorded frame\nimages to establish the dental training sample set.\nC. Model Training\nCommon target detection algorithms including RCNN,\nYOLO, SSD [19] only classify the target in the image. However,\nthe accurate target segmentation is benecial to the auxiliary med-\nical diagnosis, to achieve the aim of fast and accurate detection\nof dental diseases and dental area accurate segmentation. Based\non the established dental sample library, the MASK R-CNN\nmethod is chosen for the accurate detection and segmentation\nof the dental target.\nThe designed MASK R-CNN network is shown in the left\nof Fig. 6 , in which, MASK R-CNN adds a branch predicting\nthe segmentation mask in each interested area based on Faster\nR-CNN [20]. In Faster R-CNN, region of interest (RoI) pool\nis used to extract the small features from each RoI. Firstly,\nRoIPool scales the RoI represented by oating point numbers to\nFig. 7. Left: MASK R-CNN network. Right: example detections using\nMASK R-CNN on dental images test.\nthe granularity matching the feature graph, followed by parti-\ntioning of the scaled ROI, ending up with the summary of the\ncharacteristic value of each block coverage area. Such calcula-\ntions misplace the ROI and the extracted features, which, though\npossibly not affecting the classication, for the classication has\nthe certain robustness to the small amplitude transformation,\nexerts a great negative impact on the prediction of the precise\nmask of pixel level. Mask R-CNN proposes the RoI Align layer\nto remove the dislocation of RoIPool and aligns the extracted\nfeatures with the input accurately. In RoI Align, a bilinear in-\nterpolation is used to calculate the exact value of each position,\nalong with the summary of the results by using the maximum\nor average pooling, and the extracted features and input can be\naligned with the pixel to pixel, thereby improving the segmen-\ntation accuracy effectively. For the lower convolution network\nused for feature extraction on the whole image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN AN",
        " image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN ANCHOR SCALES are set. The sample\ndata is transferred from the 16-bit grayscale to 8-bit grayscale,\nthen copied to the training directory to execute the training code.\nThe data sets for each dental disease were basically balanced,\nand the method of limiting training time is adopted to avoid\noverﬁtting, with the detection results using MASK R-CNN on\ndental images being shown in the right of Fig. 7 .\nD. Inference\nRecognition rate in this study refers to the rate at which dental\ndiseases can be correctly identiﬁed in these testing image data.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 903\nT ABLE II\nTHE RECOGNITION ACCURACY OF 7T YPES OF DENT AL DISEASES\nFig. 8. A board level prototype of the intelligent dental image acquisition\ndevicet.\nThe algorithm above is followed to train the model following the\n4-step training of Faster R-CNN [22], with the Table II showing\nthe recognition accuracy of each dental disease. The table shows\nthat we can ﬁnd good results achieved by MASK R-CNN even\nunder challenging conditions, such as the reection of saliva,\ntooth gap, etc. The recognition rate of the algorithm is over 90%\nfor these seven major dental diseases, with the recognition rate\nof dental plaque as 100%, and the recognition rate of decayed\ntooth as 90.1%. It is analyzed that relatively low recognition rate\nof decayed tooth is attributed to the device using a xed focus\nlens, which will be affected by the shooting, such as smear\nand defocusing blurring. In addition, coding errors and missing\nframes can also be responsible for it. Compared with the related\nwork in [14], the accuracy of the presented transfer learning\nmethod for the classication of dental caries and periodontitis\nare all 87.5 %. This work achieves an accuracy of 90.1% and\n94.3% respectively, indicating that the classication accuracy of\ncorresponding dental diseases has been greatly improved in our\nwork.\nIV . S YSTEM INTEGRA TION AND PROTOTYPE IMPLEMENT A TION\nA. System Implementation\nThe PCB hardware of the intelligent dental image acquisition\ndevice is designed and completed, as well as the APP soft-\nware for android and apple system, with the motherboard and\nthe phone communicating via Wi-Fi. As shown in Fig. 8 ,t h e\nhardware motherboard is a circular plate with 6cm of diameter,\nwhich is suitable for being held in hands, and can be inserted\ninto the mouth exibly to collect images of the teeth. A small\npercentage of the collected images, due to the lack of"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2581
    },
    {
      "id": "Q7",
      "question": "How is missing data handled in this study?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        6,
        2,
        13
      ],
      "chunks_str": [
        ".\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with the 7 types of dental\ndiseases as follows: dental caries, dental uorosis, periodontal\ndisease, cracked tooth, dental calculus, dental plaque, and tooth\nloss. 4/5 of these data was used in training, while 1/5 of them was\nin model testing, training data set and test data are respectively\nfrom different objects, thus without overlap between the testing\ndataset and the training dataset.\nB. Build Sample Set\nThe semi-automatic labeling method is applied to establish\nthe training sample set to improve the efﬁciency. The dental im-\nages were initially labeled by the design of detector for 7 types\nof dental diseases, as shown in Fig. 5 , the functions of the de-\ntector here include image enhancement, color texture matching,\ncoarse localization and classiﬁcation of disease. Followed by\nthe conﬁrmation of images with labeling error or classiﬁcation\nerror through manual screening method, the training samples\nset were ﬁnally calibrated by 20 dental disease experts, with the\ndetails as follows:\n1) Image Enhancement: In some dental images, the features\nof the tooth disease site without very high contrast are not very\nobvious, thereby making it necessary to enhance the images\nbefore designing the classiﬁcation algorithms. The Retinex al-\ngorithm is used [17], which adaptively prompts various types\nof images to achieve balance in dynamic range, edge, and color.\nThe image enhancement effect in Fig. 6 shows that the color\nand texture details of the dental disease are highlighted after the\nenhancement.\n2) Coarse Localization and Classiﬁcation of Dental Disease\nTarget Area: It is just a preliminary detecting, and only the areas\nclose to the color and texture of the image to be matched will\nbe detected as samples. Firstly, a histogram matching method\nwith fast calculation speed is used to select the region of color\nproximity, followed by the use of the Tamura texture feature\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n902 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through art",
        " [12],\nwhich is also used to implement the automated segmentation of\ngingival diseases from oral images [13]. In [14], the approaches\nof CNN and transfer learning are used in dental diseases, and\nthe above artiﬁcial intelligence methods for dental are based\n2168-2194 © 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\nSee https://www.ieee.org/publications/rights/index.html for more information.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 899\non X-ray. However, visual diagnosis serves as one of the most\nimportant parts of dental health care.\nThe smart dental health IoT system, due to the lack of coor-\ndinated IoT-based In-home dental health care services, is devel-\noped in this paper, which plays an important role in elaborating\nits applications in home and private dental clinic scenarios. The\nproposed system builds a home-centric, self-assisted, fully au-\ntomatic intelligent In-home dental healthcare solution by taking\nadvantage of embedded intelligent hardware technology, articial\nintelligence (AI), and the mobile terminal.\nThe system closely combines the personal self-service dental\nhealth examination and dental resources through studying the\nAI method to expand the scope and coverage of traditional\ndental health care, which is the major contribution made by the\nproposed iHome smart dental Health-IoT system. Patients can\nchoose medical resources online and receive an appointment for\nmedical treatment via self-service smart dental screening.\nThe rest parts of this paper are organized as follows.\nSection II discusses smart In-home dentist system, followed\nby Section III analyzing the intelligent dental diagnosis, intro-\nducing the algorithm ﬂow and test results. Section IV presents\nthe integrated system and hardware prototype, and reports the\napplication results, and a conclusion is given in Section V\nﬁnally.\nII. S MART IN-HOME DENTIST SYSTEM\nThe occurrence of dental disease can be well predictable. For\nexample, each stage from dental plaque, calculus to dental caries\nand periodontal disease shows different characteristics and so-\nlutions, thereby making it possible to monitor the whole body\nand reduce the risk of sudden diseases effectively. It can reduce\npain, save time and reduce the cost of money for patients. How-\never, most consumers lack the correct tooth awareness, thereby\nmaking the timely treatment for tooth disease difﬁcult. More-\nover, there is a relative shortage of dental resources in hospitals.\nThese main contradictions are explained in the following aspects\nin details:\nr First, there are a lot of patients with dental diseases, but\nfewer people pay attention to the teeth. Many individ-\nuals pay for treatment only when they have teeth with\nproblems, which may cause irreversible damage to the\nlong-term development of children.\nr Second, the cost of dental treatment is relatively high.\nr Third, dental disease, due to the characteristics of elective\ntreatment, is difﬁcult to get timely treatment.\nBased on what is discussed above, a promising trend in health-\ncare is to move routine medical checks and other healthcare ser-\nvices from hospital (Hospital-Centric) to the home environment\n(Home-centric) [15], through which, the patients can get seam-\nless health care at any time in a comfortable home environment.\nEven more, it can ensure that the overall iHome dental health-\ncare system including three partspersonalized services, dental\nservices and intelligent and interactive service could be opti-\nmized to a large extent. Based on this platform, the closed",
        " interconnected devices promise\nmore efﬁcient and comprehensive health care,” IEEE Pulse , vol. 7, no. 5,\npp. 35–39, Sep./Oct. 2016.\n[7] P . Sundaravadivel, E. Kougianos, S. P . Mohanty, and M. K. Ganapathiraju,\n“Everything you wanted to know about smart health care: Evaluating the\ndifferent technologies and components of the internet of things for better\nhealth,” IEEE Consum. Electron. Mag. , vol. 7, no. 1, pp. 18–28, Jan. 2017.\n[8] J. Arevalo, F. A. Gonzalez, R. Ramos-Pollan, J. L. Oliveira, and M. A.\nGuevara Lopez, “Convolutional neural networks for mammography mass\nlesion classiﬁcation,” in Proc. Conf. IEEE Eng. Med. Biol. Soc. , 2015,\nvol. 2015, pp. 797–800.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n906 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\n[9] H. I. Suk, S. W. Lee, and D. Shen, “Deep sparse multi-task learning for\nfeature selection in alzheimer’s disease diagnosis,” Brain Struct. Funct. ,\nvol. 221, no. 5, pp. 2569–2587, 2016.\n[10] A. Kwasigroch, A. Mikoajczyk, and M. Grochowski, “Deep con-\nvolutional neural networks as a decision support tool in medical\nproblems—Malignant melanoma case study,” in Trends in Advanced\nIntelligent Control, Optimization and Automation (Advances in In-\ntelligent Systems and Computing). New Y ork, NY , USA: Springer,\n2017.\n[11] A. Esteva et al. , “Dermatologist-level classiﬁcation of skin cancer\nwith deep neural networks,” Nature, vol. 542, no. 7639, pp. 115–118,\n2017.\n[12] A. B. Oktay and Y . S. Akgul, “Diagnosis of degenerative intervertebral\ndisc disease with deep networks and SVM,” in Computer and Information\nSciences. New Y ork, NY , USA: Springer, 2016.\n[13] D. H. Wolpert and W. G. Macready, “No free lunch theorems for op-\ntimization,” IEEE Trans. Evol. Comput. , vol. 1, no. 1, pp. 67–82, Apr.\n1997.\n[14] S. A. Prajapati, R. Nagaraj, and S. Mitra, “Classiﬁcation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2538
    },
    {
      "id": "Q8",
      "question": "How are outliers handled in this study?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        14,
        2,
        1
      ],
      "chunks_str": [
        "cation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—V olume II (Lecture Notes in\nElectrical Engineering). New Y ork, NY , USA: Springer, 2014, pp. 631–\n639.\n[17] E. Provenzi, C. L. De, A. Rizzi, and D. Marini, “Mathematical deﬁnition\nand analysis of the Retinex algorithm,” J. Opt. Soc. Am. A , vol. 22, no. 12,\npp. 2613–2621, 2005.\n[18] S. Y . Liao and T. Q. Huang, “Video copy-move forgery detection and\nlocalization based on Tamura texture features,” in Proc. Int. Congr . Image\nSignal Process., 2014, pp. 864–868.\n[19] X. Wang, K. Chen, Z. Huang, C. Y ao, and W. Liu, “Point linking network\nfor object detection,” 2017, arXiv preprint arXiv:1706.03646.\n[20] J. Dai, K. He, and J. Sun, “Instance-aware semantic segmentation via\nmulti-task network cascades,” in Proc. IEEE Conf. Comput. Vision Pattern\nRecognit., 2015, pp. 3150–3158.\n[21] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in Proc. IEEE Conf. Comput. Vision Pattern Recognit. , 2015,\npp. 770–778.\n[22] S. Ren, R. Girshick, R. Girshick, and J. Sun, “Faster R-CNN: Towards\nreal-time object detection with region proposal networks,” IEEE Trans.\nPattern Anal. & Mach. Intell. , vol. 39, no. 6, pp. 1137–1149, Jun. 2017.\n[23] Z. Xie, X. Zhang, D. Zeng, X. Chen, and W. Feng, “Design and imple-\nmentation of the remote wireless intraoral endoscope system,” in Proc.\nInt. Ind. Inform. Comput. Eng. Conf. , 2015, pp. 975–980.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. ",
        " [12],\nwhich is also used to implement the automated segmentation of\ngingival diseases from oral images [13]. In [14], the approaches\nof CNN and transfer learning are used in dental diseases, and\nthe above artiﬁcial intelligence methods for dental are based\n2168-2194 © 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\nSee https://www.ieee.org/publications/rights/index.html for more information.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 899\non X-ray. However, visual diagnosis serves as one of the most\nimportant parts of dental health care.\nThe smart dental health IoT system, due to the lack of coor-\ndinated IoT-based In-home dental health care services, is devel-\noped in this paper, which plays an important role in elaborating\nits applications in home and private dental clinic scenarios. The\nproposed system builds a home-centric, self-assisted, fully au-\ntomatic intelligent In-home dental healthcare solution by taking\nadvantage of embedded intelligent hardware technology, articial\nintelligence (AI), and the mobile terminal.\nThe system closely combines the personal self-service dental\nhealth examination and dental resources through studying the\nAI method to expand the scope and coverage of traditional\ndental health care, which is the major contribution made by the\nproposed iHome smart dental Health-IoT system. Patients can\nchoose medical resources online and receive an appointment for\nmedical treatment via self-service smart dental screening.\nThe rest parts of this paper are organized as follows.\nSection II discusses smart In-home dentist system, followed\nby Section III analyzing the intelligent dental diagnosis, intro-\nducing the algorithm ﬂow and test results. Section IV presents\nthe integrated system and hardware prototype, and reports the\napplication results, and a conclusion is given in Section V\nﬁnally.\nII. S MART IN-HOME DENTIST SYSTEM\nThe occurrence of dental disease can be well predictable. For\nexample, each stage from dental plaque, calculus to dental caries\nand periodontal disease shows different characteristics and so-\nlutions, thereby making it possible to monitor the whole body\nand reduce the risk of sudden diseases effectively. It can reduce\npain, save time and reduce the cost of money for patients. How-\never, most consumers lack the correct tooth awareness, thereby\nmaking the timely treatment for tooth disease difﬁcult. More-\nover, there is a relative shortage of dental resources in hospitals.\nThese main contradictions are explained in the following aspects\nin details:\nr First, there are a lot of patients with dental diseases, but\nfewer people pay attention to the teeth. Many individ-\nuals pay for treatment only when they have teeth with\nproblems, which may cause irreversible damage to the\nlong-term development of children.\nr Second, the cost of dental treatment is relatively high.\nr Third, dental disease, due to the characteristics of elective\ntreatment, is difﬁcult to get timely treatment.\nBased on what is discussed above, a promising trend in health-\ncare is to move routine medical checks and other healthcare ser-\nvices from hospital (Hospital-Centric) to the home environment\n(Home-centric) [15], through which, the patients can get seam-\nless health care at any time in a comfortable home environment.\nEven more, it can ensure that the overall iHome dental health-\ncare system including three partspersonalized services, dental\nservices and intelligent and interactive service could be opti-\nmized to a large extent. Based on this platform, the closed",
        " part by the Shanghai Pujiang Program under Grant\n17PJ1400800, and in part by Shanghai Institute of Intelligent Electronics\nand Systems. (Corresponding authors: Li-Rong Zheng; Zhuo Zou; Shih-\nChing Y eh.)\nThe authors are with the School of Information Science and T ech-\nnology, Fudan University, Shanghai 200433 China (e-mail: , isreason@\n126.com; jwxu16@fudan.edu.cn; yxhuan@kth.se; zhuo@kth.se; yeshi\nqing@fudan.edu.cn; lirong@kth.se).\nDigital Object Identiﬁer 10.1109/JBHI.2019.2919916\nstrong sense of tooth protection, can be problematic. The latest\nsurvey on oral health shows that a shocking 94% of popula-\ntion suffers from various forms of dental problems in China [1].\nHowever, dental diseases in many cases can be prevented, and\nserious problems can be avoided if teeth are regularly moni-\ntored. Moreover, the monitoring of periodontal, gingival and\noral mucosa can play a signiﬁcant role in monitoring the pa-\ntients’ cardiovascular and cerebrovascular diseases, diabetes,\nAIDS and other problems [2]–[4].\nNowadays, the IoT, a growing ubiquitous concept, has inu-\nenced various aspects of human life [5]. To be more speciﬁc,\nIoT-based healthcare service has been applied to a wide range of\nelds, and various healthcare solutions are thereby provided [6],\n[7]. It is possible to achieve signicant enhancement in healthcare\nsuch as early-detection and prediction. However, with the emer-\ngence of the IoT-based healthcare services, smart HomeCentric\ndental solution can be built to make treatment before getting\nillnessa reality. Speciﬁcally, such studies focus commonly on\nIoT-based healthcare services platforms, with few researches on\nIn-home dental healthcare and services.\nThe rapid development of wireless and mobile networks has\nbeen accompanied by mobile terminals serving as an effective\nsocial platform for everyone, and mobile application software\nis increasingly popular, thereby making it necessary to design\nthe dental healthcare APPs to realize the quick and effective\nconnection between patients and dental doctors.\nRecent years have witnessed deep learning showing potential\nin the versatile and highly variable tasks of a variety of ﬁne-\ngrained object classiﬁcations. Powered by advances in com-\nputation and excessively large datasets, deep learning algo-\nrithms have produced promising results in different medical\ntasks, which have also been applied in medical image analy-\nsis such as MRI, derma to scopic images and standard images.\nDeep neural networks were used to form a mammography mass\nlesion classiﬁcation [8], Alzheimer disease classiﬁcation [9],\nskin lesion and skin cancer classiﬁcation [10], [11] Ayse Betul\nOktay presented a method of detecting teeth in dental panoramic\nX-ray images with Convolutional Neural Network (CNN) [12],\nwhich is also used to implement the automated segmentation of\ngingival diseases from oral images [13]. In [14], the approaches\nof CNN and transfer learning are used in dental diseases, and\nthe above artiﬁcial intelligence methods for dental are based\n2168-2194 © 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\nSee https://www.ieee.org/publications/rights/index.html for more information.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2415
    },
    {
      "id": "Q9",
      "question": "Which prediction models were used in this study?",
      "answer": "Mask R-CNN and ResNet-50-C4 backbone.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        6,
        2,
        8
      ],
      "chunks_str": [
        ".\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with the 7 types of dental\ndiseases as follows: dental caries, dental uorosis, periodontal\ndisease, cracked tooth, dental calculus, dental plaque, and tooth\nloss. 4/5 of these data was used in training, while 1/5 of them was\nin model testing, training data set and test data are respectively\nfrom different objects, thus without overlap between the testing\ndataset and the training dataset.\nB. Build Sample Set\nThe semi-automatic labeling method is applied to establish\nthe training sample set to improve the efﬁciency. The dental im-\nages were initially labeled by the design of detector for 7 types\nof dental diseases, as shown in Fig. 5 , the functions of the de-\ntector here include image enhancement, color texture matching,\ncoarse localization and classiﬁcation of disease. Followed by\nthe conﬁrmation of images with labeling error or classiﬁcation\nerror through manual screening method, the training samples\nset were ﬁnally calibrated by 20 dental disease experts, with the\ndetails as follows:\n1) Image Enhancement: In some dental images, the features\nof the tooth disease site without very high contrast are not very\nobvious, thereby making it necessary to enhance the images\nbefore designing the classiﬁcation algorithms. The Retinex al-\ngorithm is used [17], which adaptively prompts various types\nof images to achieve balance in dynamic range, edge, and color.\nThe image enhancement effect in Fig. 6 shows that the color\nand texture details of the dental disease are highlighted after the\nenhancement.\n2) Coarse Localization and Classiﬁcation of Dental Disease\nTarget Area: It is just a preliminary detecting, and only the areas\nclose to the color and texture of the image to be matched will\nbe detected as samples. Firstly, a histogram matching method\nwith fast calculation speed is used to select the region of color\nproximity, followed by the use of the Tamura texture feature\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n902 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through art",
        " [12],\nwhich is also used to implement the automated segmentation of\ngingival diseases from oral images [13]. In [14], the approaches\nof CNN and transfer learning are used in dental diseases, and\nthe above artiﬁcial intelligence methods for dental are based\n2168-2194 © 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\nSee https://www.ieee.org/publications/rights/index.html for more information.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 899\non X-ray. However, visual diagnosis serves as one of the most\nimportant parts of dental health care.\nThe smart dental health IoT system, due to the lack of coor-\ndinated IoT-based In-home dental health care services, is devel-\noped in this paper, which plays an important role in elaborating\nits applications in home and private dental clinic scenarios. The\nproposed system builds a home-centric, self-assisted, fully au-\ntomatic intelligent In-home dental healthcare solution by taking\nadvantage of embedded intelligent hardware technology, articial\nintelligence (AI), and the mobile terminal.\nThe system closely combines the personal self-service dental\nhealth examination and dental resources through studying the\nAI method to expand the scope and coverage of traditional\ndental health care, which is the major contribution made by the\nproposed iHome smart dental Health-IoT system. Patients can\nchoose medical resources online and receive an appointment for\nmedical treatment via self-service smart dental screening.\nThe rest parts of this paper are organized as follows.\nSection II discusses smart In-home dentist system, followed\nby Section III analyzing the intelligent dental diagnosis, intro-\nducing the algorithm ﬂow and test results. Section IV presents\nthe integrated system and hardware prototype, and reports the\napplication results, and a conclusion is given in Section V\nﬁnally.\nII. S MART IN-HOME DENTIST SYSTEM\nThe occurrence of dental disease can be well predictable. For\nexample, each stage from dental plaque, calculus to dental caries\nand periodontal disease shows different characteristics and so-\nlutions, thereby making it possible to monitor the whole body\nand reduce the risk of sudden diseases effectively. It can reduce\npain, save time and reduce the cost of money for patients. How-\never, most consumers lack the correct tooth awareness, thereby\nmaking the timely treatment for tooth disease difﬁcult. More-\nover, there is a relative shortage of dental resources in hospitals.\nThese main contradictions are explained in the following aspects\nin details:\nr First, there are a lot of patients with dental diseases, but\nfewer people pay attention to the teeth. Many individ-\nuals pay for treatment only when they have teeth with\nproblems, which may cause irreversible damage to the\nlong-term development of children.\nr Second, the cost of dental treatment is relatively high.\nr Third, dental disease, due to the characteristics of elective\ntreatment, is difﬁcult to get timely treatment.\nBased on what is discussed above, a promising trend in health-\ncare is to move routine medical checks and other healthcare ser-\nvices from hospital (Hospital-Centric) to the home environment\n(Home-centric) [15], through which, the patients can get seam-\nless health care at any time in a comfortable home environment.\nEven more, it can ensure that the overall iHome dental health-\ncare system including three partspersonalized services, dental\nservices and intelligent and interactive service could be opti-\nmized to a large extent. Based on this platform, the closed",
        " image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN ANCHOR SCALES are set. The sample\ndata is transferred from the 16-bit grayscale to 8-bit grayscale,\nthen copied to the training directory to execute the training code.\nThe data sets for each dental disease were basically balanced,\nand the method of limiting training time is adopted to avoid\noverﬁtting, with the detection results using MASK R-CNN on\ndental images being shown in the right of Fig. 7 .\nD. Inference\nRecognition rate in this study refers to the rate at which dental\ndiseases can be correctly identiﬁed in these testing image data.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 903\nT ABLE II\nTHE RECOGNITION ACCURACY OF 7T YPES OF DENT AL DISEASES\nFig. 8. A board level prototype of the intelligent dental image acquisition\ndevicet.\nThe algorithm above is followed to train the model following the\n4-step training of Faster R-CNN [22], with the Table II showing\nthe recognition accuracy of each dental disease. The table shows\nthat we can ﬁnd good results achieved by MASK R-CNN even\nunder challenging conditions, such as the reection of saliva,\ntooth gap, etc. The recognition rate of the algorithm is over 90%\nfor these seven major dental diseases, with the recognition rate\nof dental plaque as 100%, and the recognition rate of decayed\ntooth as 90.1%. It is analyzed that relatively low recognition rate\nof decayed tooth is attributed to the device using a xed focus\nlens, which will be affected by the shooting, such as smear\nand defocusing blurring. In addition, coding errors and missing\nframes can also be responsible for it. Compared with the related\nwork in [14], the accuracy of the presented transfer learning\nmethod for the classication of dental caries and periodontitis\nare all 87.5 %. This work achieves an accuracy of 90.1% and\n94.3% respectively, indicating that the classication accuracy of\ncorresponding dental diseases has been greatly improved in our\nwork.\nIV . S YSTEM INTEGRA TION AND PROTOTYPE IMPLEMENT A TION\nA. System Implementation\nThe PCB hardware of the intelligent dental image acquisition\ndevice is designed and completed, as well as the APP soft-\nware for android and apple system, with the motherboard and\nthe phone communicating via Wi-Fi. As shown in Fig. 8 ,t h e\nhardware motherboard is a circular plate with 6cm of diameter,\nwhich is suitable for being held in hands, and can be inserted\ninto the mouth exibly to collect images of the teeth. A small\npercentage of the collected images, due to the lack of"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2559
    },
    {
      "id": "Q10",
      "question": "What considerations were given to model selection and hyperparameter tuning in this study?",
      "answer": "ResNet-50 backbone, Mask R-CNN, TensorFlow, hyperparameters set.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        8,
        13,
        0
      ],
      "chunks_str": [
        " image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN ANCHOR SCALES are set. The sample\ndata is transferred from the 16-bit grayscale to 8-bit grayscale,\nthen copied to the training directory to execute the training code.\nThe data sets for each dental disease were basically balanced,\nand the method of limiting training time is adopted to avoid\noverﬁtting, with the detection results using MASK R-CNN on\ndental images being shown in the right of Fig. 7 .\nD. Inference\nRecognition rate in this study refers to the rate at which dental\ndiseases can be correctly identiﬁed in these testing image data.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 903\nT ABLE II\nTHE RECOGNITION ACCURACY OF 7T YPES OF DENT AL DISEASES\nFig. 8. A board level prototype of the intelligent dental image acquisition\ndevicet.\nThe algorithm above is followed to train the model following the\n4-step training of Faster R-CNN [22], with the Table II showing\nthe recognition accuracy of each dental disease. The table shows\nthat we can ﬁnd good results achieved by MASK R-CNN even\nunder challenging conditions, such as the reection of saliva,\ntooth gap, etc. The recognition rate of the algorithm is over 90%\nfor these seven major dental diseases, with the recognition rate\nof dental plaque as 100%, and the recognition rate of decayed\ntooth as 90.1%. It is analyzed that relatively low recognition rate\nof decayed tooth is attributed to the device using a xed focus\nlens, which will be affected by the shooting, such as smear\nand defocusing blurring. In addition, coding errors and missing\nframes can also be responsible for it. Compared with the related\nwork in [14], the accuracy of the presented transfer learning\nmethod for the classication of dental caries and periodontitis\nare all 87.5 %. This work achieves an accuracy of 90.1% and\n94.3% respectively, indicating that the classication accuracy of\ncorresponding dental diseases has been greatly improved in our\nwork.\nIV . S YSTEM INTEGRA TION AND PROTOTYPE IMPLEMENT A TION\nA. System Implementation\nThe PCB hardware of the intelligent dental image acquisition\ndevice is designed and completed, as well as the APP soft-\nware for android and apple system, with the motherboard and\nthe phone communicating via Wi-Fi. As shown in Fig. 8 ,t h e\nhardware motherboard is a circular plate with 6cm of diameter,\nwhich is suitable for being held in hands, and can be inserted\ninto the mouth exibly to collect images of the teeth. A small\npercentage of the collected images, due to the lack of",
        " interconnected devices promise\nmore efﬁcient and comprehensive health care,” IEEE Pulse , vol. 7, no. 5,\npp. 35–39, Sep./Oct. 2016.\n[7] P . Sundaravadivel, E. Kougianos, S. P . Mohanty, and M. K. Ganapathiraju,\n“Everything you wanted to know about smart health care: Evaluating the\ndifferent technologies and components of the internet of things for better\nhealth,” IEEE Consum. Electron. Mag. , vol. 7, no. 1, pp. 18–28, Jan. 2017.\n[8] J. Arevalo, F. A. Gonzalez, R. Ramos-Pollan, J. L. Oliveira, and M. A.\nGuevara Lopez, “Convolutional neural networks for mammography mass\nlesion classiﬁcation,” in Proc. Conf. IEEE Eng. Med. Biol. Soc. , 2015,\nvol. 2015, pp. 797–800.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n906 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\n[9] H. I. Suk, S. W. Lee, and D. Shen, “Deep sparse multi-task learning for\nfeature selection in alzheimer’s disease diagnosis,” Brain Struct. Funct. ,\nvol. 221, no. 5, pp. 2569–2587, 2016.\n[10] A. Kwasigroch, A. Mikoajczyk, and M. Grochowski, “Deep con-\nvolutional neural networks as a decision support tool in medical\nproblems—Malignant melanoma case study,” in Trends in Advanced\nIntelligent Control, Optimization and Automation (Advances in In-\ntelligent Systems and Computing). New Y ork, NY , USA: Springer,\n2017.\n[11] A. Esteva et al. , “Dermatologist-level classiﬁcation of skin cancer\nwith deep neural networks,” Nature, vol. 542, no. 7639, pp. 115–118,\n2017.\n[12] A. B. Oktay and Y . S. Akgul, “Diagnosis of degenerative intervertebral\ndisc disease with deep networks and SVM,” in Computer and Information\nSciences. New Y ork, NY , USA: Springer, 2016.\n[13] D. H. Wolpert and W. G. Macready, “No free lunch theorems for op-\ntimization,” IEEE Trans. Evol. Comput. , vol. 1, no. 1, pp. 67–82, Apr.\n1997.\n[14] S. A. Prajapati, R. Nagaraj, and S. Mitra, “Classiﬁcation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—",
        "898 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nA Smart Dental Health-IoT Platform Based on\nIntelligent Hardware, Deep Learning, and\nMobile T erminal\nLizheng Liu , Student Member, IEEE,J i a w e iX u , Student Member, IEEE,\nY uxiang Huan , Student Member, IEEE, Zhuo Zou , Senior Member, IEEE,\nShih-Ching Y eh , Member, IEEE, and Li-Rong Zheng , Senior Member, IEEE\nAbstract— The dental disease is a common disease for a\nhuman. Screening and visual diagnosis that are currently\nperformed in clinics possibly cost a lot in various manners.\nAlong with the progress of the Internet of Things (IoT) and\nartiﬁcial intelligence, the internet-based intelligent system\nhave shown great potential in applying home-based health-\ncare. Therefore, a smart dental health-IoT system based on\nintelligent hardware, deep learning, and mobile terminal is\nproposed in this paper, aiming at exploring the feasibility\nof its application on in-home dental healthcare. Moreover, a\nsmart dental device is designed and developed in this study\nto perform the image acquisition of teeth. Based on the data\nset of 12 600 clinical images collected by the proposed de-\nvice from 10 private dental clinics, an automatic diagnosis\nmodel trained by MASK R-CNN is developed for the detec-\ntion and classiﬁcation of 7 different dental diseases includ-\ning decayed tooth, dental plaque, uorosis, and periodontal\ndisease, with the diagnosis accuracy of them reaching up to\n90%, along with high sensitivity and high speciﬁcity. Follow-\ning the one-month test in ten clinics, compared with that last\nmonth when the platform was not used, the mean diagnosis\ntime reduces by 37.5% for each patient, helping explain the\nincrease in the number of treated patients by 18.4%. Fur-\nthermore, application software (APPs) on mobile terminal\nfor client side and for dentist side are implemented to pro-\nvide service of pre-examination, consultation, appointment,\nand evaluation.\nIndex Terms— Health-IoT, MASK R-CNN, deep learning,\nartiﬁcial intelligence, intelligent hardware, mobile terminal.\nI. I NTRODUCTION\nD\nENTAL diseases (such as dental caries, periodontal dis-\nease, dental ﬂuorosis, etc.) are becoming increasingly\ncommon. Almost everyones teeth, even though he/she has a\nManuscript received October 19, 2018; revised February 16, 2019\nand March 30, 2019; accepted May 24, 2019. Date of publication June\n7, 2019; date of current version March 6, 2020. This work was supported\nin part by the National Natural Science Foundation of China under Grants\n61571137 and 61876037, in part by the Shanghai Innovation Program\n17JC1401400, and in part by the Shanghai Pujiang Program under Grant\n17PJ1400800, and in part by Shanghai Institute of Intelligent Electronics\nand Systems. (Corresponding authors: Li-Rong Zheng; Zhuo Zou; Shih-\nChing Y eh.)\nThe authors are with the School of Information Science and T ech-\nnology, Fudan University, Shanghai 200433 China (e-mail: , isreason@\n126.com; jwxu16@fudan.edu.cn; yxhuan@kth.se; zhuo@kth.se; yeshi\nqing@fudan.edu.cn; lirong@kth.se).\nDigital Object Identiﬁer 10.1109/JBHI.2019.2919916\nstrong sense of tooth protection, can"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2573
    },
    {
      "id": "Q11",
      "question": "How was data augmentation or generation used in this study?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        2,
        6,
        7
      ],
      "chunks_str": [
        " [12],\nwhich is also used to implement the automated segmentation of\ngingival diseases from oral images [13]. In [14], the approaches\nof CNN and transfer learning are used in dental diseases, and\nthe above artiﬁcial intelligence methods for dental are based\n2168-2194 © 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\nSee https://www.ieee.org/publications/rights/index.html for more information.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 899\non X-ray. However, visual diagnosis serves as one of the most\nimportant parts of dental health care.\nThe smart dental health IoT system, due to the lack of coor-\ndinated IoT-based In-home dental health care services, is devel-\noped in this paper, which plays an important role in elaborating\nits applications in home and private dental clinic scenarios. The\nproposed system builds a home-centric, self-assisted, fully au-\ntomatic intelligent In-home dental healthcare solution by taking\nadvantage of embedded intelligent hardware technology, articial\nintelligence (AI), and the mobile terminal.\nThe system closely combines the personal self-service dental\nhealth examination and dental resources through studying the\nAI method to expand the scope and coverage of traditional\ndental health care, which is the major contribution made by the\nproposed iHome smart dental Health-IoT system. Patients can\nchoose medical resources online and receive an appointment for\nmedical treatment via self-service smart dental screening.\nThe rest parts of this paper are organized as follows.\nSection II discusses smart In-home dentist system, followed\nby Section III analyzing the intelligent dental diagnosis, intro-\nducing the algorithm ﬂow and test results. Section IV presents\nthe integrated system and hardware prototype, and reports the\napplication results, and a conclusion is given in Section V\nﬁnally.\nII. S MART IN-HOME DENTIST SYSTEM\nThe occurrence of dental disease can be well predictable. For\nexample, each stage from dental plaque, calculus to dental caries\nand periodontal disease shows different characteristics and so-\nlutions, thereby making it possible to monitor the whole body\nand reduce the risk of sudden diseases effectively. It can reduce\npain, save time and reduce the cost of money for patients. How-\never, most consumers lack the correct tooth awareness, thereby\nmaking the timely treatment for tooth disease difﬁcult. More-\nover, there is a relative shortage of dental resources in hospitals.\nThese main contradictions are explained in the following aspects\nin details:\nr First, there are a lot of patients with dental diseases, but\nfewer people pay attention to the teeth. Many individ-\nuals pay for treatment only when they have teeth with\nproblems, which may cause irreversible damage to the\nlong-term development of children.\nr Second, the cost of dental treatment is relatively high.\nr Third, dental disease, due to the characteristics of elective\ntreatment, is difﬁcult to get timely treatment.\nBased on what is discussed above, a promising trend in health-\ncare is to move routine medical checks and other healthcare ser-\nvices from hospital (Hospital-Centric) to the home environment\n(Home-centric) [15], through which, the patients can get seam-\nless health care at any time in a comfortable home environment.\nEven more, it can ensure that the overall iHome dental health-\ncare system including three partspersonalized services, dental\nservices and intelligent and interactive service could be opti-\nmized to a large extent. Based on this platform, the closed",
        ".\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with the 7 types of dental\ndiseases as follows: dental caries, dental uorosis, periodontal\ndisease, cracked tooth, dental calculus, dental plaque, and tooth\nloss. 4/5 of these data was used in training, while 1/5 of them was\nin model testing, training data set and test data are respectively\nfrom different objects, thus without overlap between the testing\ndataset and the training dataset.\nB. Build Sample Set\nThe semi-automatic labeling method is applied to establish\nthe training sample set to improve the efﬁciency. The dental im-\nages were initially labeled by the design of detector for 7 types\nof dental diseases, as shown in Fig. 5 , the functions of the de-\ntector here include image enhancement, color texture matching,\ncoarse localization and classiﬁcation of disease. Followed by\nthe conﬁrmation of images with labeling error or classiﬁcation\nerror through manual screening method, the training samples\nset were ﬁnally calibrated by 20 dental disease experts, with the\ndetails as follows:\n1) Image Enhancement: In some dental images, the features\nof the tooth disease site without very high contrast are not very\nobvious, thereby making it necessary to enhance the images\nbefore designing the classiﬁcation algorithms. The Retinex al-\ngorithm is used [17], which adaptively prompts various types\nof images to achieve balance in dynamic range, edge, and color.\nThe image enhancement effect in Fig. 6 shows that the color\nand texture details of the dental disease are highlighted after the\nenhancement.\n2) Coarse Localization and Classiﬁcation of Dental Disease\nTarget Area: It is just a preliminary detecting, and only the areas\nclose to the color and texture of the image to be matched will\nbe detected as samples. Firstly, a histogram matching method\nwith fast calculation speed is used to select the region of color\nproximity, followed by the use of the Tamura texture feature\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n902 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through art",
        "3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through articial selection, along with the possible adding of\nthe undetected target images. The nished data is applied as the\ntraining sample data for the detection and classication of dental\ndiseases, ending up with the summary of the recorded frame\nimages to establish the dental training sample set.\nC. Model Training\nCommon target detection algorithms including RCNN,\nYOLO, SSD [19] only classify the target in the image. However,\nthe accurate target segmentation is benecial to the auxiliary med-\nical diagnosis, to achieve the aim of fast and accurate detection\nof dental diseases and dental area accurate segmentation. Based\non the established dental sample library, the MASK R-CNN\nmethod is chosen for the accurate detection and segmentation\nof the dental target.\nThe designed MASK R-CNN network is shown in the left\nof Fig. 6 , in which, MASK R-CNN adds a branch predicting\nthe segmentation mask in each interested area based on Faster\nR-CNN [20]. In Faster R-CNN, region of interest (RoI) pool\nis used to extract the small features from each RoI. Firstly,\nRoIPool scales the RoI represented by oating point numbers to\nFig. 7. Left: MASK R-CNN network. Right: example detections using\nMASK R-CNN on dental images test.\nthe granularity matching the feature graph, followed by parti-\ntioning of the scaled ROI, ending up with the summary of the\ncharacteristic value of each block coverage area. Such calcula-\ntions misplace the ROI and the extracted features, which, though\npossibly not affecting the classication, for the classication has\nthe certain robustness to the small amplitude transformation,\nexerts a great negative impact on the prediction of the precise\nmask of pixel level. Mask R-CNN proposes the RoI Align layer\nto remove the dislocation of RoIPool and aligns the extracted\nfeatures with the input accurately. In RoI Align, a bilinear in-\nterpolation is used to calculate the exact value of each position,\nalong with the summary of the results by using the maximum\nor average pooling, and the extracted features and input can be\naligned with the pixel to pixel, thereby improving the segmen-\ntation accuracy effectively. For the lower convolution network\nused for feature extraction on the whole image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN AN"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2559
    },
    {
      "id": "Q12",
      "question": "Is the performance of the predictive models benchmarked or compared to a baseline?",
      "answer": "Yes, compared to related work.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        8,
        10,
        7
      ],
      "chunks_str": [
        " image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN ANCHOR SCALES are set. The sample\ndata is transferred from the 16-bit grayscale to 8-bit grayscale,\nthen copied to the training directory to execute the training code.\nThe data sets for each dental disease were basically balanced,\nand the method of limiting training time is adopted to avoid\noverﬁtting, with the detection results using MASK R-CNN on\ndental images being shown in the right of Fig. 7 .\nD. Inference\nRecognition rate in this study refers to the rate at which dental\ndiseases can be correctly identiﬁed in these testing image data.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 903\nT ABLE II\nTHE RECOGNITION ACCURACY OF 7T YPES OF DENT AL DISEASES\nFig. 8. A board level prototype of the intelligent dental image acquisition\ndevicet.\nThe algorithm above is followed to train the model following the\n4-step training of Faster R-CNN [22], with the Table II showing\nthe recognition accuracy of each dental disease. The table shows\nthat we can ﬁnd good results achieved by MASK R-CNN even\nunder challenging conditions, such as the reection of saliva,\ntooth gap, etc. The recognition rate of the algorithm is over 90%\nfor these seven major dental diseases, with the recognition rate\nof dental plaque as 100%, and the recognition rate of decayed\ntooth as 90.1%. It is analyzed that relatively low recognition rate\nof decayed tooth is attributed to the device using a xed focus\nlens, which will be affected by the shooting, such as smear\nand defocusing blurring. In addition, coding errors and missing\nframes can also be responsible for it. Compared with the related\nwork in [14], the accuracy of the presented transfer learning\nmethod for the classication of dental caries and periodontitis\nare all 87.5 %. This work achieves an accuracy of 90.1% and\n94.3% respectively, indicating that the classication accuracy of\ncorresponding dental diseases has been greatly improved in our\nwork.\nIV . S YSTEM INTEGRA TION AND PROTOTYPE IMPLEMENT A TION\nA. System Implementation\nThe PCB hardware of the intelligent dental image acquisition\ndevice is designed and completed, as well as the APP soft-\nware for android and apple system, with the motherboard and\nthe phone communicating via Wi-Fi. As shown in Fig. 8 ,t h e\nhardware motherboard is a circular plate with 6cm of diameter,\nwhich is suitable for being held in hands, and can be inserted\ninto the mouth exibly to collect images of the teeth. A small\npercentage of the collected images, due to the lack of",
        " as dental caries\nbetween the teeth, smoke scale.\nC. System Integration Testing\nVia the client-side APP , the users, if logging in for the ﬁrst\ntime, have to register information, and set up the network\nconnection parameters for the device, then enter the dental\ndisease detection process normally, with the dental photo\nbeing uploaded to the algorithm server for artiﬁcial intelligence\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n904 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE III\nSENSITIVITY AND SPECIFICITY OF 7T YPES OF DENT AL DISEASES\nFig. 9. The APPs running interface.\nanalysis, and the patient will enter the doctor’s appointment pro-\ncess if the dental disease is found in the analysis results. It is also\npossible for users to learn about dental care knowledge, the lat-\nest treatment technologies and products through the client-side\nAPP .\nVia the doctor-side APP , the dentist can enter the normal work\nmode after ﬁnishing the registration, and the dentist, if receiv-\ning the patient diagnosis request, will respond to the request,\ncoordinate treatment time with the patient. Meanwhile, dentists\ncan manage their own patients and track the effects, with Fig. 9\nshowing parts of the APPs running interface.\nD. The Diagnostic Efﬁciency\nWe carried on a systematic testing in 10 private dental clinics,\nwith a total of 25 dentists being used the dentist-side APP , and\nFig. 10. (a) Comparison chart of patient numbers. (b) The mean diag-\nnosis time comparison chart.\nthen counted the working hours of each dentist, the number of\npatients received and the mean time of diagnosis after a month.\nFig. 10 shows the statistical results, suggesting that compared\nwith the traditional way, the number of treated patients with\nthe help of smart dental service increases by 18.4%, while the\nmean diagnosis time reduces by at least 37.5%. Investigation\nand analysis show that patients capable of using the intelligent\ndental image acquisition device and AI analysis to perform pre-\nscreening at home are responsible for it. In short, compared to\nthe traditional way of checking in the dental clinic, this method\ncan save 25–30 minutes of the diagnosis time. Another interest-\ning factor is that dentists often take some time to explain and\ncommunicate with the patients after diagnosis in private dental\nclinics, while patients can acquire the relevant knowledge on\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 905\nT ABLE IV\nTHE RECOGNITION RESUL TS\ndental diseases at the iHome smart dental Health-IoT platform\nafter self-examination.\nIn this test, the recognition results of the algorithm in the\nreal environment have bene counted, with the sample distribu-\ntion and recognition results being shown in Table IV . Statis-\ntically, we found that the reason for the signiﬁcant inﬂuence\non the recognition rate was still owing to the fact that the pa-\ntients were not particularly skillful at using the intelligent den-\ntal image acquisition equipment. Compared with the results in\nTable II above, the results in Table IV show no signiﬁcant ﬂuctu-\nation, indicating that the algorithm is highly reliable",
        "3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through articial selection, along with the possible adding of\nthe undetected target images. The nished data is applied as the\ntraining sample data for the detection and classication of dental\ndiseases, ending up with the summary of the recorded frame\nimages to establish the dental training sample set.\nC. Model Training\nCommon target detection algorithms including RCNN,\nYOLO, SSD [19] only classify the target in the image. However,\nthe accurate target segmentation is benecial to the auxiliary med-\nical diagnosis, to achieve the aim of fast and accurate detection\nof dental diseases and dental area accurate segmentation. Based\non the established dental sample library, the MASK R-CNN\nmethod is chosen for the accurate detection and segmentation\nof the dental target.\nThe designed MASK R-CNN network is shown in the left\nof Fig. 6 , in which, MASK R-CNN adds a branch predicting\nthe segmentation mask in each interested area based on Faster\nR-CNN [20]. In Faster R-CNN, region of interest (RoI) pool\nis used to extract the small features from each RoI. Firstly,\nRoIPool scales the RoI represented by oating point numbers to\nFig. 7. Left: MASK R-CNN network. Right: example detections using\nMASK R-CNN on dental images test.\nthe granularity matching the feature graph, followed by parti-\ntioning of the scaled ROI, ending up with the summary of the\ncharacteristic value of each block coverage area. Such calcula-\ntions misplace the ROI and the extracted features, which, though\npossibly not affecting the classication, for the classication has\nthe certain robustness to the small amplitude transformation,\nexerts a great negative impact on the prediction of the precise\nmask of pixel level. Mask R-CNN proposes the RoI Align layer\nto remove the dislocation of RoIPool and aligns the extracted\nfeatures with the input accurately. In RoI Align, a bilinear in-\nterpolation is used to calculate the exact value of each position,\nalong with the summary of the results by using the maximum\nor average pooling, and the extracted features and input can be\naligned with the pixel to pixel, thereby improving the segmen-\ntation accuracy effectively. For the lower convolution network\nused for feature extraction on the whole image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN AN"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2576
    },
    {
      "id": "Q13",
      "question": "Which type of explainability techniques are used?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        2,
        7,
        5
      ],
      "chunks_str": [
        " [12],\nwhich is also used to implement the automated segmentation of\ngingival diseases from oral images [13]. In [14], the approaches\nof CNN and transfer learning are used in dental diseases, and\nthe above artiﬁcial intelligence methods for dental are based\n2168-2194 © 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\nSee https://www.ieee.org/publications/rights/index.html for more information.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 899\non X-ray. However, visual diagnosis serves as one of the most\nimportant parts of dental health care.\nThe smart dental health IoT system, due to the lack of coor-\ndinated IoT-based In-home dental health care services, is devel-\noped in this paper, which plays an important role in elaborating\nits applications in home and private dental clinic scenarios. The\nproposed system builds a home-centric, self-assisted, fully au-\ntomatic intelligent In-home dental healthcare solution by taking\nadvantage of embedded intelligent hardware technology, articial\nintelligence (AI), and the mobile terminal.\nThe system closely combines the personal self-service dental\nhealth examination and dental resources through studying the\nAI method to expand the scope and coverage of traditional\ndental health care, which is the major contribution made by the\nproposed iHome smart dental Health-IoT system. Patients can\nchoose medical resources online and receive an appointment for\nmedical treatment via self-service smart dental screening.\nThe rest parts of this paper are organized as follows.\nSection II discusses smart In-home dentist system, followed\nby Section III analyzing the intelligent dental diagnosis, intro-\nducing the algorithm ﬂow and test results. Section IV presents\nthe integrated system and hardware prototype, and reports the\napplication results, and a conclusion is given in Section V\nﬁnally.\nII. S MART IN-HOME DENTIST SYSTEM\nThe occurrence of dental disease can be well predictable. For\nexample, each stage from dental plaque, calculus to dental caries\nand periodontal disease shows different characteristics and so-\nlutions, thereby making it possible to monitor the whole body\nand reduce the risk of sudden diseases effectively. It can reduce\npain, save time and reduce the cost of money for patients. How-\never, most consumers lack the correct tooth awareness, thereby\nmaking the timely treatment for tooth disease difﬁcult. More-\nover, there is a relative shortage of dental resources in hospitals.\nThese main contradictions are explained in the following aspects\nin details:\nr First, there are a lot of patients with dental diseases, but\nfewer people pay attention to the teeth. Many individ-\nuals pay for treatment only when they have teeth with\nproblems, which may cause irreversible damage to the\nlong-term development of children.\nr Second, the cost of dental treatment is relatively high.\nr Third, dental disease, due to the characteristics of elective\ntreatment, is difﬁcult to get timely treatment.\nBased on what is discussed above, a promising trend in health-\ncare is to move routine medical checks and other healthcare ser-\nvices from hospital (Hospital-Centric) to the home environment\n(Home-centric) [15], through which, the patients can get seam-\nless health care at any time in a comfortable home environment.\nEven more, it can ensure that the overall iHome dental health-\ncare system including three partspersonalized services, dental\nservices and intelligent and interactive service could be opti-\nmized to a large extent. Based on this platform, the closed",
        "3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through articial selection, along with the possible adding of\nthe undetected target images. The nished data is applied as the\ntraining sample data for the detection and classication of dental\ndiseases, ending up with the summary of the recorded frame\nimages to establish the dental training sample set.\nC. Model Training\nCommon target detection algorithms including RCNN,\nYOLO, SSD [19] only classify the target in the image. However,\nthe accurate target segmentation is benecial to the auxiliary med-\nical diagnosis, to achieve the aim of fast and accurate detection\nof dental diseases and dental area accurate segmentation. Based\non the established dental sample library, the MASK R-CNN\nmethod is chosen for the accurate detection and segmentation\nof the dental target.\nThe designed MASK R-CNN network is shown in the left\nof Fig. 6 , in which, MASK R-CNN adds a branch predicting\nthe segmentation mask in each interested area based on Faster\nR-CNN [20]. In Faster R-CNN, region of interest (RoI) pool\nis used to extract the small features from each RoI. Firstly,\nRoIPool scales the RoI represented by oating point numbers to\nFig. 7. Left: MASK R-CNN network. Right: example detections using\nMASK R-CNN on dental images test.\nthe granularity matching the feature graph, followed by parti-\ntioning of the scaled ROI, ending up with the summary of the\ncharacteristic value of each block coverage area. Such calcula-\ntions misplace the ROI and the extracted features, which, though\npossibly not affecting the classication, for the classication has\nthe certain robustness to the small amplitude transformation,\nexerts a great negative impact on the prediction of the precise\nmask of pixel level. Mask R-CNN proposes the RoI Align layer\nto remove the dislocation of RoIPool and aligns the extracted\nfeatures with the input accurately. In RoI Align, a bilinear in-\nterpolation is used to calculate the exact value of each position,\nalong with the summary of the results by using the maximum\nor average pooling, and the extracted features and input can be\naligned with the pixel to pixel, thereby improving the segmen-\ntation accuracy effectively. For the lower convolution network\nused for feature extraction on the whole image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN AN",
        "namely, client, service platform and doctor at the application\nlogic level. Users capture pictures using intelligent dental im-\nage data acquisition device, and then upload the pictures to the\nservice platform through the mobile terminal, and these den-\ntal image data will be analyzed using AI methods. The system\nwill advise the user to seek for medical care if problems have\nbeen found in teeth after the conﬁrmation of the service by the\nuser. Nearby dental clinics or doctors based on their geographic\nlocation will be recommended at the service platform, thereby\nmaking it possible for users to consult with doctors to make\nappointments and complete ofﬂine medical procedures if the\nappointment is successful.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 901\nFig. 4. The intelligent dental image acquisition device hardware\ndiagram.\nC. Intelligent Hardware\nTraditional dental image collection methods can bring about\nthe inconvenience as follows:\nr Dentists are required to acquire knowledge on more shoot-\ning skills;\nr It is necessary to expand the auxiliary equipment such as\nthe oral expander, along with high cost of the SLR camera.\nr Only partial dental images can be obtained\nDue to the peculiarity of oral structure, the general image\nacquisition equipment (e.g. smart cell-phone) cant meet the im-\nage data collection requirement of 6 surfaces of teeth, thereby\nhelping explain that an intelligent dental image acquisition de-\nvice is designed to photograph dental images. As shown in the\nFig. 4 , the intelligent dental image acquisition device is mainly\ncomposed of an image module and the control board, and the\nmicro exible packaging technology is applied to manufacture\nthe image module. On the exible printed circuit board, it is in-\ntegrated with a 1-megapixel CMOS Sensor, the supplementary\nlighting LEDs, and a macro lens to form a module.\nIncluding processing chip, Wi-Fi module, gyroscope, mem-\nory, keys, LEDs, power management and wireless charger, the\nmain board has functions such as video encoding, interface con-\ntrol, light control and task processing. Additionally, the device\ncan be communicated with the mobile terminal through the Wi-\nFi module. When photographing the teeth, the left-side images\nand right-side images are ﬂipped, with the use of a gyroscope\nsensor in the hardware design [16]. Moreover, In the process\nof shooting, the processor can sense the change signal, and then\ncorrect the image position with the software automatically.\nIII. I NTELLIGENT DENT AL DIAGNOSIS\nA. System Flow and Data Acquisition\nAI detection of dental diseases is the most important part of\nthe intelligent dental Health-IoT platform, and the main steps\nFig. 5. Dental image analysis system ﬂow.\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2571
    },
    {
      "id": "Q14",
      "question": "Which evaluation metrics or outcome measures are used to assess the predictive models?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        13,
        7,
        6
      ],
      "chunks_str": [
        " interconnected devices promise\nmore efﬁcient and comprehensive health care,” IEEE Pulse , vol. 7, no. 5,\npp. 35–39, Sep./Oct. 2016.\n[7] P . Sundaravadivel, E. Kougianos, S. P . Mohanty, and M. K. Ganapathiraju,\n“Everything you wanted to know about smart health care: Evaluating the\ndifferent technologies and components of the internet of things for better\nhealth,” IEEE Consum. Electron. Mag. , vol. 7, no. 1, pp. 18–28, Jan. 2017.\n[8] J. Arevalo, F. A. Gonzalez, R. Ramos-Pollan, J. L. Oliveira, and M. A.\nGuevara Lopez, “Convolutional neural networks for mammography mass\nlesion classiﬁcation,” in Proc. Conf. IEEE Eng. Med. Biol. Soc. , 2015,\nvol. 2015, pp. 797–800.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n906 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\n[9] H. I. Suk, S. W. Lee, and D. Shen, “Deep sparse multi-task learning for\nfeature selection in alzheimer’s disease diagnosis,” Brain Struct. Funct. ,\nvol. 221, no. 5, pp. 2569–2587, 2016.\n[10] A. Kwasigroch, A. Mikoajczyk, and M. Grochowski, “Deep con-\nvolutional neural networks as a decision support tool in medical\nproblems—Malignant melanoma case study,” in Trends in Advanced\nIntelligent Control, Optimization and Automation (Advances in In-\ntelligent Systems and Computing). New Y ork, NY , USA: Springer,\n2017.\n[11] A. Esteva et al. , “Dermatologist-level classiﬁcation of skin cancer\nwith deep neural networks,” Nature, vol. 542, no. 7639, pp. 115–118,\n2017.\n[12] A. B. Oktay and Y . S. Akgul, “Diagnosis of degenerative intervertebral\ndisc disease with deep networks and SVM,” in Computer and Information\nSciences. New Y ork, NY , USA: Springer, 2016.\n[13] D. H. Wolpert and W. G. Macready, “No free lunch theorems for op-\ntimization,” IEEE Trans. Evol. Comput. , vol. 1, no. 1, pp. 67–82, Apr.\n1997.\n[14] S. A. Prajapati, R. Nagaraj, and S. Mitra, “Classiﬁcation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—",
        "3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through articial selection, along with the possible adding of\nthe undetected target images. The nished data is applied as the\ntraining sample data for the detection and classication of dental\ndiseases, ending up with the summary of the recorded frame\nimages to establish the dental training sample set.\nC. Model Training\nCommon target detection algorithms including RCNN,\nYOLO, SSD [19] only classify the target in the image. However,\nthe accurate target segmentation is benecial to the auxiliary med-\nical diagnosis, to achieve the aim of fast and accurate detection\nof dental diseases and dental area accurate segmentation. Based\non the established dental sample library, the MASK R-CNN\nmethod is chosen for the accurate detection and segmentation\nof the dental target.\nThe designed MASK R-CNN network is shown in the left\nof Fig. 6 , in which, MASK R-CNN adds a branch predicting\nthe segmentation mask in each interested area based on Faster\nR-CNN [20]. In Faster R-CNN, region of interest (RoI) pool\nis used to extract the small features from each RoI. Firstly,\nRoIPool scales the RoI represented by oating point numbers to\nFig. 7. Left: MASK R-CNN network. Right: example detections using\nMASK R-CNN on dental images test.\nthe granularity matching the feature graph, followed by parti-\ntioning of the scaled ROI, ending up with the summary of the\ncharacteristic value of each block coverage area. Such calcula-\ntions misplace the ROI and the extracted features, which, though\npossibly not affecting the classication, for the classication has\nthe certain robustness to the small amplitude transformation,\nexerts a great negative impact on the prediction of the precise\nmask of pixel level. Mask R-CNN proposes the RoI Align layer\nto remove the dislocation of RoIPool and aligns the extracted\nfeatures with the input accurately. In RoI Align, a bilinear in-\nterpolation is used to calculate the exact value of each position,\nalong with the summary of the results by using the maximum\nor average pooling, and the extracted features and input can be\naligned with the pixel to pixel, thereby improving the segmen-\ntation accuracy effectively. For the lower convolution network\nused for feature extraction on the whole image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN AN",
        ".\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with the 7 types of dental\ndiseases as follows: dental caries, dental uorosis, periodontal\ndisease, cracked tooth, dental calculus, dental plaque, and tooth\nloss. 4/5 of these data was used in training, while 1/5 of them was\nin model testing, training data set and test data are respectively\nfrom different objects, thus without overlap between the testing\ndataset and the training dataset.\nB. Build Sample Set\nThe semi-automatic labeling method is applied to establish\nthe training sample set to improve the efﬁciency. The dental im-\nages were initially labeled by the design of detector for 7 types\nof dental diseases, as shown in Fig. 5 , the functions of the de-\ntector here include image enhancement, color texture matching,\ncoarse localization and classiﬁcation of disease. Followed by\nthe conﬁrmation of images with labeling error or classiﬁcation\nerror through manual screening method, the training samples\nset were ﬁnally calibrated by 20 dental disease experts, with the\ndetails as follows:\n1) Image Enhancement: In some dental images, the features\nof the tooth disease site without very high contrast are not very\nobvious, thereby making it necessary to enhance the images\nbefore designing the classiﬁcation algorithms. The Retinex al-\ngorithm is used [17], which adaptively prompts various types\nof images to achieve balance in dynamic range, edge, and color.\nThe image enhancement effect in Fig. 6 shows that the color\nand texture details of the dental disease are highlighted after the\nenhancement.\n2) Coarse Localization and Classiﬁcation of Dental Disease\nTarget Area: It is just a preliminary detecting, and only the areas\nclose to the color and texture of the image to be matched will\nbe detected as samples. Firstly, a histogram matching method\nwith fast calculation speed is used to select the region of color\nproximity, followed by the use of the Tamura texture feature\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n902 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through art"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2558
    },
    {
      "id": "Q15",
      "question": "What considerations were given to selected evaluation metrics or outcome measures in this study?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        13,
        7,
        6
      ],
      "chunks_str": [
        " interconnected devices promise\nmore efﬁcient and comprehensive health care,” IEEE Pulse , vol. 7, no. 5,\npp. 35–39, Sep./Oct. 2016.\n[7] P . Sundaravadivel, E. Kougianos, S. P . Mohanty, and M. K. Ganapathiraju,\n“Everything you wanted to know about smart health care: Evaluating the\ndifferent technologies and components of the internet of things for better\nhealth,” IEEE Consum. Electron. Mag. , vol. 7, no. 1, pp. 18–28, Jan. 2017.\n[8] J. Arevalo, F. A. Gonzalez, R. Ramos-Pollan, J. L. Oliveira, and M. A.\nGuevara Lopez, “Convolutional neural networks for mammography mass\nlesion classiﬁcation,” in Proc. Conf. IEEE Eng. Med. Biol. Soc. , 2015,\nvol. 2015, pp. 797–800.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n906 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\n[9] H. I. Suk, S. W. Lee, and D. Shen, “Deep sparse multi-task learning for\nfeature selection in alzheimer’s disease diagnosis,” Brain Struct. Funct. ,\nvol. 221, no. 5, pp. 2569–2587, 2016.\n[10] A. Kwasigroch, A. Mikoajczyk, and M. Grochowski, “Deep con-\nvolutional neural networks as a decision support tool in medical\nproblems—Malignant melanoma case study,” in Trends in Advanced\nIntelligent Control, Optimization and Automation (Advances in In-\ntelligent Systems and Computing). New Y ork, NY , USA: Springer,\n2017.\n[11] A. Esteva et al. , “Dermatologist-level classiﬁcation of skin cancer\nwith deep neural networks,” Nature, vol. 542, no. 7639, pp. 115–118,\n2017.\n[12] A. B. Oktay and Y . S. Akgul, “Diagnosis of degenerative intervertebral\ndisc disease with deep networks and SVM,” in Computer and Information\nSciences. New Y ork, NY , USA: Springer, 2016.\n[13] D. H. Wolpert and W. G. Macready, “No free lunch theorems for op-\ntimization,” IEEE Trans. Evol. Comput. , vol. 1, no. 1, pp. 67–82, Apr.\n1997.\n[14] S. A. Prajapati, R. Nagaraj, and S. Mitra, “Classiﬁcation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—",
        "3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through articial selection, along with the possible adding of\nthe undetected target images. The nished data is applied as the\ntraining sample data for the detection and classication of dental\ndiseases, ending up with the summary of the recorded frame\nimages to establish the dental training sample set.\nC. Model Training\nCommon target detection algorithms including RCNN,\nYOLO, SSD [19] only classify the target in the image. However,\nthe accurate target segmentation is benecial to the auxiliary med-\nical diagnosis, to achieve the aim of fast and accurate detection\nof dental diseases and dental area accurate segmentation. Based\non the established dental sample library, the MASK R-CNN\nmethod is chosen for the accurate detection and segmentation\nof the dental target.\nThe designed MASK R-CNN network is shown in the left\nof Fig. 6 , in which, MASK R-CNN adds a branch predicting\nthe segmentation mask in each interested area based on Faster\nR-CNN [20]. In Faster R-CNN, region of interest (RoI) pool\nis used to extract the small features from each RoI. Firstly,\nRoIPool scales the RoI represented by oating point numbers to\nFig. 7. Left: MASK R-CNN network. Right: example detections using\nMASK R-CNN on dental images test.\nthe granularity matching the feature graph, followed by parti-\ntioning of the scaled ROI, ending up with the summary of the\ncharacteristic value of each block coverage area. Such calcula-\ntions misplace the ROI and the extracted features, which, though\npossibly not affecting the classication, for the classication has\nthe certain robustness to the small amplitude transformation,\nexerts a great negative impact on the prediction of the precise\nmask of pixel level. Mask R-CNN proposes the RoI Align layer\nto remove the dislocation of RoIPool and aligns the extracted\nfeatures with the input accurately. In RoI Align, a bilinear in-\nterpolation is used to calculate the exact value of each position,\nalong with the summary of the results by using the maximum\nor average pooling, and the extracted features and input can be\naligned with the pixel to pixel, thereby improving the segmen-\ntation accuracy effectively. For the lower convolution network\nused for feature extraction on the whole image, the ResNet-50-\nC4 backbone [20], [21] is adopted with the depth of 50 layers,\nand extract features from the nal convolution layer of the fourth\nstage in the MASK R-CNN. For the upper network, we extend\nthe Faster R-CNN upper network proposed in ResNet, adding a\nmask branch respectively. TensorFlow and Mask R-CNN open\nsource are adopted in the training model, along with modiﬁca-\ntion of ShapesCong class, and GPU COUNT and IMAGES PER\nGPU are set to 1 according to the training server conguration.\nAt the same time, according to the training sample library, cate-\ngories NUM CLASSES, image size IMAGE MIN DIM and the\nsize of the anchor RPN AN",
        ".\ninclude teeth cases images collection, the sample set building,\nand model training to achieve this goal. The system ﬂowchart is\nshown in Fig. 5 .\nDue to the lack of dental diseases standard data sets, we\nworked with some dental clinics (such as Beijing Mei-Xiao\ndental clinics). With the consent of the subjects, 300 subjects\nuse dental image acquisition device to sample the dental diseases\nvideo data, and the algorithm analyzes each frame of video, and\n3835 images of dental cases are sampled ﬁnally. These clinics\nalready have 8,765 images of dental cases, with a total of 12,600\nclinical images being collected. These images are classiﬁed into\n7 different types as shown in Table I, with the 7 types of dental\ndiseases as follows: dental caries, dental uorosis, periodontal\ndisease, cracked tooth, dental calculus, dental plaque, and tooth\nloss. 4/5 of these data was used in training, while 1/5 of them was\nin model testing, training data set and test data are respectively\nfrom different objects, thus without overlap between the testing\ndataset and the training dataset.\nB. Build Sample Set\nThe semi-automatic labeling method is applied to establish\nthe training sample set to improve the efﬁciency. The dental im-\nages were initially labeled by the design of detector for 7 types\nof dental diseases, as shown in Fig. 5 , the functions of the de-\ntector here include image enhancement, color texture matching,\ncoarse localization and classiﬁcation of disease. Followed by\nthe conﬁrmation of images with labeling error or classiﬁcation\nerror through manual screening method, the training samples\nset were ﬁnally calibrated by 20 dental disease experts, with the\ndetails as follows:\n1) Image Enhancement: In some dental images, the features\nof the tooth disease site without very high contrast are not very\nobvious, thereby making it necessary to enhance the images\nbefore designing the classiﬁcation algorithms. The Retinex al-\ngorithm is used [17], which adaptively prompts various types\nof images to achieve balance in dynamic range, edge, and color.\nThe image enhancement effect in Fig. 6 shows that the color\nand texture details of the dental disease are highlighted after the\nenhancement.\n2) Coarse Localization and Classiﬁcation of Dental Disease\nTarget Area: It is just a preliminary detecting, and only the areas\nclose to the color and texture of the image to be matched will\nbe detected as samples. Firstly, a histogram matching method\nwith fast calculation speed is used to select the region of color\nproximity, followed by the use of the Tamura texture feature\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n902 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE I\nDISTRIBUTION OF DENT AL DISEASE TYPES\nFig. 6. Dental images enhancement comparison chart.\nalgorithm by this design [18], which is applied to ﬁnd the\nimage area blocks close to the sample image.\n3) Artiﬁcial Screening Determines the Sample Library: For\nthe image areas after coarse location and classication, the anno-\ntation information of each frame of data needs to be manually\nconﬁrmed by dental disease experts. Labelme tool is used to gen-\nerate mask data set, along with description of the segmentation\nregion of dental disease as accurate as possible with multiple key\npoints. We delete the wrong label positions and ﬁx the wrong\ntags through art"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2559
    },
    {
      "id": "Q16",
      "question": "How were robustness, confidence or statistical significance of the results assessed in this study?",
      "answer": "one-month testing in 10 clinics",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        12,
        11,
        13
      ],
      "chunks_str": [
        "iﬁcant impact on the anal-\nysis of artiﬁcial intelligence. Therefore, the future work will\ngive more priority to the improvement of the hardware design\nand the efﬁciency of image acquisition device, and further work\nwill focus on improving algorithm efﬁciency and recognition\nrate, reducing false alarm rate, and setting up a larger image\ndata set for dental diseases.\nV. C ONCLUSION\nThis paper proposes an iHome smart dental Health-IoT sys-\ntem based on intelligent hardware, deep learning and mobile\nterminal, aiming to regulate as well as optimize the accessibil-\nity of dental treatment and provide home-based dental health\ncare service more efciently. The trained model was used to\nrealize the detection and classication of dental diseases, and\napplication software (Apps) on mobile terminal was designed\nfor client-side and dentist-side. The software platform with the\nfunctions including pre-examination of dental disease, consulta-\ntion, appointment, and evaluation, etc, made the service docking\nbetween the patient and the dentist resources a reality. The AI\nalgorithm achieved more than 90% recognition rate for seven\ndental diseases., which has greatly improved the patient rate and\nthe resource utilization rate of the dental clinic through a one-\nmonth systematic testing in 10 private dental clinics, showing\nhigh reliability in practical application.\nREFERENCES\n[1] Z. Qian, “Opportunities abound for dental care in China,” China\nBrieﬁng, Feb. 2015. [Online]. Available: http://www.china-brieﬁng.com/\nnews/2015/02/27/opportunities-abound-dental-care-china.html\n[2] P . J. Pussinen, P . Jousilahti, G. Alfthan, T. Palosuo, S. Asikainen, and V .\nSalomaa, “Antibodies to periodontal pathogens are associated with coro-\nnary heart disease,” Arteriosclerosis Thrombosis V ascular Biol. , vol. 23,\nno. 7, 2003, pp. 1250–1254.\n[3] H. Jansson et al. , “Type 2 diabetes and risk for periodontal disease: A\nrole for dental health awareness,” J. Clinical Periodontol. , vol. 33, no. 6,\npp. 408–414, 2006.\n[4] N. W. Johnson, “The mouth in HIV/AIDS: Markers of disease status and\nmanagement challenges for the dental profession,” Australian Dental J. ,\nvol. 55, no. s1, pp. 85–102, 2010.\n[5] L. Atzori, A. Iera, and G. Morabito, The Internet of Things: A Survey .\nAmsterdam, The Netherlands: Elsevier, 2010.\n[6] D. Metcalf, S. T. Milliard, M. Gomez, and M. Schwartz, “Wearables and\nthe internet of things for health: Wearable, interconnected devices promise\nmore efﬁcient and comprehensive health care,” IEEE Pulse , vol. 7, no. 5,\npp. 35–39, Sep./Oct. 2016.\n[7] P . Sundaravadivel, E. Kougianos, S. P . Mohanty, and M. K. Ganapathiraju,\n“Everything you wanted to know about smart health care: Evaluating the\ndifferent technologies and components of the internet of things for better\nhealth,” IEEE Consum. Electron. Mag. , vol. 7, no. 1, pp. 18–28, Jan. 2017.\n[8] J. Arevalo, F. A. Gonzalez, R. Ramos-Pollan, J. L.",
        "905\nT ABLE IV\nTHE RECOGNITION RESUL TS\ndental diseases at the iHome smart dental Health-IoT platform\nafter self-examination.\nIn this test, the recognition results of the algorithm in the\nreal environment have bene counted, with the sample distribu-\ntion and recognition results being shown in Table IV . Statis-\ntically, we found that the reason for the signiﬁcant inﬂuence\non the recognition rate was still owing to the fact that the pa-\ntients were not particularly skillful at using the intelligent den-\ntal image acquisition equipment. Compared with the results in\nTable II above, the results in Table IV show no signiﬁcant ﬂuctu-\nation, indicating that the algorithm is highly reliable in practical\napplication.\nE. Discussion\nThe individual home environment is connected with the hos-\npital, dental clinics, and other medical facilities through the\ndeveloped iHome smart dental Health-IoT system, thereby pro-\nviding remote diagnosis and medical service, with the key in-\nnovation and functionality as follows.\n1) Oral Disease Prevention: The investigation showed a low\nawareness of tooth protection for most patients in China. Usu-\nally, they will choose to diagnose and treat their teeth after\nfeeling certain discomfort. The iHome smart dental Health-IoT\nsystem provides users with a convenient platform for the self-\nexamination. To be more speciﬁc, dental diseases of users can\nbe detected and prevented early with the help of AI analysis, as\nwell as raising individuals’ awareness of tooth protection.\n2) Intelligent Analysis: The proposed iHome smart dental\nHealth-IoT system performs AI analysis on dental images us-\ning deep learning algorithm, which can quickly and effectively\ndetect tooth diseases, thereby providing a diagnostic basis for\ndentists and saving treatment time.\n3) Remote Medical Service: The interactive platform of the\niHome smart dental Health-IoT system makes a direct ap-\npointment to the nearest dentists and prompts them to medi-\ncal treatment in a low-price and time-saving manner. This new\ninternet mode can mobilize the dental diagnostic resources rel-\natively idle. Patients are able to solve their dental problems\nat lower price, which is attributed to the fact that on the one\nhand, the intelligent dental image acquisition device costs less,\nand on the other hand, the platform has been able to mobi-\nlize some idle dental clinics where clients can go for treat-\nment. In this way, the cost per customer will be reduced as the\nnumber of users increases. The platform establishes a unique\nword-of-mouth system for dentists, with the evaluation from\nthe patients after treatment promoting further improvement in\nthe quality of dentist service, making it possible for the user to\nchoose some cost-effective clinics for treatment.\nThe implemented intelligent hardware provides a way to ob-\ntain dental image data, but the use of prime lens brings image\nblurring and ghosting in the process of test. In addition, the lack\nof lens angle results in the incomplete coverage of larger teeth.\nThese problems exert a relatively signiﬁcant impact on the anal-\nysis of artiﬁcial intelligence. Therefore, the future work will\ngive more priority to the improvement of the hardware design\nand the efﬁciency of image acquisition device, and further work\nwill focus on improving algorithm efﬁciency and recognition\nrate, reducing false alarm rate, and setting up a larger image\ndata set for dental diseases.\nV. C ONCLUSION\nThis paper proposes an iHome smart dental Health-IoT sys-\ntem based on intelligent hardware, deep learning and mobile\nterminal, aiming to regulate as well as optimize the accessibil-\nity of dental treatment and provide home-based dental health\ncare service more efciently. The trained model was used to\nrealize the detection and classication of dental diseases,",
        " interconnected devices promise\nmore efﬁcient and comprehensive health care,” IEEE Pulse , vol. 7, no. 5,\npp. 35–39, Sep./Oct. 2016.\n[7] P . Sundaravadivel, E. Kougianos, S. P . Mohanty, and M. K. Ganapathiraju,\n“Everything you wanted to know about smart health care: Evaluating the\ndifferent technologies and components of the internet of things for better\nhealth,” IEEE Consum. Electron. Mag. , vol. 7, no. 1, pp. 18–28, Jan. 2017.\n[8] J. Arevalo, F. A. Gonzalez, R. Ramos-Pollan, J. L. Oliveira, and M. A.\nGuevara Lopez, “Convolutional neural networks for mammography mass\nlesion classiﬁcation,” in Proc. Conf. IEEE Eng. Med. Biol. Soc. , 2015,\nvol. 2015, pp. 797–800.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n906 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\n[9] H. I. Suk, S. W. Lee, and D. Shen, “Deep sparse multi-task learning for\nfeature selection in alzheimer’s disease diagnosis,” Brain Struct. Funct. ,\nvol. 221, no. 5, pp. 2569–2587, 2016.\n[10] A. Kwasigroch, A. Mikoajczyk, and M. Grochowski, “Deep con-\nvolutional neural networks as a decision support tool in medical\nproblems—Malignant melanoma case study,” in Trends in Advanced\nIntelligent Control, Optimization and Automation (Advances in In-\ntelligent Systems and Computing). New Y ork, NY , USA: Springer,\n2017.\n[11] A. Esteva et al. , “Dermatologist-level classiﬁcation of skin cancer\nwith deep neural networks,” Nature, vol. 542, no. 7639, pp. 115–118,\n2017.\n[12] A. B. Oktay and Y . S. Akgul, “Diagnosis of degenerative intervertebral\ndisc disease with deep networks and SVM,” in Computer and Information\nSciences. New Y ork, NY , USA: Springer, 2016.\n[13] D. H. Wolpert and W. G. Macready, “No free lunch theorems for op-\ntimization,” IEEE Trans. Evol. Comput. , vol. 1, no. 1, pp. 67–82, Apr.\n1997.\n[14] S. A. Prajapati, R. Nagaraj, and S. Mitra, “Classiﬁcation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2538
    },
    {
      "id": "Q17",
      "question": "What limitations of the study were discussed?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        13,
        2,
        14
      ],
      "chunks_str": [
        " interconnected devices promise\nmore efﬁcient and comprehensive health care,” IEEE Pulse , vol. 7, no. 5,\npp. 35–39, Sep./Oct. 2016.\n[7] P . Sundaravadivel, E. Kougianos, S. P . Mohanty, and M. K. Ganapathiraju,\n“Everything you wanted to know about smart health care: Evaluating the\ndifferent technologies and components of the internet of things for better\nhealth,” IEEE Consum. Electron. Mag. , vol. 7, no. 1, pp. 18–28, Jan. 2017.\n[8] J. Arevalo, F. A. Gonzalez, R. Ramos-Pollan, J. L. Oliveira, and M. A.\nGuevara Lopez, “Convolutional neural networks for mammography mass\nlesion classiﬁcation,” in Proc. Conf. IEEE Eng. Med. Biol. Soc. , 2015,\nvol. 2015, pp. 797–800.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\n906 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\n[9] H. I. Suk, S. W. Lee, and D. Shen, “Deep sparse multi-task learning for\nfeature selection in alzheimer’s disease diagnosis,” Brain Struct. Funct. ,\nvol. 221, no. 5, pp. 2569–2587, 2016.\n[10] A. Kwasigroch, A. Mikoajczyk, and M. Grochowski, “Deep con-\nvolutional neural networks as a decision support tool in medical\nproblems—Malignant melanoma case study,” in Trends in Advanced\nIntelligent Control, Optimization and Automation (Advances in In-\ntelligent Systems and Computing). New Y ork, NY , USA: Springer,\n2017.\n[11] A. Esteva et al. , “Dermatologist-level classiﬁcation of skin cancer\nwith deep neural networks,” Nature, vol. 542, no. 7639, pp. 115–118,\n2017.\n[12] A. B. Oktay and Y . S. Akgul, “Diagnosis of degenerative intervertebral\ndisc disease with deep networks and SVM,” in Computer and Information\nSciences. New Y ork, NY , USA: Springer, 2016.\n[13] D. H. Wolpert and W. G. Macready, “No free lunch theorems for op-\ntimization,” IEEE Trans. Evol. Comput. , vol. 1, no. 1, pp. 67–82, Apr.\n1997.\n[14] S. A. Prajapati, R. Nagaraj, and S. Mitra, “Classiﬁcation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—",
        " [12],\nwhich is also used to implement the automated segmentation of\ngingival diseases from oral images [13]. In [14], the approaches\nof CNN and transfer learning are used in dental diseases, and\nthe above artiﬁcial intelligence methods for dental are based\n2168-2194 © 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\nSee https://www.ieee.org/publications/rights/index.html for more information.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. \n\nLIU et al.: SMART DENT AL HEAL TH-IOT PLA TFORM BASED ON INTELLIGENT HARDWARE, DEEP LEARNING AND MOBILE TERMINAL 899\non X-ray. However, visual diagnosis serves as one of the most\nimportant parts of dental health care.\nThe smart dental health IoT system, due to the lack of coor-\ndinated IoT-based In-home dental health care services, is devel-\noped in this paper, which plays an important role in elaborating\nits applications in home and private dental clinic scenarios. The\nproposed system builds a home-centric, self-assisted, fully au-\ntomatic intelligent In-home dental healthcare solution by taking\nadvantage of embedded intelligent hardware technology, articial\nintelligence (AI), and the mobile terminal.\nThe system closely combines the personal self-service dental\nhealth examination and dental resources through studying the\nAI method to expand the scope and coverage of traditional\ndental health care, which is the major contribution made by the\nproposed iHome smart dental Health-IoT system. Patients can\nchoose medical resources online and receive an appointment for\nmedical treatment via self-service smart dental screening.\nThe rest parts of this paper are organized as follows.\nSection II discusses smart In-home dentist system, followed\nby Section III analyzing the intelligent dental diagnosis, intro-\nducing the algorithm ﬂow and test results. Section IV presents\nthe integrated system and hardware prototype, and reports the\napplication results, and a conclusion is given in Section V\nﬁnally.\nII. S MART IN-HOME DENTIST SYSTEM\nThe occurrence of dental disease can be well predictable. For\nexample, each stage from dental plaque, calculus to dental caries\nand periodontal disease shows different characteristics and so-\nlutions, thereby making it possible to monitor the whole body\nand reduce the risk of sudden diseases effectively. It can reduce\npain, save time and reduce the cost of money for patients. How-\never, most consumers lack the correct tooth awareness, thereby\nmaking the timely treatment for tooth disease difﬁcult. More-\nover, there is a relative shortage of dental resources in hospitals.\nThese main contradictions are explained in the following aspects\nin details:\nr First, there are a lot of patients with dental diseases, but\nfewer people pay attention to the teeth. Many individ-\nuals pay for treatment only when they have teeth with\nproblems, which may cause irreversible damage to the\nlong-term development of children.\nr Second, the cost of dental treatment is relatively high.\nr Third, dental disease, due to the characteristics of elective\ntreatment, is difﬁcult to get timely treatment.\nBased on what is discussed above, a promising trend in health-\ncare is to move routine medical checks and other healthcare ser-\nvices from hospital (Hospital-Centric) to the home environment\n(Home-centric) [15], through which, the patients can get seam-\nless health care at any time in a comfortable home environment.\nEven more, it can ensure that the overall iHome dental health-\ncare system including three partspersonalized services, dental\nservices and intelligent and interactive service could be opti-\nmized to a large extent. Based on this platform, the closed",
        "cation of dental diseases\nusing CNN and transfer learning,” in Proc. Int. Symp. Comput. Bus. Intell. ,\n2017, pp. 70–74.\n[15] Z. Pang, Q. Chen, J. Tian, L. Zheng, and E. Dubrova, “Ecosystem analysis\nin the design of open platform-based in-home healthcare terminals towards\nthe internet-of-things,” in Proc. 15th Int. Conf. Adv. Commun. Technol. ,\n2013, pp. 529–534.\n[16] G. Xin, W. Chen, and J. Li, “Research on security monitoring and health\nmanagement system of UA V ,” in Proceedings of the First Symposium\non Aviation Maintenance and Management—V olume II (Lecture Notes in\nElectrical Engineering). New Y ork, NY , USA: Springer, 2014, pp. 631–\n639.\n[17] E. Provenzi, C. L. De, A. Rizzi, and D. Marini, “Mathematical deﬁnition\nand analysis of the Retinex algorithm,” J. Opt. Soc. Am. A , vol. 22, no. 12,\npp. 2613–2621, 2005.\n[18] S. Y . Liao and T. Q. Huang, “Video copy-move forgery detection and\nlocalization based on Tamura texture features,” in Proc. Int. Congr . Image\nSignal Process., 2014, pp. 864–868.\n[19] X. Wang, K. Chen, Z. Huang, C. Y ao, and W. Liu, “Point linking network\nfor object detection,” 2017, arXiv preprint arXiv:1706.03646.\n[20] J. Dai, K. He, and J. Sun, “Instance-aware semantic segmentation via\nmulti-task network cascades,” in Proc. IEEE Conf. Comput. Vision Pattern\nRecognit., 2015, pp. 3150–3158.\n[21] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in Proc. IEEE Conf. Comput. Vision Pattern Recognit. , 2015,\npp. 770–778.\n[22] S. Ren, R. Girshick, R. Girshick, and J. Sun, “Faster R-CNN: Towards\nreal-time object detection with region proposal networks,” IEEE Trans.\nPattern Anal. & Mach. Intell. , vol. 39, no. 6, pp. 1137–1149, Jun. 2017.\n[23] Z. Xie, X. Zhang, D. Zeng, X. Chen, and W. Feng, “Design and imple-\nmentation of the remote wireless intraoral endoscope system,” in Proc.\nInt. Ind. Inform. Comput. Eng. Conf. , 2015, pp. 975–980.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 25,2025 at 09:22:40 UTC from IEEE Xplore.  Restrictions apply. "
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2410
    }
  ]
}