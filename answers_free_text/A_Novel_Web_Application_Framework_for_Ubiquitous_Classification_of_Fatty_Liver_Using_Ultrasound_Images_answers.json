{
  "paper": "A Novel Web Application Framework for Ubiquitous Classification of Fatty Liver Using Ultrasound Images.pdf",
  "answers": [
    {
      "id": "Q1",
      "question": "Is the aim of this study to predict future events (prognostic) or current disease status (diagnostic)?",
      "answer": "Diagnostic.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        5,
        4,
        7
      ],
      "chunks_str": [
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for",
        "ician.\nFig. 3. Developed web interface along with the ultrasound and prediction\nwhen tested using a normal liver image.\nFig. 4. Developed web interface along with the ultrasound and prediction\nwhen tested using a liver image with a fatty liver condition.\nIII. D EVELOPED CNN BASED ACCURATE FATTY LIVER\nCLASSIFICATION FRAMEWORK\nIn [19], we have developed a novel CNN based accurate\nfatty liver classiﬁcation model using ultrasound images. The\nsame model is adopted in this paper for the classiﬁcation of\nfatty liver using ultrasound images. The architecture comprises\nof a pre-trained VGG-16 model along with the transfer learn-\ning and ﬁne-tuning. VGGNet using CNN is initially designed\nwith different layer depths aiming for image recognition tasks.\nPreliminary analysis of VGGNet offered a promising accuracy\nof 92.7% when validated using the ImagNet dataset com-\nprising of 14 million images from 1000 classes [20]. In this\npaper, we make use the 16 layers VGG-16 with convolution\nblocks(including convolution layers and max-pooling layers)\nand a fully connected classiﬁer. The ﬁne-tuning is carried out\nusing the pre-trained VGG-16 model in Keras. Traditionally,\nthe convolution 2D layers in VGG-16 consists of 512 nodes for\nconvolution layers, however, in our experiment we ﬁne-tuned\nthe network from using 512 nodes to 256 nodes. Also, we ﬁne-\ntuned fully connected layers having 4096 nodes to 256 nodes,\nand the output layer comprises two neurons whose output\ncorresponds to the two classes (normal and abnormal) in this\nstudy. During the training of the model, the weight parameters\nof the output layer are initialized using random Gaussian\ndistribution, and the training is performed over 100 epochs.\nSince the development of the CNN based accurate fatty liver\nclassiﬁcation framework is not our primary contribution in this\npaper, we would like to advise the readers to kindly refer [19]\nfor more details on the developed model. However, we would\nlike to highlight that the database used for validation in [19]\nis different from what we used here.\nIV. R ESULTS\nThe publicly available datasets for ultrasound images of the\nliver are very few. Hence, due to the unavailability of the\npublic datasets, we acquired and developed our own dataset\nusing a GE LOGIQ F6 ultrasound scanner in collaboration\nwith MNR Medical College, Sangareddy, Hyderabad, India.\nThe dataset consisted of 58 representative liver images com-\nprising of both fatty liver (22 images) and normal conditions\n(36 images). We cropped the images which does not convey\nany diagnostic information such as hospital name, time of the\ndiagnosis, etc. Also, since the pre-trained models are trained\nwith an input image size of 224×224 pixels, the images of\nour dataset were also resized to 224×224 pixels for compat-\nibility. The performance of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.",
        " and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C. Silva, F. D. M. Guedes and\nJ. J. P. C. Rodrigues, “A mobile healthcare solution for ambient assisted\nliving environments,” 2014 IEEE 16th International Conference on e-\nHealth Networking, Applications and Services (Healthcom), Natal, 2014,\npp. 170-175. doi: 10.1109/HealthCom.2014.7001836\n[4] J. M. Quero et al., “Health Care Applications Based on Mobile Phone\nCentric Smart Sensor Network,” 2007 29th Annual International Con-\nference of the IEEE Engineering in Medicine and Biology Society, Lyon,\n2007, pp. 6298-6301. doi: 10.1109/IEMBS.2007.4353795\n[5] Kvedar et al., “Connected health: A review of technologies and strategies\nto improve patient care with telemedicine and telehealth,”Health Affairs,\nvol. 33, pp. 194199, 2014.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n505\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\n[6] Swerdlow, D.R. et. al., “Robotic armassisted sonography: Review of\ntechnical developments and potential clinical applications,” Am. J.\nRoentgenol., vol. 208, pp. 733738, 2017.\n[7] J. Grundy, M. Abdelrazek and M. K. Curumsing, “Vision: Improved\nDevelopment of Mobile eHealth Applications,” 2018 IEEE/ACM 5th\nInternational Conference on Mobile Software Engineering and Systems\n(MOBILESoft), Gothenburg, Sweden, 2018, pp. 219-223.\n[8] H.-Y . Tang et al., “Miniaturizing ultrasonic system for portable health\ncare and ﬁtness,” IEEE Trans. Biomed. Circuits Syst., vol. 9, no. 6, pp.\n767776, Dec. 2015.\n[9] J. Kang et al., “A System-on-Chip Solution for Point-of-Care Ultrasound\nImaging Systems: Architecture and ASIC Implementation,” in IEEE\nTransactions on Biomedical Circuits and Systems, vol. 10, no. 2, pp.\n412-423, April 2016. doi: 10.1109/TBCAS.2015.2431272\n[10] Stawicki, Stanislaw Peter, and David Paul Bahner. “Modern sonology\nand the bedside practitioner: evolution of ultrasound from curious\nnovelty to essential clinical tool,” European Journal of Trauma and\nEmergency Surgery 41.5, 457-460, 2015.\n[11] R. Bharath et al., “Portable ultrasound scanner for remote diagnosis,”\n2015 17th International Conference on E-health Networking"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2554
    },
    {
      "id": "Q2",
      "question": "On what basis were eligible participants included in this study (symptons, previous tests, registry, etc.)?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        7,
        9,
        5
      ],
      "chunks_str": [
        " and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C. Silva, F. D. M. Guedes and\nJ. J. P. C. Rodrigues, “A mobile healthcare solution for ambient assisted\nliving environments,” 2014 IEEE 16th International Conference on e-\nHealth Networking, Applications and Services (Healthcom), Natal, 2014,\npp. 170-175. doi: 10.1109/HealthCom.2014.7001836\n[4] J. M. Quero et al., “Health Care Applications Based on Mobile Phone\nCentric Smart Sensor Network,” 2007 29th Annual International Con-\nference of the IEEE Engineering in Medicine and Biology Society, Lyon,\n2007, pp. 6298-6301. doi: 10.1109/IEMBS.2007.4353795\n[5] Kvedar et al., “Connected health: A review of technologies and strategies\nto improve patient care with telemedicine and telehealth,”Health Affairs,\nvol. 33, pp. 194199, 2014.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n505\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\n[6] Swerdlow, D.R. et. al., “Robotic armassisted sonography: Review of\ntechnical developments and potential clinical applications,” Am. J.\nRoentgenol., vol. 208, pp. 733738, 2017.\n[7] J. Grundy, M. Abdelrazek and M. K. Curumsing, “Vision: Improved\nDevelopment of Mobile eHealth Applications,” 2018 IEEE/ACM 5th\nInternational Conference on Mobile Software Engineering and Systems\n(MOBILESoft), Gothenburg, Sweden, 2018, pp. 219-223.\n[8] H.-Y . Tang et al., “Miniaturizing ultrasonic system for portable health\ncare and ﬁtness,” IEEE Trans. Biomed. Circuits Syst., vol. 9, no. 6, pp.\n767776, Dec. 2015.\n[9] J. Kang et al., “A System-on-Chip Solution for Point-of-Care Ultrasound\nImaging Systems: Architecture and ASIC Implementation,” in IEEE\nTransactions on Biomedical Circuits and Systems, vol. 10, no. 2, pp.\n412-423, April 2016. doi: 10.1109/TBCAS.2015.2431272\n[10] Stawicki, Stanislaw Peter, and David Paul Bahner. “Modern sonology\nand the bedside practitioner: evolution of ultrasound from curious\nnovelty to essential clinical tool,” European Journal of Trauma and\nEmergency Surgery 41.5, 457-460, 2015.\n[11] R. Bharath et al., “Portable ultrasound scanner for remote diagnosis,”\n2015 17th International Conference on E-health Networking",
        "] S. M. Abd El-Kader and E. M. El-Den Ashmawy, “Non-alcoholic fatty\nliver disease: The diagnosis and management.” World J. Hepatol , Apr.\n2015, vol. 7, pp. 846858. doi: 10.4254/wjh.v7.i6.846.\n[18] P. V ogel, T. Klooster, V . Andrikopoulos and M. Lungu, “A Low-\nEffort Analytics Platform for Visualizing Evolving Flask-Based Python\nWeb Services,” 2017 IEEE Working Conference on Software Visual-\nization (VISSOFT), Shanghai, 2017, pp. 109-113. doi: 10.1109/VIS-\nSOFT.2017.13\n[19] D. S. Reddy, R. Bharath and P. Rajalakshmi, “A Novel Computer-Aided\nDiagnosis Framework Using Deep Learning for Classiﬁcation of Fatty\nLiver Disease in Ultrasound Imaging,” 2018 IEEE 20th International\nConference on e-Health Networking, Applications and Services (Health-\ncom), Ostrava, 2018, pp. 1-5. doi: 10.1109/HealthCom.2018.8531118\n[20] K. Simonyan and A. Zisserman, “Very deep convolutional networks for\nlarge-scale image recognition,” in Proc. Int. Conf. Learn. Representa-\ntions, 2015.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n506\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. ",
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2126
    },
    {
      "id": "Q3",
      "question": "How were participants sampled in this study: by convenience, randomly, or consecutively?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        5,
        2,
        6
      ],
      "chunks_str": [
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for",
        " eHealth ap-\nplications using scalable video coding (SVC) extension for\nMPEC-4 A VC/H.264 which enables a doctor in a different\nlocation to administer the scanning in real-time. This solution\nis feasible in areas where high bandwidth network connectivity\nis available and may not be a suitable solution for rural areas.\nIn [14] In [14], authors proposed an abnormality detection\nbased on Viola Jones and Support Vector Machine (SVM)\nclassiﬁer to detect the abnormality in ultrasound image. In\n[15], authors proposed a framework for compressing the\nultrasound images using web real-time communication (We-\nbRTC) framework technology for low data real-time eHealth\napplications. However, it still requires the high performance\nnetwork connectivity which is not available in rural areas.\nAlso, in [16] the authors have developed similar frameworks\nfor tele-diagnosis wherein the ultrasound scanning information\nis streamed to the expert side for getting inferences. In all the\nabove studies the major drawbacks include the following: (1)\nthe infrastructure needs to be replaced, (2) requirement of high\nperformance network connectivity and (3) manual observance\nof the ultrasound data which is prone to errors and entirely\ndepends on the skill of the sonographers. Hence, in this paper,\nwe developed a web based architecture wherein a clinician can\nupload the ultrasound image and can get accurate diagnosis\ninformation. This architecture does not require any change in\nthe existing infrastructure and is an easily scalable solution\nespecially for developing nations.\nThe rest of this paper is organized as follows. Section\nII describes the proposed architecture and the functional\nunits present. Section III describes the developed CNN based\nclassiﬁcation framework for accurate classiﬁcation of fatty\nliver using ultrasound images. In Section IV , we discuss\nthe dataset developed for analyzing the performance of the\nproposed architecture and the key insights observed from the\nperformance analysis. Finally, Section V concludes the paper\nby summarizing the work performed and discussed the future\nscope of this work.\nII. P ROPOSED NOVEL E HEALTH ARCHITECTURE FOR\nACCURATE WEB BASED FATTY LIVER CLASSIFICATION\nFig. 1 shows the ultrasound images of liver under normal\nconditions and those with affected by fatty liver. Excess fat\naccumulated in the liver can lead to fatty liver conditions\nand can cause severe liver damage. The normal liver usually\ncontains 5 to 10% of the fat and if the fat concentration\nexceeds beyond this limit, it is observed as a fatty liver\n(a)\n(b)\nFig. 1. (a) Ultrasound images of liver under normal conditions, (b) Ultrasound\nimages of liver under fatty liver conditions.\nWeb \nBrowser\nPre−processingUltrasound\nLiver Image\nNormal\nAbnormal\nOutput Prediction\nCNN Based\nClassifier\nClient Interface (Remote Location) Cloud Based Web Application\nFig. 2. Proposed novel low-cost and scalable eHealth architecture for accurate\nweb based fatty liver classiﬁcation\ncondition. The liver in general is capable of repairing if the\nold cells are damaged by rebuilding the new liver cells until\nrepeated liver damage occurs. Currently, the fatty liver disease\nis becoming a more prevailing condition, affecting about 25 to\n30 % of the population in both the developed and developing\ncountries [17]. If the condition is left untreated, fatty liver\nleads to more harmful steatohepatitis gradually leading into\nliver cancer. Early detection of fatty liver can thus prevent from\nthe permanent failure of the liver. To identify the fatty liver\ncondition, ultrasound imaging is the widely used diagnostic\nmethod.\nFig. 2 shows the proposed architecture for the novel low-\ncost and scalable eHealth architecture for fatty liver classiﬁca-\ntion. The entire architecture can be",
        " Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for improving the state of\nthe art research in the development of scalable and low-cost\neHealth applications.\nV. CONCLUSION\nIn this paper, we proposed and developed a low-cost and\neasily scalable eHealth architecture comprising of a web\napplication for automatic classiﬁcation of fatty liver using\nultrasound images. The developed web application is easy to\nuse and requires no change in the current infrastructure. The\nultrasound images obtained using the traditional ultrasound\nscanners can be uploaded to the developed web application\nusing moderate network connectivity and the web application\nthen classiﬁes the image into either normal or abnormal using\na CNN based framework. The performance of the proposed\nframework is tested with with 58 ultrasound images, we have\ndeveloped a custom database comprising of 58 ultrasound\nimages with liver information of which 36 correspond to liver\nimages are normal conditions and the rest correspond to a fatty\nliver condition. It is observed that the proposed framework\nachieves an average accuracy of 91.37%. Also, the latency\nanalysis shows that the proposed CNN model predicts within\n20 ms when running on a PC with Intel i7 processor and 16 GB\nRAM. Also when considered along with the network latency\nthe total latency observed is approximately 150 ms when used\nwith moderate network connectivity. Hence, we strongly feel\nthat the proposed eHealth framework will help future research\nin developing low-cost, easily scalable and ubiquitous eHealth\nframeworks. Our future scope of this work is to develop a more\nrobust classiﬁcation framework which can eliminate the false\nnegatives. Also, we would like to consider real-time trials in\ncoordination with hospitals to analyze the performance in real\nconstraints.\nVI. ACKNOWLEDGMENT\nWe are thankful to the team of radiologists at Asian Institute\nof Gastroenterology and MNR Medical College & Hospital,\nHyderabad, Telangana, India, for spending their valuable time\nduring this research. This research was partly funded by\nvisvesvaraya Ph.D. Scheme, Media Lab Asia, MEITY , Govt.\nof India and partly funded by Indian Institute of Technology\nHyderabad.\nREFERENCES\n[1] B. Farahani, F. Firouzi, V . Chang, M. Badaroglu, N. Constant, and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2532
    },
    {
      "id": "Q4",
      "question": "How was the dataset described in this study before predictive modeling was performed?",
      "answer": "58 ultrasound images with 36 normal and 22 abnormal.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        5,
        4,
        6
      ],
      "chunks_str": [
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for",
        "ician.\nFig. 3. Developed web interface along with the ultrasound and prediction\nwhen tested using a normal liver image.\nFig. 4. Developed web interface along with the ultrasound and prediction\nwhen tested using a liver image with a fatty liver condition.\nIII. D EVELOPED CNN BASED ACCURATE FATTY LIVER\nCLASSIFICATION FRAMEWORK\nIn [19], we have developed a novel CNN based accurate\nfatty liver classiﬁcation model using ultrasound images. The\nsame model is adopted in this paper for the classiﬁcation of\nfatty liver using ultrasound images. The architecture comprises\nof a pre-trained VGG-16 model along with the transfer learn-\ning and ﬁne-tuning. VGGNet using CNN is initially designed\nwith different layer depths aiming for image recognition tasks.\nPreliminary analysis of VGGNet offered a promising accuracy\nof 92.7% when validated using the ImagNet dataset com-\nprising of 14 million images from 1000 classes [20]. In this\npaper, we make use the 16 layers VGG-16 with convolution\nblocks(including convolution layers and max-pooling layers)\nand a fully connected classiﬁer. The ﬁne-tuning is carried out\nusing the pre-trained VGG-16 model in Keras. Traditionally,\nthe convolution 2D layers in VGG-16 consists of 512 nodes for\nconvolution layers, however, in our experiment we ﬁne-tuned\nthe network from using 512 nodes to 256 nodes. Also, we ﬁne-\ntuned fully connected layers having 4096 nodes to 256 nodes,\nand the output layer comprises two neurons whose output\ncorresponds to the two classes (normal and abnormal) in this\nstudy. During the training of the model, the weight parameters\nof the output layer are initialized using random Gaussian\ndistribution, and the training is performed over 100 epochs.\nSince the development of the CNN based accurate fatty liver\nclassiﬁcation framework is not our primary contribution in this\npaper, we would like to advise the readers to kindly refer [19]\nfor more details on the developed model. However, we would\nlike to highlight that the database used for validation in [19]\nis different from what we used here.\nIV. R ESULTS\nThe publicly available datasets for ultrasound images of the\nliver are very few. Hence, due to the unavailability of the\npublic datasets, we acquired and developed our own dataset\nusing a GE LOGIQ F6 ultrasound scanner in collaboration\nwith MNR Medical College, Sangareddy, Hyderabad, India.\nThe dataset consisted of 58 representative liver images com-\nprising of both fatty liver (22 images) and normal conditions\n(36 images). We cropped the images which does not convey\nany diagnostic information such as hospital name, time of the\ndiagnosis, etc. Also, since the pre-trained models are trained\nwith an input image size of 224×224 pixels, the images of\nour dataset were also resized to 224×224 pixels for compat-\nibility. The performance of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.",
        " Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for improving the state of\nthe art research in the development of scalable and low-cost\neHealth applications.\nV. CONCLUSION\nIn this paper, we proposed and developed a low-cost and\neasily scalable eHealth architecture comprising of a web\napplication for automatic classiﬁcation of fatty liver using\nultrasound images. The developed web application is easy to\nuse and requires no change in the current infrastructure. The\nultrasound images obtained using the traditional ultrasound\nscanners can be uploaded to the developed web application\nusing moderate network connectivity and the web application\nthen classiﬁes the image into either normal or abnormal using\na CNN based framework. The performance of the proposed\nframework is tested with with 58 ultrasound images, we have\ndeveloped a custom database comprising of 58 ultrasound\nimages with liver information of which 36 correspond to liver\nimages are normal conditions and the rest correspond to a fatty\nliver condition. It is observed that the proposed framework\nachieves an average accuracy of 91.37%. Also, the latency\nanalysis shows that the proposed CNN model predicts within\n20 ms when running on a PC with Intel i7 processor and 16 GB\nRAM. Also when considered along with the network latency\nthe total latency observed is approximately 150 ms when used\nwith moderate network connectivity. Hence, we strongly feel\nthat the proposed eHealth framework will help future research\nin developing low-cost, easily scalable and ubiquitous eHealth\nframeworks. Our future scope of this work is to develop a more\nrobust classiﬁcation framework which can eliminate the false\nnegatives. Also, we would like to consider real-time trials in\ncoordination with hospitals to analyze the performance in real\nconstraints.\nVI. ACKNOWLEDGMENT\nWe are thankful to the team of radiologists at Asian Institute\nof Gastroenterology and MNR Medical College & Hospital,\nHyderabad, Telangana, India, for spending their valuable time\nduring this research. This research was partly funded by\nvisvesvaraya Ph.D. Scheme, Media Lab Asia, MEITY , Govt.\nof India and partly funded by Indian Institute of Technology\nHyderabad.\nREFERENCES\n[1] B. Farahani, F. Firouzi, V . Chang, M. Badaroglu, N. Constant, and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2547
    },
    {
      "id": "Q5",
      "question": "What was the proedure for splitting the dataset into training, validation, and test sets in this study?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        5,
        4,
        6
      ],
      "chunks_str": [
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for",
        "ician.\nFig. 3. Developed web interface along with the ultrasound and prediction\nwhen tested using a normal liver image.\nFig. 4. Developed web interface along with the ultrasound and prediction\nwhen tested using a liver image with a fatty liver condition.\nIII. D EVELOPED CNN BASED ACCURATE FATTY LIVER\nCLASSIFICATION FRAMEWORK\nIn [19], we have developed a novel CNN based accurate\nfatty liver classiﬁcation model using ultrasound images. The\nsame model is adopted in this paper for the classiﬁcation of\nfatty liver using ultrasound images. The architecture comprises\nof a pre-trained VGG-16 model along with the transfer learn-\ning and ﬁne-tuning. VGGNet using CNN is initially designed\nwith different layer depths aiming for image recognition tasks.\nPreliminary analysis of VGGNet offered a promising accuracy\nof 92.7% when validated using the ImagNet dataset com-\nprising of 14 million images from 1000 classes [20]. In this\npaper, we make use the 16 layers VGG-16 with convolution\nblocks(including convolution layers and max-pooling layers)\nand a fully connected classiﬁer. The ﬁne-tuning is carried out\nusing the pre-trained VGG-16 model in Keras. Traditionally,\nthe convolution 2D layers in VGG-16 consists of 512 nodes for\nconvolution layers, however, in our experiment we ﬁne-tuned\nthe network from using 512 nodes to 256 nodes. Also, we ﬁne-\ntuned fully connected layers having 4096 nodes to 256 nodes,\nand the output layer comprises two neurons whose output\ncorresponds to the two classes (normal and abnormal) in this\nstudy. During the training of the model, the weight parameters\nof the output layer are initialized using random Gaussian\ndistribution, and the training is performed over 100 epochs.\nSince the development of the CNN based accurate fatty liver\nclassiﬁcation framework is not our primary contribution in this\npaper, we would like to advise the readers to kindly refer [19]\nfor more details on the developed model. However, we would\nlike to highlight that the database used for validation in [19]\nis different from what we used here.\nIV. R ESULTS\nThe publicly available datasets for ultrasound images of the\nliver are very few. Hence, due to the unavailability of the\npublic datasets, we acquired and developed our own dataset\nusing a GE LOGIQ F6 ultrasound scanner in collaboration\nwith MNR Medical College, Sangareddy, Hyderabad, India.\nThe dataset consisted of 58 representative liver images com-\nprising of both fatty liver (22 images) and normal conditions\n(36 images). We cropped the images which does not convey\nany diagnostic information such as hospital name, time of the\ndiagnosis, etc. Also, since the pre-trained models are trained\nwith an input image size of 224×224 pixels, the images of\nour dataset were also resized to 224×224 pixels for compat-\nibility. The performance of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.",
        " Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for improving the state of\nthe art research in the development of scalable and low-cost\neHealth applications.\nV. CONCLUSION\nIn this paper, we proposed and developed a low-cost and\neasily scalable eHealth architecture comprising of a web\napplication for automatic classiﬁcation of fatty liver using\nultrasound images. The developed web application is easy to\nuse and requires no change in the current infrastructure. The\nultrasound images obtained using the traditional ultrasound\nscanners can be uploaded to the developed web application\nusing moderate network connectivity and the web application\nthen classiﬁes the image into either normal or abnormal using\na CNN based framework. The performance of the proposed\nframework is tested with with 58 ultrasound images, we have\ndeveloped a custom database comprising of 58 ultrasound\nimages with liver information of which 36 correspond to liver\nimages are normal conditions and the rest correspond to a fatty\nliver condition. It is observed that the proposed framework\nachieves an average accuracy of 91.37%. Also, the latency\nanalysis shows that the proposed CNN model predicts within\n20 ms when running on a PC with Intel i7 processor and 16 GB\nRAM. Also when considered along with the network latency\nthe total latency observed is approximately 150 ms when used\nwith moderate network connectivity. Hence, we strongly feel\nthat the proposed eHealth framework will help future research\nin developing low-cost, easily scalable and ubiquitous eHealth\nframeworks. Our future scope of this work is to develop a more\nrobust classiﬁcation framework which can eliminate the false\nnegatives. Also, we would like to consider real-time trials in\ncoordination with hospitals to analyze the performance in real\nconstraints.\nVI. ACKNOWLEDGMENT\nWe are thankful to the team of radiologists at Asian Institute\nof Gastroenterology and MNR Medical College & Hospital,\nHyderabad, Telangana, India, for spending their valuable time\nduring this research. This research was partly funded by\nvisvesvaraya Ph.D. Scheme, Media Lab Asia, MEITY , Govt.\nof India and partly funded by Indian Institute of Technology\nHyderabad.\nREFERENCES\n[1] B. Farahani, F. Firouzi, V . Chang, M. Badaroglu, N. Constant, and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2548
    },
    {
      "id": "Q6",
      "question": "What preprocessing techniques on the included variables/features were applied in this study?",
      "answer": "Cropping and resizing to 224×224 pixels.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        2,
        6,
        4
      ],
      "chunks_str": [
        " eHealth ap-\nplications using scalable video coding (SVC) extension for\nMPEC-4 A VC/H.264 which enables a doctor in a different\nlocation to administer the scanning in real-time. This solution\nis feasible in areas where high bandwidth network connectivity\nis available and may not be a suitable solution for rural areas.\nIn [14] In [14], authors proposed an abnormality detection\nbased on Viola Jones and Support Vector Machine (SVM)\nclassiﬁer to detect the abnormality in ultrasound image. In\n[15], authors proposed a framework for compressing the\nultrasound images using web real-time communication (We-\nbRTC) framework technology for low data real-time eHealth\napplications. However, it still requires the high performance\nnetwork connectivity which is not available in rural areas.\nAlso, in [16] the authors have developed similar frameworks\nfor tele-diagnosis wherein the ultrasound scanning information\nis streamed to the expert side for getting inferences. In all the\nabove studies the major drawbacks include the following: (1)\nthe infrastructure needs to be replaced, (2) requirement of high\nperformance network connectivity and (3) manual observance\nof the ultrasound data which is prone to errors and entirely\ndepends on the skill of the sonographers. Hence, in this paper,\nwe developed a web based architecture wherein a clinician can\nupload the ultrasound image and can get accurate diagnosis\ninformation. This architecture does not require any change in\nthe existing infrastructure and is an easily scalable solution\nespecially for developing nations.\nThe rest of this paper is organized as follows. Section\nII describes the proposed architecture and the functional\nunits present. Section III describes the developed CNN based\nclassiﬁcation framework for accurate classiﬁcation of fatty\nliver using ultrasound images. In Section IV , we discuss\nthe dataset developed for analyzing the performance of the\nproposed architecture and the key insights observed from the\nperformance analysis. Finally, Section V concludes the paper\nby summarizing the work performed and discussed the future\nscope of this work.\nII. P ROPOSED NOVEL E HEALTH ARCHITECTURE FOR\nACCURATE WEB BASED FATTY LIVER CLASSIFICATION\nFig. 1 shows the ultrasound images of liver under normal\nconditions and those with affected by fatty liver. Excess fat\naccumulated in the liver can lead to fatty liver conditions\nand can cause severe liver damage. The normal liver usually\ncontains 5 to 10% of the fat and if the fat concentration\nexceeds beyond this limit, it is observed as a fatty liver\n(a)\n(b)\nFig. 1. (a) Ultrasound images of liver under normal conditions, (b) Ultrasound\nimages of liver under fatty liver conditions.\nWeb \nBrowser\nPre−processingUltrasound\nLiver Image\nNormal\nAbnormal\nOutput Prediction\nCNN Based\nClassifier\nClient Interface (Remote Location) Cloud Based Web Application\nFig. 2. Proposed novel low-cost and scalable eHealth architecture for accurate\nweb based fatty liver classiﬁcation\ncondition. The liver in general is capable of repairing if the\nold cells are damaged by rebuilding the new liver cells until\nrepeated liver damage occurs. Currently, the fatty liver disease\nis becoming a more prevailing condition, affecting about 25 to\n30 % of the population in both the developed and developing\ncountries [17]. If the condition is left untreated, fatty liver\nleads to more harmful steatohepatitis gradually leading into\nliver cancer. Early detection of fatty liver can thus prevent from\nthe permanent failure of the liver. To identify the fatty liver\ncondition, ultrasound imaging is the widely used diagnostic\nmethod.\nFig. 2 shows the proposed architecture for the novel low-\ncost and scalable eHealth architecture for fatty liver classiﬁca-\ntion. The entire architecture can be",
        " Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for improving the state of\nthe art research in the development of scalable and low-cost\neHealth applications.\nV. CONCLUSION\nIn this paper, we proposed and developed a low-cost and\neasily scalable eHealth architecture comprising of a web\napplication for automatic classiﬁcation of fatty liver using\nultrasound images. The developed web application is easy to\nuse and requires no change in the current infrastructure. The\nultrasound images obtained using the traditional ultrasound\nscanners can be uploaded to the developed web application\nusing moderate network connectivity and the web application\nthen classiﬁes the image into either normal or abnormal using\na CNN based framework. The performance of the proposed\nframework is tested with with 58 ultrasound images, we have\ndeveloped a custom database comprising of 58 ultrasound\nimages with liver information of which 36 correspond to liver\nimages are normal conditions and the rest correspond to a fatty\nliver condition. It is observed that the proposed framework\nachieves an average accuracy of 91.37%. Also, the latency\nanalysis shows that the proposed CNN model predicts within\n20 ms when running on a PC with Intel i7 processor and 16 GB\nRAM. Also when considered along with the network latency\nthe total latency observed is approximately 150 ms when used\nwith moderate network connectivity. Hence, we strongly feel\nthat the proposed eHealth framework will help future research\nin developing low-cost, easily scalable and ubiquitous eHealth\nframeworks. Our future scope of this work is to develop a more\nrobust classiﬁcation framework which can eliminate the false\nnegatives. Also, we would like to consider real-time trials in\ncoordination with hospitals to analyze the performance in real\nconstraints.\nVI. ACKNOWLEDGMENT\nWe are thankful to the team of radiologists at Asian Institute\nof Gastroenterology and MNR Medical College & Hospital,\nHyderabad, Telangana, India, for spending their valuable time\nduring this research. This research was partly funded by\nvisvesvaraya Ph.D. Scheme, Media Lab Asia, MEITY , Govt.\nof India and partly funded by Indian Institute of Technology\nHyderabad.\nREFERENCES\n[1] B. Farahani, F. Firouzi, V . Chang, M. Badaroglu, N. Constant, and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C",
        "ician.\nFig. 3. Developed web interface along with the ultrasound and prediction\nwhen tested using a normal liver image.\nFig. 4. Developed web interface along with the ultrasound and prediction\nwhen tested using a liver image with a fatty liver condition.\nIII. D EVELOPED CNN BASED ACCURATE FATTY LIVER\nCLASSIFICATION FRAMEWORK\nIn [19], we have developed a novel CNN based accurate\nfatty liver classiﬁcation model using ultrasound images. The\nsame model is adopted in this paper for the classiﬁcation of\nfatty liver using ultrasound images. The architecture comprises\nof a pre-trained VGG-16 model along with the transfer learn-\ning and ﬁne-tuning. VGGNet using CNN is initially designed\nwith different layer depths aiming for image recognition tasks.\nPreliminary analysis of VGGNet offered a promising accuracy\nof 92.7% when validated using the ImagNet dataset com-\nprising of 14 million images from 1000 classes [20]. In this\npaper, we make use the 16 layers VGG-16 with convolution\nblocks(including convolution layers and max-pooling layers)\nand a fully connected classiﬁer. The ﬁne-tuning is carried out\nusing the pre-trained VGG-16 model in Keras. Traditionally,\nthe convolution 2D layers in VGG-16 consists of 512 nodes for\nconvolution layers, however, in our experiment we ﬁne-tuned\nthe network from using 512 nodes to 256 nodes. Also, we ﬁne-\ntuned fully connected layers having 4096 nodes to 256 nodes,\nand the output layer comprises two neurons whose output\ncorresponds to the two classes (normal and abnormal) in this\nstudy. During the training of the model, the weight parameters\nof the output layer are initialized using random Gaussian\ndistribution, and the training is performed over 100 epochs.\nSince the development of the CNN based accurate fatty liver\nclassiﬁcation framework is not our primary contribution in this\npaper, we would like to advise the readers to kindly refer [19]\nfor more details on the developed model. However, we would\nlike to highlight that the database used for validation in [19]\nis different from what we used here.\nIV. R ESULTS\nThe publicly available datasets for ultrasound images of the\nliver are very few. Hence, due to the unavailability of the\npublic datasets, we acquired and developed our own dataset\nusing a GE LOGIQ F6 ultrasound scanner in collaboration\nwith MNR Medical College, Sangareddy, Hyderabad, India.\nThe dataset consisted of 58 representative liver images com-\nprising of both fatty liver (22 images) and normal conditions\n(36 images). We cropped the images which does not convey\nany diagnostic information such as hospital name, time of the\ndiagnosis, etc. Also, since the pre-trained models are trained\nwith an input image size of 224×224 pixels, the images of\nour dataset were also resized to 224×224 pixels for compat-\nibility. The performance of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore."
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2541
    },
    {
      "id": "Q7",
      "question": "How is missing data handled in this study?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        6,
        2,
        9
      ],
      "chunks_str": [
        " Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for improving the state of\nthe art research in the development of scalable and low-cost\neHealth applications.\nV. CONCLUSION\nIn this paper, we proposed and developed a low-cost and\neasily scalable eHealth architecture comprising of a web\napplication for automatic classiﬁcation of fatty liver using\nultrasound images. The developed web application is easy to\nuse and requires no change in the current infrastructure. The\nultrasound images obtained using the traditional ultrasound\nscanners can be uploaded to the developed web application\nusing moderate network connectivity and the web application\nthen classiﬁes the image into either normal or abnormal using\na CNN based framework. The performance of the proposed\nframework is tested with with 58 ultrasound images, we have\ndeveloped a custom database comprising of 58 ultrasound\nimages with liver information of which 36 correspond to liver\nimages are normal conditions and the rest correspond to a fatty\nliver condition. It is observed that the proposed framework\nachieves an average accuracy of 91.37%. Also, the latency\nanalysis shows that the proposed CNN model predicts within\n20 ms when running on a PC with Intel i7 processor and 16 GB\nRAM. Also when considered along with the network latency\nthe total latency observed is approximately 150 ms when used\nwith moderate network connectivity. Hence, we strongly feel\nthat the proposed eHealth framework will help future research\nin developing low-cost, easily scalable and ubiquitous eHealth\nframeworks. Our future scope of this work is to develop a more\nrobust classiﬁcation framework which can eliminate the false\nnegatives. Also, we would like to consider real-time trials in\ncoordination with hospitals to analyze the performance in real\nconstraints.\nVI. ACKNOWLEDGMENT\nWe are thankful to the team of radiologists at Asian Institute\nof Gastroenterology and MNR Medical College & Hospital,\nHyderabad, Telangana, India, for spending their valuable time\nduring this research. This research was partly funded by\nvisvesvaraya Ph.D. Scheme, Media Lab Asia, MEITY , Govt.\nof India and partly funded by Indian Institute of Technology\nHyderabad.\nREFERENCES\n[1] B. Farahani, F. Firouzi, V . Chang, M. Badaroglu, N. Constant, and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C",
        " eHealth ap-\nplications using scalable video coding (SVC) extension for\nMPEC-4 A VC/H.264 which enables a doctor in a different\nlocation to administer the scanning in real-time. This solution\nis feasible in areas where high bandwidth network connectivity\nis available and may not be a suitable solution for rural areas.\nIn [14] In [14], authors proposed an abnormality detection\nbased on Viola Jones and Support Vector Machine (SVM)\nclassiﬁer to detect the abnormality in ultrasound image. In\n[15], authors proposed a framework for compressing the\nultrasound images using web real-time communication (We-\nbRTC) framework technology for low data real-time eHealth\napplications. However, it still requires the high performance\nnetwork connectivity which is not available in rural areas.\nAlso, in [16] the authors have developed similar frameworks\nfor tele-diagnosis wherein the ultrasound scanning information\nis streamed to the expert side for getting inferences. In all the\nabove studies the major drawbacks include the following: (1)\nthe infrastructure needs to be replaced, (2) requirement of high\nperformance network connectivity and (3) manual observance\nof the ultrasound data which is prone to errors and entirely\ndepends on the skill of the sonographers. Hence, in this paper,\nwe developed a web based architecture wherein a clinician can\nupload the ultrasound image and can get accurate diagnosis\ninformation. This architecture does not require any change in\nthe existing infrastructure and is an easily scalable solution\nespecially for developing nations.\nThe rest of this paper is organized as follows. Section\nII describes the proposed architecture and the functional\nunits present. Section III describes the developed CNN based\nclassiﬁcation framework for accurate classiﬁcation of fatty\nliver using ultrasound images. In Section IV , we discuss\nthe dataset developed for analyzing the performance of the\nproposed architecture and the key insights observed from the\nperformance analysis. Finally, Section V concludes the paper\nby summarizing the work performed and discussed the future\nscope of this work.\nII. P ROPOSED NOVEL E HEALTH ARCHITECTURE FOR\nACCURATE WEB BASED FATTY LIVER CLASSIFICATION\nFig. 1 shows the ultrasound images of liver under normal\nconditions and those with affected by fatty liver. Excess fat\naccumulated in the liver can lead to fatty liver conditions\nand can cause severe liver damage. The normal liver usually\ncontains 5 to 10% of the fat and if the fat concentration\nexceeds beyond this limit, it is observed as a fatty liver\n(a)\n(b)\nFig. 1. (a) Ultrasound images of liver under normal conditions, (b) Ultrasound\nimages of liver under fatty liver conditions.\nWeb \nBrowser\nPre−processingUltrasound\nLiver Image\nNormal\nAbnormal\nOutput Prediction\nCNN Based\nClassifier\nClient Interface (Remote Location) Cloud Based Web Application\nFig. 2. Proposed novel low-cost and scalable eHealth architecture for accurate\nweb based fatty liver classiﬁcation\ncondition. The liver in general is capable of repairing if the\nold cells are damaged by rebuilding the new liver cells until\nrepeated liver damage occurs. Currently, the fatty liver disease\nis becoming a more prevailing condition, affecting about 25 to\n30 % of the population in both the developed and developing\ncountries [17]. If the condition is left untreated, fatty liver\nleads to more harmful steatohepatitis gradually leading into\nliver cancer. Early detection of fatty liver can thus prevent from\nthe permanent failure of the liver. To identify the fatty liver\ncondition, ultrasound imaging is the widely used diagnostic\nmethod.\nFig. 2 shows the proposed architecture for the novel low-\ncost and scalable eHealth architecture for fatty liver classiﬁca-\ntion. The entire architecture can be",
        "] S. M. Abd El-Kader and E. M. El-Den Ashmawy, “Non-alcoholic fatty\nliver disease: The diagnosis and management.” World J. Hepatol , Apr.\n2015, vol. 7, pp. 846858. doi: 10.4254/wjh.v7.i6.846.\n[18] P. V ogel, T. Klooster, V . Andrikopoulos and M. Lungu, “A Low-\nEffort Analytics Platform for Visualizing Evolving Flask-Based Python\nWeb Services,” 2017 IEEE Working Conference on Software Visual-\nization (VISSOFT), Shanghai, 2017, pp. 109-113. doi: 10.1109/VIS-\nSOFT.2017.13\n[19] D. S. Reddy, R. Bharath and P. Rajalakshmi, “A Novel Computer-Aided\nDiagnosis Framework Using Deep Learning for Classiﬁcation of Fatty\nLiver Disease in Ultrasound Imaging,” 2018 IEEE 20th International\nConference on e-Health Networking, Applications and Services (Health-\ncom), Ostrava, 2018, pp. 1-5. doi: 10.1109/HealthCom.2018.8531118\n[20] K. Simonyan and A. Zisserman, “Very deep convolutional networks for\nlarge-scale image recognition,” in Proc. Int. Conf. Learn. Representa-\ntions, 2015.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n506\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. "
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2098
    },
    {
      "id": "Q8",
      "question": "How are outliers handled in this study?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        7,
        9,
        6
      ],
      "chunks_str": [
        " and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C. Silva, F. D. M. Guedes and\nJ. J. P. C. Rodrigues, “A mobile healthcare solution for ambient assisted\nliving environments,” 2014 IEEE 16th International Conference on e-\nHealth Networking, Applications and Services (Healthcom), Natal, 2014,\npp. 170-175. doi: 10.1109/HealthCom.2014.7001836\n[4] J. M. Quero et al., “Health Care Applications Based on Mobile Phone\nCentric Smart Sensor Network,” 2007 29th Annual International Con-\nference of the IEEE Engineering in Medicine and Biology Society, Lyon,\n2007, pp. 6298-6301. doi: 10.1109/IEMBS.2007.4353795\n[5] Kvedar et al., “Connected health: A review of technologies and strategies\nto improve patient care with telemedicine and telehealth,”Health Affairs,\nvol. 33, pp. 194199, 2014.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n505\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\n[6] Swerdlow, D.R. et. al., “Robotic armassisted sonography: Review of\ntechnical developments and potential clinical applications,” Am. J.\nRoentgenol., vol. 208, pp. 733738, 2017.\n[7] J. Grundy, M. Abdelrazek and M. K. Curumsing, “Vision: Improved\nDevelopment of Mobile eHealth Applications,” 2018 IEEE/ACM 5th\nInternational Conference on Mobile Software Engineering and Systems\n(MOBILESoft), Gothenburg, Sweden, 2018, pp. 219-223.\n[8] H.-Y . Tang et al., “Miniaturizing ultrasonic system for portable health\ncare and ﬁtness,” IEEE Trans. Biomed. Circuits Syst., vol. 9, no. 6, pp.\n767776, Dec. 2015.\n[9] J. Kang et al., “A System-on-Chip Solution for Point-of-Care Ultrasound\nImaging Systems: Architecture and ASIC Implementation,” in IEEE\nTransactions on Biomedical Circuits and Systems, vol. 10, no. 2, pp.\n412-423, April 2016. doi: 10.1109/TBCAS.2015.2431272\n[10] Stawicki, Stanislaw Peter, and David Paul Bahner. “Modern sonology\nand the bedside practitioner: evolution of ultrasound from curious\nnovelty to essential clinical tool,” European Journal of Trauma and\nEmergency Surgery 41.5, 457-460, 2015.\n[11] R. Bharath et al., “Portable ultrasound scanner for remote diagnosis,”\n2015 17th International Conference on E-health Networking",
        "] S. M. Abd El-Kader and E. M. El-Den Ashmawy, “Non-alcoholic fatty\nliver disease: The diagnosis and management.” World J. Hepatol , Apr.\n2015, vol. 7, pp. 846858. doi: 10.4254/wjh.v7.i6.846.\n[18] P. V ogel, T. Klooster, V . Andrikopoulos and M. Lungu, “A Low-\nEffort Analytics Platform for Visualizing Evolving Flask-Based Python\nWeb Services,” 2017 IEEE Working Conference on Software Visual-\nization (VISSOFT), Shanghai, 2017, pp. 109-113. doi: 10.1109/VIS-\nSOFT.2017.13\n[19] D. S. Reddy, R. Bharath and P. Rajalakshmi, “A Novel Computer-Aided\nDiagnosis Framework Using Deep Learning for Classiﬁcation of Fatty\nLiver Disease in Ultrasound Imaging,” 2018 IEEE 20th International\nConference on e-Health Networking, Applications and Services (Health-\ncom), Ostrava, 2018, pp. 1-5. doi: 10.1109/HealthCom.2018.8531118\n[20] K. Simonyan and A. Zisserman, “Very deep convolutional networks for\nlarge-scale image recognition,” in Proc. Int. Conf. Learn. Representa-\ntions, 2015.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n506\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. ",
        " Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for improving the state of\nthe art research in the development of scalable and low-cost\neHealth applications.\nV. CONCLUSION\nIn this paper, we proposed and developed a low-cost and\neasily scalable eHealth architecture comprising of a web\napplication for automatic classiﬁcation of fatty liver using\nultrasound images. The developed web application is easy to\nuse and requires no change in the current infrastructure. The\nultrasound images obtained using the traditional ultrasound\nscanners can be uploaded to the developed web application\nusing moderate network connectivity and the web application\nthen classiﬁes the image into either normal or abnormal using\na CNN based framework. The performance of the proposed\nframework is tested with with 58 ultrasound images, we have\ndeveloped a custom database comprising of 58 ultrasound\nimages with liver information of which 36 correspond to liver\nimages are normal conditions and the rest correspond to a fatty\nliver condition. It is observed that the proposed framework\nachieves an average accuracy of 91.37%. Also, the latency\nanalysis shows that the proposed CNN model predicts within\n20 ms when running on a PC with Intel i7 processor and 16 GB\nRAM. Also when considered along with the network latency\nthe total latency observed is approximately 150 ms when used\nwith moderate network connectivity. Hence, we strongly feel\nthat the proposed eHealth framework will help future research\nin developing low-cost, easily scalable and ubiquitous eHealth\nframeworks. Our future scope of this work is to develop a more\nrobust classiﬁcation framework which can eliminate the false\nnegatives. Also, we would like to consider real-time trials in\ncoordination with hospitals to analyze the performance in real\nconstraints.\nVI. ACKNOWLEDGMENT\nWe are thankful to the team of radiologists at Asian Institute\nof Gastroenterology and MNR Medical College & Hospital,\nHyderabad, Telangana, India, for spending their valuable time\nduring this research. This research was partly funded by\nvisvesvaraya Ph.D. Scheme, Media Lab Asia, MEITY , Govt.\nof India and partly funded by Indian Institute of Technology\nHyderabad.\nREFERENCES\n[1] B. Farahani, F. Firouzi, V . Chang, M. Badaroglu, N. Constant, and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2103
    },
    {
      "id": "Q9",
      "question": "Which prediction models were used in this study?",
      "answer": "VGG-16 model with transfer learning and fine-tuning.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        4,
        7,
        2
      ],
      "chunks_str": [
        "ician.\nFig. 3. Developed web interface along with the ultrasound and prediction\nwhen tested using a normal liver image.\nFig. 4. Developed web interface along with the ultrasound and prediction\nwhen tested using a liver image with a fatty liver condition.\nIII. D EVELOPED CNN BASED ACCURATE FATTY LIVER\nCLASSIFICATION FRAMEWORK\nIn [19], we have developed a novel CNN based accurate\nfatty liver classiﬁcation model using ultrasound images. The\nsame model is adopted in this paper for the classiﬁcation of\nfatty liver using ultrasound images. The architecture comprises\nof a pre-trained VGG-16 model along with the transfer learn-\ning and ﬁne-tuning. VGGNet using CNN is initially designed\nwith different layer depths aiming for image recognition tasks.\nPreliminary analysis of VGGNet offered a promising accuracy\nof 92.7% when validated using the ImagNet dataset com-\nprising of 14 million images from 1000 classes [20]. In this\npaper, we make use the 16 layers VGG-16 with convolution\nblocks(including convolution layers and max-pooling layers)\nand a fully connected classiﬁer. The ﬁne-tuning is carried out\nusing the pre-trained VGG-16 model in Keras. Traditionally,\nthe convolution 2D layers in VGG-16 consists of 512 nodes for\nconvolution layers, however, in our experiment we ﬁne-tuned\nthe network from using 512 nodes to 256 nodes. Also, we ﬁne-\ntuned fully connected layers having 4096 nodes to 256 nodes,\nand the output layer comprises two neurons whose output\ncorresponds to the two classes (normal and abnormal) in this\nstudy. During the training of the model, the weight parameters\nof the output layer are initialized using random Gaussian\ndistribution, and the training is performed over 100 epochs.\nSince the development of the CNN based accurate fatty liver\nclassiﬁcation framework is not our primary contribution in this\npaper, we would like to advise the readers to kindly refer [19]\nfor more details on the developed model. However, we would\nlike to highlight that the database used for validation in [19]\nis different from what we used here.\nIV. R ESULTS\nThe publicly available datasets for ultrasound images of the\nliver are very few. Hence, due to the unavailability of the\npublic datasets, we acquired and developed our own dataset\nusing a GE LOGIQ F6 ultrasound scanner in collaboration\nwith MNR Medical College, Sangareddy, Hyderabad, India.\nThe dataset consisted of 58 representative liver images com-\nprising of both fatty liver (22 images) and normal conditions\n(36 images). We cropped the images which does not convey\nany diagnostic information such as hospital name, time of the\ndiagnosis, etc. Also, since the pre-trained models are trained\nwith an input image size of 224×224 pixels, the images of\nour dataset were also resized to 224×224 pixels for compat-\nibility. The performance of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.",
        " and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C. Silva, F. D. M. Guedes and\nJ. J. P. C. Rodrigues, “A mobile healthcare solution for ambient assisted\nliving environments,” 2014 IEEE 16th International Conference on e-\nHealth Networking, Applications and Services (Healthcom), Natal, 2014,\npp. 170-175. doi: 10.1109/HealthCom.2014.7001836\n[4] J. M. Quero et al., “Health Care Applications Based on Mobile Phone\nCentric Smart Sensor Network,” 2007 29th Annual International Con-\nference of the IEEE Engineering in Medicine and Biology Society, Lyon,\n2007, pp. 6298-6301. doi: 10.1109/IEMBS.2007.4353795\n[5] Kvedar et al., “Connected health: A review of technologies and strategies\nto improve patient care with telemedicine and telehealth,”Health Affairs,\nvol. 33, pp. 194199, 2014.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n505\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\n[6] Swerdlow, D.R. et. al., “Robotic armassisted sonography: Review of\ntechnical developments and potential clinical applications,” Am. J.\nRoentgenol., vol. 208, pp. 733738, 2017.\n[7] J. Grundy, M. Abdelrazek and M. K. Curumsing, “Vision: Improved\nDevelopment of Mobile eHealth Applications,” 2018 IEEE/ACM 5th\nInternational Conference on Mobile Software Engineering and Systems\n(MOBILESoft), Gothenburg, Sweden, 2018, pp. 219-223.\n[8] H.-Y . Tang et al., “Miniaturizing ultrasonic system for portable health\ncare and ﬁtness,” IEEE Trans. Biomed. Circuits Syst., vol. 9, no. 6, pp.\n767776, Dec. 2015.\n[9] J. Kang et al., “A System-on-Chip Solution for Point-of-Care Ultrasound\nImaging Systems: Architecture and ASIC Implementation,” in IEEE\nTransactions on Biomedical Circuits and Systems, vol. 10, no. 2, pp.\n412-423, April 2016. doi: 10.1109/TBCAS.2015.2431272\n[10] Stawicki, Stanislaw Peter, and David Paul Bahner. “Modern sonology\nand the bedside practitioner: evolution of ultrasound from curious\nnovelty to essential clinical tool,” European Journal of Trauma and\nEmergency Surgery 41.5, 457-460, 2015.\n[11] R. Bharath et al., “Portable ultrasound scanner for remote diagnosis,”\n2015 17th International Conference on E-health Networking",
        " eHealth ap-\nplications using scalable video coding (SVC) extension for\nMPEC-4 A VC/H.264 which enables a doctor in a different\nlocation to administer the scanning in real-time. This solution\nis feasible in areas where high bandwidth network connectivity\nis available and may not be a suitable solution for rural areas.\nIn [14] In [14], authors proposed an abnormality detection\nbased on Viola Jones and Support Vector Machine (SVM)\nclassiﬁer to detect the abnormality in ultrasound image. In\n[15], authors proposed a framework for compressing the\nultrasound images using web real-time communication (We-\nbRTC) framework technology for low data real-time eHealth\napplications. However, it still requires the high performance\nnetwork connectivity which is not available in rural areas.\nAlso, in [16] the authors have developed similar frameworks\nfor tele-diagnosis wherein the ultrasound scanning information\nis streamed to the expert side for getting inferences. In all the\nabove studies the major drawbacks include the following: (1)\nthe infrastructure needs to be replaced, (2) requirement of high\nperformance network connectivity and (3) manual observance\nof the ultrasound data which is prone to errors and entirely\ndepends on the skill of the sonographers. Hence, in this paper,\nwe developed a web based architecture wherein a clinician can\nupload the ultrasound image and can get accurate diagnosis\ninformation. This architecture does not require any change in\nthe existing infrastructure and is an easily scalable solution\nespecially for developing nations.\nThe rest of this paper is organized as follows. Section\nII describes the proposed architecture and the functional\nunits present. Section III describes the developed CNN based\nclassiﬁcation framework for accurate classiﬁcation of fatty\nliver using ultrasound images. In Section IV , we discuss\nthe dataset developed for analyzing the performance of the\nproposed architecture and the key insights observed from the\nperformance analysis. Finally, Section V concludes the paper\nby summarizing the work performed and discussed the future\nscope of this work.\nII. P ROPOSED NOVEL E HEALTH ARCHITECTURE FOR\nACCURATE WEB BASED FATTY LIVER CLASSIFICATION\nFig. 1 shows the ultrasound images of liver under normal\nconditions and those with affected by fatty liver. Excess fat\naccumulated in the liver can lead to fatty liver conditions\nand can cause severe liver damage. The normal liver usually\ncontains 5 to 10% of the fat and if the fat concentration\nexceeds beyond this limit, it is observed as a fatty liver\n(a)\n(b)\nFig. 1. (a) Ultrasound images of liver under normal conditions, (b) Ultrasound\nimages of liver under fatty liver conditions.\nWeb \nBrowser\nPre−processingUltrasound\nLiver Image\nNormal\nAbnormal\nOutput Prediction\nCNN Based\nClassifier\nClient Interface (Remote Location) Cloud Based Web Application\nFig. 2. Proposed novel low-cost and scalable eHealth architecture for accurate\nweb based fatty liver classiﬁcation\ncondition. The liver in general is capable of repairing if the\nold cells are damaged by rebuilding the new liver cells until\nrepeated liver damage occurs. Currently, the fatty liver disease\nis becoming a more prevailing condition, affecting about 25 to\n30 % of the population in both the developed and developing\ncountries [17]. If the condition is left untreated, fatty liver\nleads to more harmful steatohepatitis gradually leading into\nliver cancer. Early detection of fatty liver can thus prevent from\nthe permanent failure of the liver. To identify the fatty liver\ncondition, ultrasound imaging is the widely used diagnostic\nmethod.\nFig. 2 shows the proposed architecture for the novel low-\ncost and scalable eHealth architecture for fatty liver classiﬁca-\ntion. The entire architecture can be"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2542
    },
    {
      "id": "Q10",
      "question": "What considerations were given to model selection and hyperparameter tuning in this study?",
      "answer": "Unknown from this paper",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        5,
        9,
        8
      ],
      "chunks_str": [
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for",
        "] S. M. Abd El-Kader and E. M. El-Den Ashmawy, “Non-alcoholic fatty\nliver disease: The diagnosis and management.” World J. Hepatol , Apr.\n2015, vol. 7, pp. 846858. doi: 10.4254/wjh.v7.i6.846.\n[18] P. V ogel, T. Klooster, V . Andrikopoulos and M. Lungu, “A Low-\nEffort Analytics Platform for Visualizing Evolving Flask-Based Python\nWeb Services,” 2017 IEEE Working Conference on Software Visual-\nization (VISSOFT), Shanghai, 2017, pp. 109-113. doi: 10.1109/VIS-\nSOFT.2017.13\n[19] D. S. Reddy, R. Bharath and P. Rajalakshmi, “A Novel Computer-Aided\nDiagnosis Framework Using Deep Learning for Classiﬁcation of Fatty\nLiver Disease in Ultrasound Imaging,” 2018 IEEE 20th International\nConference on e-Health Networking, Applications and Services (Health-\ncom), Ostrava, 2018, pp. 1-5. doi: 10.1109/HealthCom.2018.8531118\n[20] K. Simonyan and A. Zisserman, “Very deep convolutional networks for\nlarge-scale image recognition,” in Proc. Int. Conf. Learn. Representa-\ntions, 2015.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n506\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. ",
        " Point-of-Care Ultrasound\nImaging Systems: Architecture and ASIC Implementation,” in IEEE\nTransactions on Biomedical Circuits and Systems, vol. 10, no. 2, pp.\n412-423, April 2016. doi: 10.1109/TBCAS.2015.2431272\n[10] Stawicki, Stanislaw Peter, and David Paul Bahner. “Modern sonology\nand the bedside practitioner: evolution of ultrasound from curious\nnovelty to essential clinical tool,” European Journal of Trauma and\nEmergency Surgery 41.5, 457-460, 2015.\n[11] R. Bharath et al., “Portable ultrasound scanner for remote diagnosis,”\n2015 17th International Conference on E-health Networking, Applica-\ntion & Services (HealthCom), Boston, MA, 2015, pp. 211-216. doi:\n10.1109/HealthCom.2015.7454500\n[12] R. K. Megalingam, G. Pocklassery, V . Jayakrishnan and G. Mourya,\n“PULSS: Portable ultrasound scanning system,” 2013 IEEE Global Hu-\nmanitarian Technology Conference: South Asia Satellite (GHTC-SAS),\nTrivandrum, 2013, pp. 119-123. doi: 10.1109/GHTC-SAS.2013.6629900\n[13] M. Shoaib, U. Ahmad and A. Al-Amri, “Multimedia framework to\nsupport eHealth applications,” Multimedia Tools and Applications, Dec.\n2014, vol. 73, no. 3, pp. 2081-2101.\n[14] P. Vaish, R. Bharath, P. Rajalakshmi and U. B. Desai, “Smartphone\nbased automatic abnormality detection of kidney in ultrasound images,”\n2016 IEEE 18th International Conference on e-Health Networking,\nApplications and Services (Healthcom), Munich, 2016, pp. 1-6. doi:\n10.1109/HealthCom.2016.7749492\n[15] R. Bharath, P. Vaish and P. Rajalakshmi, “Implementation of diagnosti-\ncally driven compression algorithms via WebRTC for IoT enabled tele-\nsonography,” 2016 IEEE EMBS Conference on Biomedical Engineer-\ning and Sciences (IECBES), Kuala Lumpur, 2016, pp. 204-209. doi:\n10.1109/IECBES.2016.7843443\n[16] R. Bharath and P. Rajalakshmi, “WebRTC based invariant scattering\nconvolution network for automated validation of ultrasonic videos for\nIoT enabled tele-sonography,” 2018 IEEE 4th World Forum on Internet\nof Things (WF-IoT), Singapore, 2018, pp. 790-795. doi: 10.1109/WF-\nIoT.2018.8355197\n[17] S. M. Abd El-Kader and E. M. El-Den Ashmawy, “Non-alcoholic fatty\nliver disease: The diagnosis and management.” World J. Hepatol , Apr.\n2015, vol. 7, pp. 846858. doi: 10.4254/wjh.v7.i6.846.\n[18] P. V ogel, T. Klooster, V . Andrikopoulos and M. Lungu, “A Low-\nEffort Analytics Platform for Visualizing Evolving Flask-Based Python\nWeb Services,” 2017 IEEE Working Conference on Software Visual-\nization (VISSOFT), Shanghai, 2017, pp. 109-113. doi: 10.1109/V"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE"
    },
    {
      "id": "Q11",
      "question": "Is the performance of the predictive models benchmarked or compared to a baseline?",
      "answer": "Unknown from this paper",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        5,
        4,
        6
      ],
      "chunks_str": [
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for",
        "ician.\nFig. 3. Developed web interface along with the ultrasound and prediction\nwhen tested using a normal liver image.\nFig. 4. Developed web interface along with the ultrasound and prediction\nwhen tested using a liver image with a fatty liver condition.\nIII. D EVELOPED CNN BASED ACCURATE FATTY LIVER\nCLASSIFICATION FRAMEWORK\nIn [19], we have developed a novel CNN based accurate\nfatty liver classiﬁcation model using ultrasound images. The\nsame model is adopted in this paper for the classiﬁcation of\nfatty liver using ultrasound images. The architecture comprises\nof a pre-trained VGG-16 model along with the transfer learn-\ning and ﬁne-tuning. VGGNet using CNN is initially designed\nwith different layer depths aiming for image recognition tasks.\nPreliminary analysis of VGGNet offered a promising accuracy\nof 92.7% when validated using the ImagNet dataset com-\nprising of 14 million images from 1000 classes [20]. In this\npaper, we make use the 16 layers VGG-16 with convolution\nblocks(including convolution layers and max-pooling layers)\nand a fully connected classiﬁer. The ﬁne-tuning is carried out\nusing the pre-trained VGG-16 model in Keras. Traditionally,\nthe convolution 2D layers in VGG-16 consists of 512 nodes for\nconvolution layers, however, in our experiment we ﬁne-tuned\nthe network from using 512 nodes to 256 nodes. Also, we ﬁne-\ntuned fully connected layers having 4096 nodes to 256 nodes,\nand the output layer comprises two neurons whose output\ncorresponds to the two classes (normal and abnormal) in this\nstudy. During the training of the model, the weight parameters\nof the output layer are initialized using random Gaussian\ndistribution, and the training is performed over 100 epochs.\nSince the development of the CNN based accurate fatty liver\nclassiﬁcation framework is not our primary contribution in this\npaper, we would like to advise the readers to kindly refer [19]\nfor more details on the developed model. However, we would\nlike to highlight that the database used for validation in [19]\nis different from what we used here.\nIV. R ESULTS\nThe publicly available datasets for ultrasound images of the\nliver are very few. Hence, due to the unavailability of the\npublic datasets, we acquired and developed our own dataset\nusing a GE LOGIQ F6 ultrasound scanner in collaboration\nwith MNR Medical College, Sangareddy, Hyderabad, India.\nThe dataset consisted of 58 representative liver images com-\nprising of both fatty liver (22 images) and normal conditions\n(36 images). We cropped the images which does not convey\nany diagnostic information such as hospital name, time of the\ndiagnosis, etc. Also, since the pre-trained models are trained\nwith an input image size of 224×224 pixels, the images of\nour dataset were also resized to 224×224 pixels for compat-\nibility. The performance of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.",
        " Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for improving the state of\nthe art research in the development of scalable and low-cost\neHealth applications.\nV. CONCLUSION\nIn this paper, we proposed and developed a low-cost and\neasily scalable eHealth architecture comprising of a web\napplication for automatic classiﬁcation of fatty liver using\nultrasound images. The developed web application is easy to\nuse and requires no change in the current infrastructure. The\nultrasound images obtained using the traditional ultrasound\nscanners can be uploaded to the developed web application\nusing moderate network connectivity and the web application\nthen classiﬁes the image into either normal or abnormal using\na CNN based framework. The performance of the proposed\nframework is tested with with 58 ultrasound images, we have\ndeveloped a custom database comprising of 58 ultrasound\nimages with liver information of which 36 correspond to liver\nimages are normal conditions and the rest correspond to a fatty\nliver condition. It is observed that the proposed framework\nachieves an average accuracy of 91.37%. Also, the latency\nanalysis shows that the proposed CNN model predicts within\n20 ms when running on a PC with Intel i7 processor and 16 GB\nRAM. Also when considered along with the network latency\nthe total latency observed is approximately 150 ms when used\nwith moderate network connectivity. Hence, we strongly feel\nthat the proposed eHealth framework will help future research\nin developing low-cost, easily scalable and ubiquitous eHealth\nframeworks. Our future scope of this work is to develop a more\nrobust classiﬁcation framework which can eliminate the false\nnegatives. Also, we would like to consider real-time trials in\ncoordination with hospitals to analyze the performance in real\nconstraints.\nVI. ACKNOWLEDGMENT\nWe are thankful to the team of radiologists at Asian Institute\nof Gastroenterology and MNR Medical College & Hospital,\nHyderabad, Telangana, India, for spending their valuable time\nduring this research. This research was partly funded by\nvisvesvaraya Ph.D. Scheme, Media Lab Asia, MEITY , Govt.\nof India and partly funded by Indian Institute of Technology\nHyderabad.\nREFERENCES\n[1] B. Farahani, F. Firouzi, V . Chang, M. Badaroglu, N. Constant, and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE"
    },
    {
      "id": "Q12",
      "question": "Which type of explainability techniques are used?",
      "answer": "CNN based framework",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        6,
        2,
        5
      ],
      "chunks_str": [
        " Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for improving the state of\nthe art research in the development of scalable and low-cost\neHealth applications.\nV. CONCLUSION\nIn this paper, we proposed and developed a low-cost and\neasily scalable eHealth architecture comprising of a web\napplication for automatic classiﬁcation of fatty liver using\nultrasound images. The developed web application is easy to\nuse and requires no change in the current infrastructure. The\nultrasound images obtained using the traditional ultrasound\nscanners can be uploaded to the developed web application\nusing moderate network connectivity and the web application\nthen classiﬁes the image into either normal or abnormal using\na CNN based framework. The performance of the proposed\nframework is tested with with 58 ultrasound images, we have\ndeveloped a custom database comprising of 58 ultrasound\nimages with liver information of which 36 correspond to liver\nimages are normal conditions and the rest correspond to a fatty\nliver condition. It is observed that the proposed framework\nachieves an average accuracy of 91.37%. Also, the latency\nanalysis shows that the proposed CNN model predicts within\n20 ms when running on a PC with Intel i7 processor and 16 GB\nRAM. Also when considered along with the network latency\nthe total latency observed is approximately 150 ms when used\nwith moderate network connectivity. Hence, we strongly feel\nthat the proposed eHealth framework will help future research\nin developing low-cost, easily scalable and ubiquitous eHealth\nframeworks. Our future scope of this work is to develop a more\nrobust classiﬁcation framework which can eliminate the false\nnegatives. Also, we would like to consider real-time trials in\ncoordination with hospitals to analyze the performance in real\nconstraints.\nVI. ACKNOWLEDGMENT\nWe are thankful to the team of radiologists at Asian Institute\nof Gastroenterology and MNR Medical College & Hospital,\nHyderabad, Telangana, India, for spending their valuable time\nduring this research. This research was partly funded by\nvisvesvaraya Ph.D. Scheme, Media Lab Asia, MEITY , Govt.\nof India and partly funded by Indian Institute of Technology\nHyderabad.\nREFERENCES\n[1] B. Farahani, F. Firouzi, V . Chang, M. Badaroglu, N. Constant, and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C",
        " eHealth ap-\nplications using scalable video coding (SVC) extension for\nMPEC-4 A VC/H.264 which enables a doctor in a different\nlocation to administer the scanning in real-time. This solution\nis feasible in areas where high bandwidth network connectivity\nis available and may not be a suitable solution for rural areas.\nIn [14] In [14], authors proposed an abnormality detection\nbased on Viola Jones and Support Vector Machine (SVM)\nclassiﬁer to detect the abnormality in ultrasound image. In\n[15], authors proposed a framework for compressing the\nultrasound images using web real-time communication (We-\nbRTC) framework technology for low data real-time eHealth\napplications. However, it still requires the high performance\nnetwork connectivity which is not available in rural areas.\nAlso, in [16] the authors have developed similar frameworks\nfor tele-diagnosis wherein the ultrasound scanning information\nis streamed to the expert side for getting inferences. In all the\nabove studies the major drawbacks include the following: (1)\nthe infrastructure needs to be replaced, (2) requirement of high\nperformance network connectivity and (3) manual observance\nof the ultrasound data which is prone to errors and entirely\ndepends on the skill of the sonographers. Hence, in this paper,\nwe developed a web based architecture wherein a clinician can\nupload the ultrasound image and can get accurate diagnosis\ninformation. This architecture does not require any change in\nthe existing infrastructure and is an easily scalable solution\nespecially for developing nations.\nThe rest of this paper is organized as follows. Section\nII describes the proposed architecture and the functional\nunits present. Section III describes the developed CNN based\nclassiﬁcation framework for accurate classiﬁcation of fatty\nliver using ultrasound images. In Section IV , we discuss\nthe dataset developed for analyzing the performance of the\nproposed architecture and the key insights observed from the\nperformance analysis. Finally, Section V concludes the paper\nby summarizing the work performed and discussed the future\nscope of this work.\nII. P ROPOSED NOVEL E HEALTH ARCHITECTURE FOR\nACCURATE WEB BASED FATTY LIVER CLASSIFICATION\nFig. 1 shows the ultrasound images of liver under normal\nconditions and those with affected by fatty liver. Excess fat\naccumulated in the liver can lead to fatty liver conditions\nand can cause severe liver damage. The normal liver usually\ncontains 5 to 10% of the fat and if the fat concentration\nexceeds beyond this limit, it is observed as a fatty liver\n(a)\n(b)\nFig. 1. (a) Ultrasound images of liver under normal conditions, (b) Ultrasound\nimages of liver under fatty liver conditions.\nWeb \nBrowser\nPre−processingUltrasound\nLiver Image\nNormal\nAbnormal\nOutput Prediction\nCNN Based\nClassifier\nClient Interface (Remote Location) Cloud Based Web Application\nFig. 2. Proposed novel low-cost and scalable eHealth architecture for accurate\nweb based fatty liver classiﬁcation\ncondition. The liver in general is capable of repairing if the\nold cells are damaged by rebuilding the new liver cells until\nrepeated liver damage occurs. Currently, the fatty liver disease\nis becoming a more prevailing condition, affecting about 25 to\n30 % of the population in both the developed and developing\ncountries [17]. If the condition is left untreated, fatty liver\nleads to more harmful steatohepatitis gradually leading into\nliver cancer. Early detection of fatty liver can thus prevent from\nthe permanent failure of the liver. To identify the fatty liver\ncondition, ultrasound imaging is the widely used diagnostic\nmethod.\nFig. 2 shows the proposed architecture for the novel low-\ncost and scalable eHealth architecture for fatty liver classiﬁca-\ntion. The entire architecture can be",
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2522
    },
    {
      "id": "Q13",
      "question": "Which evaluation metrics or outcome measures are used to assess the predictive models?",
      "answer": "Accuracy, confusion matrix, F-score, Precision, Recall.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        5,
        4,
        9
      ],
      "chunks_str": [
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for",
        "ician.\nFig. 3. Developed web interface along with the ultrasound and prediction\nwhen tested using a normal liver image.\nFig. 4. Developed web interface along with the ultrasound and prediction\nwhen tested using a liver image with a fatty liver condition.\nIII. D EVELOPED CNN BASED ACCURATE FATTY LIVER\nCLASSIFICATION FRAMEWORK\nIn [19], we have developed a novel CNN based accurate\nfatty liver classiﬁcation model using ultrasound images. The\nsame model is adopted in this paper for the classiﬁcation of\nfatty liver using ultrasound images. The architecture comprises\nof a pre-trained VGG-16 model along with the transfer learn-\ning and ﬁne-tuning. VGGNet using CNN is initially designed\nwith different layer depths aiming for image recognition tasks.\nPreliminary analysis of VGGNet offered a promising accuracy\nof 92.7% when validated using the ImagNet dataset com-\nprising of 14 million images from 1000 classes [20]. In this\npaper, we make use the 16 layers VGG-16 with convolution\nblocks(including convolution layers and max-pooling layers)\nand a fully connected classiﬁer. The ﬁne-tuning is carried out\nusing the pre-trained VGG-16 model in Keras. Traditionally,\nthe convolution 2D layers in VGG-16 consists of 512 nodes for\nconvolution layers, however, in our experiment we ﬁne-tuned\nthe network from using 512 nodes to 256 nodes. Also, we ﬁne-\ntuned fully connected layers having 4096 nodes to 256 nodes,\nand the output layer comprises two neurons whose output\ncorresponds to the two classes (normal and abnormal) in this\nstudy. During the training of the model, the weight parameters\nof the output layer are initialized using random Gaussian\ndistribution, and the training is performed over 100 epochs.\nSince the development of the CNN based accurate fatty liver\nclassiﬁcation framework is not our primary contribution in this\npaper, we would like to advise the readers to kindly refer [19]\nfor more details on the developed model. However, we would\nlike to highlight that the database used for validation in [19]\nis different from what we used here.\nIV. R ESULTS\nThe publicly available datasets for ultrasound images of the\nliver are very few. Hence, due to the unavailability of the\npublic datasets, we acquired and developed our own dataset\nusing a GE LOGIQ F6 ultrasound scanner in collaboration\nwith MNR Medical College, Sangareddy, Hyderabad, India.\nThe dataset consisted of 58 representative liver images com-\nprising of both fatty liver (22 images) and normal conditions\n(36 images). We cropped the images which does not convey\nany diagnostic information such as hospital name, time of the\ndiagnosis, etc. Also, since the pre-trained models are trained\nwith an input image size of 224×224 pixels, the images of\nour dataset were also resized to 224×224 pixels for compat-\nibility. The performance of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.",
        "] S. M. Abd El-Kader and E. M. El-Den Ashmawy, “Non-alcoholic fatty\nliver disease: The diagnosis and management.” World J. Hepatol , Apr.\n2015, vol. 7, pp. 846858. doi: 10.4254/wjh.v7.i6.846.\n[18] P. V ogel, T. Klooster, V . Andrikopoulos and M. Lungu, “A Low-\nEffort Analytics Platform for Visualizing Evolving Flask-Based Python\nWeb Services,” 2017 IEEE Working Conference on Software Visual-\nization (VISSOFT), Shanghai, 2017, pp. 109-113. doi: 10.1109/VIS-\nSOFT.2017.13\n[19] D. S. Reddy, R. Bharath and P. Rajalakshmi, “A Novel Computer-Aided\nDiagnosis Framework Using Deep Learning for Classiﬁcation of Fatty\nLiver Disease in Ultrasound Imaging,” 2018 IEEE 20th International\nConference on e-Health Networking, Applications and Services (Health-\ncom), Ostrava, 2018, pp. 1-5. doi: 10.1109/HealthCom.2018.8531118\n[20] K. Simonyan and A. Zisserman, “Very deep convolutional networks for\nlarge-scale image recognition,” in Proc. Int. Conf. Learn. Representa-\ntions, 2015.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n506\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. "
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2129
    },
    {
      "id": "Q14",
      "question": "What considerations were given to selected evaluation metrics or outcome measures in this study?",
      "answer": "Classification accuracy, confusion matrix, F-score, precision, recall, latency.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        5,
        8,
        9
      ],
      "chunks_str": [
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for",
        " Point-of-Care Ultrasound\nImaging Systems: Architecture and ASIC Implementation,” in IEEE\nTransactions on Biomedical Circuits and Systems, vol. 10, no. 2, pp.\n412-423, April 2016. doi: 10.1109/TBCAS.2015.2431272\n[10] Stawicki, Stanislaw Peter, and David Paul Bahner. “Modern sonology\nand the bedside practitioner: evolution of ultrasound from curious\nnovelty to essential clinical tool,” European Journal of Trauma and\nEmergency Surgery 41.5, 457-460, 2015.\n[11] R. Bharath et al., “Portable ultrasound scanner for remote diagnosis,”\n2015 17th International Conference on E-health Networking, Applica-\ntion & Services (HealthCom), Boston, MA, 2015, pp. 211-216. doi:\n10.1109/HealthCom.2015.7454500\n[12] R. K. Megalingam, G. Pocklassery, V . Jayakrishnan and G. Mourya,\n“PULSS: Portable ultrasound scanning system,” 2013 IEEE Global Hu-\nmanitarian Technology Conference: South Asia Satellite (GHTC-SAS),\nTrivandrum, 2013, pp. 119-123. doi: 10.1109/GHTC-SAS.2013.6629900\n[13] M. Shoaib, U. Ahmad and A. Al-Amri, “Multimedia framework to\nsupport eHealth applications,” Multimedia Tools and Applications, Dec.\n2014, vol. 73, no. 3, pp. 2081-2101.\n[14] P. Vaish, R. Bharath, P. Rajalakshmi and U. B. Desai, “Smartphone\nbased automatic abnormality detection of kidney in ultrasound images,”\n2016 IEEE 18th International Conference on e-Health Networking,\nApplications and Services (Healthcom), Munich, 2016, pp. 1-6. doi:\n10.1109/HealthCom.2016.7749492\n[15] R. Bharath, P. Vaish and P. Rajalakshmi, “Implementation of diagnosti-\ncally driven compression algorithms via WebRTC for IoT enabled tele-\nsonography,” 2016 IEEE EMBS Conference on Biomedical Engineer-\ning and Sciences (IECBES), Kuala Lumpur, 2016, pp. 204-209. doi:\n10.1109/IECBES.2016.7843443\n[16] R. Bharath and P. Rajalakshmi, “WebRTC based invariant scattering\nconvolution network for automated validation of ultrasonic videos for\nIoT enabled tele-sonography,” 2018 IEEE 4th World Forum on Internet\nof Things (WF-IoT), Singapore, 2018, pp. 790-795. doi: 10.1109/WF-\nIoT.2018.8355197\n[17] S. M. Abd El-Kader and E. M. El-Den Ashmawy, “Non-alcoholic fatty\nliver disease: The diagnosis and management.” World J. Hepatol , Apr.\n2015, vol. 7, pp. 846858. doi: 10.4254/wjh.v7.i6.846.\n[18] P. V ogel, T. Klooster, V . Andrikopoulos and M. Lungu, “A Low-\nEffort Analytics Platform for Visualizing Evolving Flask-Based Python\nWeb Services,” 2017 IEEE Working Conference on Software Visual-\nization (VISSOFT), Shanghai, 2017, pp. 109-113. doi: 10.1109/V",
        "] S. M. Abd El-Kader and E. M. El-Den Ashmawy, “Non-alcoholic fatty\nliver disease: The diagnosis and management.” World J. Hepatol , Apr.\n2015, vol. 7, pp. 846858. doi: 10.4254/wjh.v7.i6.846.\n[18] P. V ogel, T. Klooster, V . Andrikopoulos and M. Lungu, “A Low-\nEffort Analytics Platform for Visualizing Evolving Flask-Based Python\nWeb Services,” 2017 IEEE Working Conference on Software Visual-\nization (VISSOFT), Shanghai, 2017, pp. 109-113. doi: 10.1109/VIS-\nSOFT.2017.13\n[19] D. S. Reddy, R. Bharath and P. Rajalakshmi, “A Novel Computer-Aided\nDiagnosis Framework Using Deep Learning for Classiﬁcation of Fatty\nLiver Disease in Ultrasound Imaging,” 2018 IEEE 20th International\nConference on e-Health Networking, Applications and Services (Health-\ncom), Ostrava, 2018, pp. 1-5. doi: 10.1109/HealthCom.2018.8531118\n[20] K. Simonyan and A. Zisserman, “Very deep convolutional networks for\nlarge-scale image recognition,” in Proc. Int. Conf. Learn. Representa-\ntions, 2015.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n506\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. "
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2128
    },
    {
      "id": "Q15",
      "question": "How were robustness, confidence or statistical significance of the results assessed in this study?",
      "answer": "Classification accuracy, confusion matrix, F-score, precision, recall.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        5,
        6,
        8
      ],
      "chunks_str": [
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for",
        " Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for improving the state of\nthe art research in the development of scalable and low-cost\neHealth applications.\nV. CONCLUSION\nIn this paper, we proposed and developed a low-cost and\neasily scalable eHealth architecture comprising of a web\napplication for automatic classiﬁcation of fatty liver using\nultrasound images. The developed web application is easy to\nuse and requires no change in the current infrastructure. The\nultrasound images obtained using the traditional ultrasound\nscanners can be uploaded to the developed web application\nusing moderate network connectivity and the web application\nthen classiﬁes the image into either normal or abnormal using\na CNN based framework. The performance of the proposed\nframework is tested with with 58 ultrasound images, we have\ndeveloped a custom database comprising of 58 ultrasound\nimages with liver information of which 36 correspond to liver\nimages are normal conditions and the rest correspond to a fatty\nliver condition. It is observed that the proposed framework\nachieves an average accuracy of 91.37%. Also, the latency\nanalysis shows that the proposed CNN model predicts within\n20 ms when running on a PC with Intel i7 processor and 16 GB\nRAM. Also when considered along with the network latency\nthe total latency observed is approximately 150 ms when used\nwith moderate network connectivity. Hence, we strongly feel\nthat the proposed eHealth framework will help future research\nin developing low-cost, easily scalable and ubiquitous eHealth\nframeworks. Our future scope of this work is to develop a more\nrobust classiﬁcation framework which can eliminate the false\nnegatives. Also, we would like to consider real-time trials in\ncoordination with hospitals to analyze the performance in real\nconstraints.\nVI. ACKNOWLEDGMENT\nWe are thankful to the team of radiologists at Asian Institute\nof Gastroenterology and MNR Medical College & Hospital,\nHyderabad, Telangana, India, for spending their valuable time\nduring this research. This research was partly funded by\nvisvesvaraya Ph.D. Scheme, Media Lab Asia, MEITY , Govt.\nof India and partly funded by Indian Institute of Technology\nHyderabad.\nREFERENCES\n[1] B. Farahani, F. Firouzi, V . Chang, M. Badaroglu, N. Constant, and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C",
        " Point-of-Care Ultrasound\nImaging Systems: Architecture and ASIC Implementation,” in IEEE\nTransactions on Biomedical Circuits and Systems, vol. 10, no. 2, pp.\n412-423, April 2016. doi: 10.1109/TBCAS.2015.2431272\n[10] Stawicki, Stanislaw Peter, and David Paul Bahner. “Modern sonology\nand the bedside practitioner: evolution of ultrasound from curious\nnovelty to essential clinical tool,” European Journal of Trauma and\nEmergency Surgery 41.5, 457-460, 2015.\n[11] R. Bharath et al., “Portable ultrasound scanner for remote diagnosis,”\n2015 17th International Conference on E-health Networking, Applica-\ntion & Services (HealthCom), Boston, MA, 2015, pp. 211-216. doi:\n10.1109/HealthCom.2015.7454500\n[12] R. K. Megalingam, G. Pocklassery, V . Jayakrishnan and G. Mourya,\n“PULSS: Portable ultrasound scanning system,” 2013 IEEE Global Hu-\nmanitarian Technology Conference: South Asia Satellite (GHTC-SAS),\nTrivandrum, 2013, pp. 119-123. doi: 10.1109/GHTC-SAS.2013.6629900\n[13] M. Shoaib, U. Ahmad and A. Al-Amri, “Multimedia framework to\nsupport eHealth applications,” Multimedia Tools and Applications, Dec.\n2014, vol. 73, no. 3, pp. 2081-2101.\n[14] P. Vaish, R. Bharath, P. Rajalakshmi and U. B. Desai, “Smartphone\nbased automatic abnormality detection of kidney in ultrasound images,”\n2016 IEEE 18th International Conference on e-Health Networking,\nApplications and Services (Healthcom), Munich, 2016, pp. 1-6. doi:\n10.1109/HealthCom.2016.7749492\n[15] R. Bharath, P. Vaish and P. Rajalakshmi, “Implementation of diagnosti-\ncally driven compression algorithms via WebRTC for IoT enabled tele-\nsonography,” 2016 IEEE EMBS Conference on Biomedical Engineer-\ning and Sciences (IECBES), Kuala Lumpur, 2016, pp. 204-209. doi:\n10.1109/IECBES.2016.7843443\n[16] R. Bharath and P. Rajalakshmi, “WebRTC based invariant scattering\nconvolution network for automated validation of ultrasonic videos for\nIoT enabled tele-sonography,” 2018 IEEE 4th World Forum on Internet\nof Things (WF-IoT), Singapore, 2018, pp. 790-795. doi: 10.1109/WF-\nIoT.2018.8355197\n[17] S. M. Abd El-Kader and E. M. El-Den Ashmawy, “Non-alcoholic fatty\nliver disease: The diagnosis and management.” World J. Hepatol , Apr.\n2015, vol. 7, pp. 846858. doi: 10.4254/wjh.v7.i6.846.\n[18] P. V ogel, T. Klooster, V . Andrikopoulos and M. Lungu, “A Low-\nEffort Analytics Platform for Visualizing Evolving Flask-Based Python\nWeb Services,” 2017 IEEE Working Conference on Software Visual-\nization (VISSOFT), Shanghai, 2017, pp. 109-113. doi: 10.1109/V"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2545
    },
    {
      "id": "Q16",
      "question": "What limitations of the study were discussed?",
      "answer": "Unknown from this paper.",
      "raw_answer": null,
      "choices_ids": null,
      "answer_label": null,
      "chunks_id": [
        5,
        7,
        9
      ],
      "chunks_str": [
        " of the proposed model is analyzed\nconsidering classiﬁcation accuracy, confusion matrix, Fscore,\nPrecision, and Recall as the key performance metrics. The\ndescription of the considered performance metrics are given\nbelow:\nFscore = 2 recall∗precision\n(recall+precision) , (1)\nR\necall = N(TP )\nN(T\nP) +N(FN ) , (2)\nP\nrecision = N(TP )\nN(T\nP) +N(FP ) , (3)\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n504\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\nTABLE I\nCONFUSION MATRIX OF THE PROPOSED ALGORITHM\nTrue class Predicted class\nNormal Abnormal\nNormal (36) 33 3\nAbnormal (22) 2 20\nTABLE II\nPERFORMANCE ANALYSIS OF THE PROPOSED ALGORITHM FOR\nDETECTION AND CLASSIFICATION OF FATTY LIVER .\nClass Precision Recall F1score Support\nNormal 94.2 91.6 92.8 36\nAbnormal 86.9 90.9 88.8 22\nAvg/total 90.5 91.2 90.8 58\nAccur\nacy = N(TP ) +N(TN )\nN(T\nP) +N(TN ) +N(FP ) +N(FN ) , (4)\nwhere N(T\nP) indicates the total true positives, N(FP )\nindicates total false positives, N(TN ) indicates total true\nnegatives and N(FN ) indicates the false negatives. All these\nmeasures are computed for each class, and an overall measure\nof the algorithm is computed by taking the average of all\nthese measures across the two classes. Also, we have analyzed\nthe latency for classiﬁcation to understand the suitability of\nthe framework in areas where moderate internet connection\nis available. From the analysis it is observed that the devel-\noped fatty liver classiﬁcation framework achieved an average\nclassiﬁcation accuracy of 91.37%. Out of the 22 images\nrepresenting fatty liver, 20 are classiﬁed correctly while the\nother 2 images are classiﬁed as normal. Similarly, 3 of the 36\nnormal images are classiﬁed to be abnormal. Table IV shows\nthe confusion matrix obtained when the developed framework\nis validated using the developed dataset. One can observe that\nthe developed algorithm achieves a classiﬁcation accuracy of\n91.37%. Table II gives the obtained Fscore, Precision, and\nRecall. The highest precision of 94.2% is achieved for Normal\ncategory followed by 86.9% for Abnormal. On an average, the\nproposed algorithm offers a precision of 90.5%. Regarding\nrecall, the highest is achieved for Normal class with 91.6%;\nthe lowest recall is obtained with Abnormal 90.9% and the\naverage recall obtained is 91.2%. Finally, the average Fscore\nis observed to be 90.8%, where maximum is Normal 92.8%\nand minimum for Abnormal 88.8% respectively.\nAlso, it is observed that the developed classiﬁcation model\noffers a latency of 20 ms for an image to be classiﬁed\nwhen running on an Intel i7 processor with 16 GB RAM.\nHowever, it is observed that in most of the cases, the latency\ndoes not exceed 150 ms with moderate network connectivity\n(approximately 2 Mbps bandwidth). We strongly feel that this\npaper can aid future researchers for",
        " and\nK. Mankodiya, “Towards fog-driven IoT eHealth: Promises and chal-\nlenges of IoT in medicine and healthcare,” Future Generat. Com-\nput. Syst., vol. 78, pp. 659676, Jan. 2018. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167739X17307677\n[2] Strasser, R., Kam, S.M., and Regalado, S.M. (2016). Rural Health Care\nAccess and Policy in Developing Countries. Annual Review of Public\nHealth, 37, 395-412\n[3] D. F. M. Rodrigues, E. T. Horta, B. M. C. Silva, F. D. M. Guedes and\nJ. J. P. C. Rodrigues, “A mobile healthcare solution for ambient assisted\nliving environments,” 2014 IEEE 16th International Conference on e-\nHealth Networking, Applications and Services (Healthcom), Natal, 2014,\npp. 170-175. doi: 10.1109/HealthCom.2014.7001836\n[4] J. M. Quero et al., “Health Care Applications Based on Mobile Phone\nCentric Smart Sensor Network,” 2007 29th Annual International Con-\nference of the IEEE Engineering in Medicine and Biology Society, Lyon,\n2007, pp. 6298-6301. doi: 10.1109/IEMBS.2007.4353795\n[5] Kvedar et al., “Connected health: A review of technologies and strategies\nto improve patient care with telemedicine and telehealth,”Health Affairs,\nvol. 33, pp. 194199, 2014.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n505\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. \n\n[6] Swerdlow, D.R. et. al., “Robotic armassisted sonography: Review of\ntechnical developments and potential clinical applications,” Am. J.\nRoentgenol., vol. 208, pp. 733738, 2017.\n[7] J. Grundy, M. Abdelrazek and M. K. Curumsing, “Vision: Improved\nDevelopment of Mobile eHealth Applications,” 2018 IEEE/ACM 5th\nInternational Conference on Mobile Software Engineering and Systems\n(MOBILESoft), Gothenburg, Sweden, 2018, pp. 219-223.\n[8] H.-Y . Tang et al., “Miniaturizing ultrasonic system for portable health\ncare and ﬁtness,” IEEE Trans. Biomed. Circuits Syst., vol. 9, no. 6, pp.\n767776, Dec. 2015.\n[9] J. Kang et al., “A System-on-Chip Solution for Point-of-Care Ultrasound\nImaging Systems: Architecture and ASIC Implementation,” in IEEE\nTransactions on Biomedical Circuits and Systems, vol. 10, no. 2, pp.\n412-423, April 2016. doi: 10.1109/TBCAS.2015.2431272\n[10] Stawicki, Stanislaw Peter, and David Paul Bahner. “Modern sonology\nand the bedside practitioner: evolution of ultrasound from curious\nnovelty to essential clinical tool,” European Journal of Trauma and\nEmergency Surgery 41.5, 457-460, 2015.\n[11] R. Bharath et al., “Portable ultrasound scanner for remote diagnosis,”\n2015 17th International Conference on E-health Networking",
        "] S. M. Abd El-Kader and E. M. El-Den Ashmawy, “Non-alcoholic fatty\nliver disease: The diagnosis and management.” World J. Hepatol , Apr.\n2015, vol. 7, pp. 846858. doi: 10.4254/wjh.v7.i6.846.\n[18] P. V ogel, T. Klooster, V . Andrikopoulos and M. Lungu, “A Low-\nEffort Analytics Platform for Visualizing Evolving Flask-Based Python\nWeb Services,” 2017 IEEE Working Conference on Software Visual-\nization (VISSOFT), Shanghai, 2017, pp. 109-113. doi: 10.1109/VIS-\nSOFT.2017.13\n[19] D. S. Reddy, R. Bharath and P. Rajalakshmi, “A Novel Computer-Aided\nDiagnosis Framework Using Deep Learning for Classiﬁcation of Fatty\nLiver Disease in Ultrasound Imaging,” 2018 IEEE 20th International\nConference on e-Health Networking, Applications and Services (Health-\ncom), Ostrava, 2018, pp. 1-5. doi: 10.1109/HealthCom.2018.8531118\n[20] K. Simonyan and A. Zisserman, “Very deep convolutional networks for\nlarge-scale image recognition,” in Proc. Int. Conf. Learn. Representa-\ntions, 2015.\n2019 IEEE 5th World Forum on Internet of Things (WF-IoT)\n506\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 24,2025 at 21:02:36 UTC from IEEE Xplore.  Restrictions apply. "
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2111
    }
  ]
}