{
  "paper": "A Machine Learning Approach to Classifying Self-Reported Health Status in a Cohort of Patients With Heart Disease Using Activity Tracker Data.pdf",
  "answers": [
    {
      "id": "Q1",
      "question": "Which data type is used in this study?",
      "answer": "time-series",
      "raw_answer": "time-series",
      "choices_ids": [
        "tabular",
        "time-series",
        "images",
        "text",
        "video",
        "audio"
      ],
      "answer_label": "time-series",
      "chunks_id": [
        2,
        10,
        3
      ],
      "chunks_str": [
        " experience of their own\nhealth and to provide valid and reliable data [13]–[15]. How-\never, response fatigue is a common problem that can result in\nmissing data due to an incomplete response from the subject,\nresulting in misclassiﬁcation [16], [17]. Response fatigue can be\ncommon when an administered survey is too long, or when a sur-\nvey is short, but administered too frequently. Because of these\ndrawbacks, data collected from a less invasive method could\npotentially provide more reliable estimates of patient health sta-\ntus over time. Previous studies have shown high compliance\nin activity trackers, indicating that they may be more reliable\nmethods for tracking continuous patient data [4], [18].\n2168-2194 © 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\nSee https://www.ieee.org/publications/rights/index.html for more information.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 13,2025 at 13:07:47 UTC from IEEE Xplore.  Restrictions apply. \n\nMENG et al.: MACHINE LEARNING APPROACH TO CLASSIFYING SELF-REPORTED HEALTH STATUS 879\nIn this study, we explore the use of machine learning methods\nto classify PRO scores over time [14]. Machine learning algo-\nrithms have been widely used in biomedical research for tasks\nsuch as disease detection [19] and outcome prediction [20].\nThese methods traditionally use a set of demographic variables\nand baseline data as a feature vector to make a classiﬁcation\nusing a machine learning algorithm such as gradient boosting\nregression tree (GBRT) [21], AdaBoost [22], or random forests\n(RF) [20], [23]. However, traditional machine learning meth-\nods are effective for making single decisions, but do not allow\nfor adjusting as more information is learned. Temporal mod-\nels are appropriate in the case of sequential observations where\nthe value of the outcome may need to be adjusted over time. In\nparticular, hidden Markov models (HMMs) are well-established\ntemporal models that use sequential data to predict events such\nas patient state changes, such as estimating mean sojourn time\nof lung cancer patients using screening images [24], detecting\nhomologous protein sequences [25], and gene ﬁnding [26].\nThe goal of this study was to investigate the feasibility of using\nmachine learning models to classify PRO scores based on data\ncollected using one type of activity tracker, the Fitbit Charge 2.\nIn this study, we tested this goal within a population of patients\nwith stable ischemic heart disease (SIHD). The rest of this article\ndescribes an approach for data preprocessing and constructing\na model that treats weeks independently, as well as an HMM\nthat takes temporal information into account. Performance of\nthe classiﬁcation algorithms is then evaluated for each PRO\nmeasure and feature importance in classiﬁcation is analyzed.\nFinally, we provide a discussion and analysis of the results and\nsuggest future directions for implementing such a classiﬁer in a\npatient surveillance application.\nII. D ATADESCRIPTION\nA set of 200 patients with SIHD were recruited for a feasibil-\nity study conducted by Cedars-Sinai Medical Center from 2017\nto 2018 to predict surrogate markers of major adverse cardiac\nevents (MACE), including myocardial infarction, arrhythmia,\nand hospitalization due to heart failure, using biometrics, wear-\nable sensors, patient-reported surveys, and other biochemical\nmarkers. This study population size is similar to several pre-\nvious studies that used activity trackers for patient monitoring\n[27], [28]. The desired monitoring period was 12 weeks for\neach subject, during which time subjects wore personal activity\ntrackers to record their physiological indices",
        "iﬁcation\naccuracy than treating weeks independently because they took\nadvantage of correlations in subjects’ survey scores from week\nto week. In our data-driven approach, the model states were de-\ntermined based on the distribution of PRO scores in the clinical\nstudy [41]. Score bins for the states were deﬁned to limit the\nsparsity during training and make the number or states consistent\nacross all of the PROMIS PROs tested. However, this may not be\nthe optimal way to deﬁne the number of states for clinical rep-\nresentation of health status. Future studies could conduct some\nanalysis to ﬁnd out the optimum number of states, which may\nfurther increase the classiﬁcation accuracy. In addition, another\nfuture direction would approach this as a regression problem to\npredict actual PRO scores with high precision over time.\nSequential deep learning models, such as recurrent neural net-\nworks (RNNs) and long-short-term-memory (LSTM) networks\nhave also demonstrated strong performance when dealing with\nsequential data [42], [43]. Therefore, these techniques may hold\npotential for applications to sensor data to classify or predict\nhealth status. However, such methods generally require a large\namount of training data, which was not available in the cur-\nrent study. In future studies, deep learning methods could be\nexplored if a sufﬁciently large data set were collected.\nWhile activity trackers are able to produce patient informa-\ntion within seconds or minutes, the sampling periods for PROs\nlike PROMIS [13] are on the order of weeks, requiring down-\nsampling of the Fitbit data for comparison. Given that the PROs\nmeasured in this study are unlikely to vary signiﬁcantly from day\nto day, this temporal resolution is appropriate for the application\nof PRO prediction. However, predicting more acute events might\nrequire more temporal resolution, which could be addressed by\nusing the activity tracker data at a ﬁner time scale. Long term\nfollow-up with patients including recordings of clinical events\nsuch as rehospitalizations could also allow us to evaluate the\neffect of mHealth monitoring on clinical outcome, an important\nstep in determining the efﬁcacy of such an intervention.\nVI. C ONCLUSION\nA temporal machine learning model can be used to classify\nself-reported physical health in patients with SIHD using phys-\niological indices measured by activity trackers. By constructing\nan HMM with feature selection and an RF classiﬁer, the result-\ning model can achieve an AUC of 0.79 for classifying Physical\nFunction. Our result indicates data generated from activity track-\ners may be used in a machine learning framework to classify\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 13,2025 at 13:07:47 UTC from IEEE Xplore.  Restrictions apply. \n\n884 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nvalidated self-reported health status variables. These techniques\ncould play a future role in larger frameworks for remotely moni-\ntoring a patient’s health state in a clinically meaningful manner.\nREFERENCES\n[ 1 ] M .K .O n g et al. , “Effectiveness of remote patient monitoring after dis-\ncharge of hospitalized patients with heart failure the better effectiveness\nafter transition-heart failure (BEA T-HF) randomized clinical trial,” JAMA\nInternal Med. , vol. 176, no. 3, pp. 310–318, 2016.\n[2] R. J. Shaw et al. , “Mobile health devices: Will patients actually use\nthem?,” J .A m .M e d .I n f o r m .A s s o c ., vol. 23, no. 3",
        " such a classiﬁer in a\npatient surveillance application.\nII. D ATADESCRIPTION\nA set of 200 patients with SIHD were recruited for a feasibil-\nity study conducted by Cedars-Sinai Medical Center from 2017\nto 2018 to predict surrogate markers of major adverse cardiac\nevents (MACE), including myocardial infarction, arrhythmia,\nand hospitalization due to heart failure, using biometrics, wear-\nable sensors, patient-reported surveys, and other biochemical\nmarkers. This study population size is similar to several pre-\nvious studies that used activity trackers for patient monitoring\n[27], [28]. The desired monitoring period was 12 weeks for\neach subject, during which time subjects wore personal activity\ntrackers to record their physiological indices, including steps,\nheart rate, calories burned, and distance traveled. At the end\nof each week, they were asked to ﬁll out eight PROMIS short\nforms as a self-report assessment of their health status [4].\nA. Activity Data\nThe Fitbit Charge 2 (Fitbit Inc., San Francisco, CA, USA)\nis a popular commercially available activity tracker that can\nrecord a person’s daily activities and health indices like heart\nrate, steps, and sleep ( Table I ). Previous work has validated\nthe accuracy of heart rate monitoring speciﬁcally in the Fitbit\nCharge 2 [29]. The Fitbit hardware and its computational algo-\nrithms for calculating step counts and physical activity have been\nT ABLE I\nSUMMARY OF 17 T YPES OF FEA TURECOLLECTED FROM FITBIT PER DAY\n∗means that feature was eliminated for model input because it was highly sparse or redun-\ndant.\nvalidated using other Fitbit devices [30], [31]. The Fitbit Charge\n2 estimates activity using metabolic equivalents (METs), which\nare calculated based on heart rate and distance traveled [32].\nHeart rate during activity is also provided, however it has been\nshown to be inaccurate during activity [33]. Data quality was\nassured by verifying that there were no extreme outliers based\non subject-speciﬁc inter-quartile range [34]. We aggregated the\ndata for each day to compensate for noise and redundancy. Af-\nter data preprocessing, tracker distance was eliminated because\nit was identical to total distance, and logged activity distance\nand sedentary active distance were also deleted because of high\nsparsity. As a result, there were 14 features per day for each\npatient in our model.\nB. Patient-Reported Outcome Measures\nPatient-Reported Outcomes Measurement Information Sys-\ntems (PROMIS) questionnaires are a library of instruments\ndeveloped and validated to measure many domains of phys-\nical and mental health [15]. This analysis uses data from\neight PROMIS instruments: Global Physical Health and Global\nMental Health, which are two composite scores from the Global-\n10 short form [35]; Fatigue-Short Form 4a; Physical Function-\nShort Form 10a; Emotional Distress-Anxiety-Short Form 6a;\nDepression-Short Form 4a; Social Isolation-Short Form 4a; and\nSleep Disturbance-Short Form 4a. Each questionnaire either\nasks about current health or has a recall period of the previous\nseven days, so they are appropriate for weekly administration.\nThe T metric method was used to standardize scores for each\ntype to a mean of 50 and a standard deviation of 10, with a\nrange between 0 and 100 [15], [36]. Symptom (i.e., Fatigue,\nAnxiety, Depression, Social Isolation, and Sleep Disturbance)\nscores of 60 or higher are one standard deviation above the av-\nerage, which is deﬁned as moderate to severe symptom severity.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2575
    },
    {
      "id": "Q2",
      "question": "Which type of digital health application is considered in this study?",
      "answer": "Digital Medicine",
      "raw_answer": "Digital Medicine",
      "choices_ids": [
        "Precision Medicine",
        "Health IT",
        "Digital Medicine",
        "Telehealth",
        "Wellness"
      ],
      "answer_label": "Digital Medicine",
      "chunks_id": [
        11,
        6,
        14
      ],
      "chunks_str": [
        " future role in larger frameworks for remotely moni-\ntoring a patient’s health state in a clinically meaningful manner.\nREFERENCES\n[ 1 ] M .K .O n g et al. , “Effectiveness of remote patient monitoring after dis-\ncharge of hospitalized patients with heart failure the better effectiveness\nafter transition-heart failure (BEA T-HF) randomized clinical trial,” JAMA\nInternal Med. , vol. 176, no. 3, pp. 310–318, 2016.\n[2] R. J. Shaw et al. , “Mobile health devices: Will patients actually use\nthem?,” J .A m .M e d .I n f o r m .A s s o c ., vol. 23, no. 3, pp. 462–466, 2016.\n[3] J. J. T. Black et al. , “A remote monitoring and telephone nurse coaching\nintervention to reduce readmissions among patients with heart failure:\nstudy protocol for the better effectiveness after transition-heart failure\n(BEA T-HF) randomized controlled trial,” Trials, vol. 15, no. 1, pp. 124–\n135, 2014.\n[4] W. Speier et al. , “Evaluating utility and compliance in a patient-based\neHealth study using continuous-time heart rate and activity trackers,” J.\nAm. Med. Inform. Assoc. , vol. 25, pp. 1386–1391, 2018.\n[5] J. Meyer and A. Hein, “Live long and prosper: Potentials of low-cost\nconsumer devices for the prevention of cardiovascular diseases,” J. Med.\nInternet Res. , vol. 15, no. 8, pp. 1–9, 2013.\n[6] M. Alharbi, N. Straiton, and R. Gallagher, “Harnessing the potential of\nwearable activity trackers for heart failure self-care,” Current Heart F ail-\nure Rep. , vol. 14, no. 1, pp. 23–29, Feb. 2017.\n[7] T. Ferguson, A. V . Rowlands, T. Olds, and C. Maher, “The validity of\nconsumer-level, activity monitors in healthy adults worn in free-living\nconditions: A cross-sectional study,” Int. J. Behav . Nutrition Phys. Activity ,\nvol. 12, no. 1, pp. 1–9, 2015.\n[8] N. C. Franklin, C. J. Lavie, and R. A. Arena, “Personal health technology:\nA new era in cardiovascular disease prevention,” P ostgrad. Med., vol. 127,\nno. 2, pp. 150–158, 2015.\n[9] C. Smith-spangler, A. L. Gienger, N. Lin, R. Lewis, C. D. Stave, and I.\nOlkin, “Clinician’s corner using pedometers to increase physical activity a\nsystematic review,” Clin. Corner , vol. 298, no. 19, pp. 2296–2304, 2014.\n[10] S. L. Shuger et al. , “Electronic feedback in a diet- and physical activity-\nbased lifestyle intervention for weight loss: A randomized controlled trial,”\nInt. J. Behav . Nutrition Phys. Activity , vol. 8, no. 1, May 2011, Art. no. 41.\n[11] S. Zan, S. Agboola, S. A. Moore, K. A. Parks, J. C. Kvedar, and K.\nJethwani, “Patient engagement with a mobile web-based telemonitoring\nsystem for heart",
        " transition matrix less sparse, we deﬁned 10 states for\nall types of health status based on the score distribution of each\nPRO. The Forward algorithm computed the probability across\nstates at time t, with the maximum probability representing the\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 13,2025 at 13:07:47 UTC from IEEE Xplore.  Restrictions apply. \n\nMENG et al.: MACHINE LEARNING APPROACH TO CLASSIFYING SELF-REPORTED HEALTH STATUS 881\nFig. 3. Illustration of independent week model (left) and Hidden Markov Model (right). For HMM, feature in each week was observed while the\nstate of health status transits from week to week.\nT ABLE II\nMEAN AND STA N DA R DDEVIA TIONROCAUC OF DIFFERENCE ALGORITHMS\nBold values are the highest for a given PRO.\n∗Signiﬁcant improvement over GBRT.\n†Signiﬁcant improvement over both GBRT and AdaBoost.\nclassiﬁed state,\nS (yt |yt−1 ,...,y 1 ,x t ,...,x 1 )= P (xt |yt )\n∗\n∑\nP( yt |yt−1 ) ∗S( yt−1 |yt−2 ,..., xt−1 ,... ) (1)\nwhere the weekly PRO score was treated as state yt , with obser-\nvation of features xt . The emission probability, P (xt |yt ), com-\nputed the probability of the observed feature vector xt given\nstate yt , computed from the random forest classiﬁer and P (yt ):\nP (xt |yt ) ∝ P (yt |xt )\nP (yt ) (2)\nAt the ﬁrst-time step, the transition probability distribution is\nundeﬁned, so the state probability was:\nS (y1 |x1 ) ∝ P (x1 |y1 ) P (y1 ) (3)\nFor analysis, states were binarized according to the criteria\ndeﬁned above. Because dichotomizing PRO score values loses\nsome information and precision, a regression analysis was con-\nducted between the median value of HMM stages and actual\nscores for the HMM. This method of predicting PRO scores\nwas compared against multinomial logistic regression to evalu-\nate the accuracy of predicting PRO scores over time.\nIV . R ESULTS\nTable II shows the mean AUC for binary classiﬁcation of\nPRO scores for the seven PROMIS measures using GBRT, Ad-\naBoost and RF. The highest mean AUC was 0.75 using RF for\nclassifying Physical Function, while the lowest was 0.47 using\nAdaBoost for Depression. The results indicated that RF signif-\nicantly outperformed other models in classiﬁcation of Anxiety\nand Depression (p < 0.05), and it was also signiﬁcantly better\nthan GBRT for Global Physical Health and Mental Health (p =\n0.01 and p = 0.01, respectively). The RF model was selected\nfor the remaining analyses because its performance was equiv-\nalent to or better than the other methods for classifying all PRO\nscores. Additionally, it was notable that the AUC related to self-\nreported physical health PROs such as Global Physical Health,\nFatigue, and Physical Function were higher than those related\nto mental health such as Global Mental Health, Anxiety, and\nDepression.\nWe then looked at the importance factor of each feature con-\ntributing to the classiﬁcation in the RF model. Table III displays\nthe importance factor for the 14 feature types summed over\nseven days. Features that were signiﬁcantly higher (p < 0.05)\nthan the average value for each classiﬁcation were determined.\nSteps,",
        "L. Morey, “Physical activity intervention for women,” Am. J. Preventive\nMed., vol. 49, no. 3, pp. 414–418, 2015.\n[28] J. B. Wang et al. , “Wearable sensor/device (ﬁtbit one) and SMS text-\nmessaging prompts to increase physical activity in overweight and obese\nadults: A randomized controlled trial,” T elemedicine e-Health, vol. 21, no.\n10, pp. 18–23, 2014.\n[29] S. Benedetto, C. Caldato, E. Bazzan, D. C. Greenwood, V . Pensabene,\nand P . Actis, “Assessment of the ﬁtbit charge 2 for monitoring heart rate,”\nPLoS One , vol. 13, no. 2, 2018, Art. no. e0192691.\n[30] M. A. Tully, C. McBride, L. Heron, and R. F. Hunter, “The validation of\nFibit ZipTM physical activity monitor as a measure of free-living physical\nactivity,” BMC Res Notes , vol. 7, 2014, Art. no. 952.\n[31] K. M. Diaz et al. , “Fitbit: An accurate and reliable device for wireless\nphysical activity tracking,” Int. J. Cardiol. , vol. 185, pp. 138–140, 2015.\n[32] R. K. Reddy et al. , “Accuracy of wrist-worn activity monitors during com-\nmon daily physical activities and types of structured exercise: Evaluation\nstudy,” JMIR Mhealth Uhealth , vol. 6, 2018, Art. no. e10338.\n[33] E. Jo, K. Lewis, D. Directo, M. J. Kim, and B. A. Dolezal, “V alidation of\nbiofeedback wearables for photoplethysmographic heart rate tracking,” J.\nSports Sci. Med. , vol. 15, pp. 540–547, 2016.\n[34] A. Ghasemi and S. Zahediasl, “Normality tests for statistical analysis:\nA guide for non-statisticians,” Int. J. Endocrinol. Metab. , vol. 10, no. 2,\npp. 486–489, 2012.\n[35] R. D. Hays, J. B. Bjorner, D. A. Revicki, K. L. Spritzer, and D. Cella,\n“Development of physical and mental health summary scores from the\npatient-reported outcomes measurement information system (PROMIS)\nglobal items,” Qual. Life Res. , vol. 18, no. 7, pp. 873–880, 2009.\n[36] B. M. R. Spiegel et al. , “Development of the NIH patient-reported\noutcomes measurement information system (PROMIS) gastrointestinal\nsymptom scales,” Am. J. Gastroenterol. , vol. 109, no. 11, pp. 1804–1814,\n2014.\n[37] J. O. Ogutu, H. P . Piepho, and T. Schulz-Streeck, “A comparison of random\nforests, boosting and support vector machines for genomic selection,”\nBMC Proc. , vol. 5, no. Suppl. 3, pp. 3–7, 2011.\n[38] R. J. Petrella, J. J. Koval, and D. A. Cunningham, “A self-paced step test\nto predict aerobic ﬁtness in older adults in the primary"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2580
    },
    {
      "id": "Q3",
      "question": "To which ICD-10 code group does the digital health application in this study pertain?",
      "answer": "Unknown from this paper",
      "raw_answer": "Unknown from this paper.",
      "choices_ids": [
        "A00-B99",
        "C00-D48",
        "D50-D89",
        "E00-E90",
        "F00-F99",
        "G00-G99",
        "H00-H59",
        "I00-I99",
        "J00-J99",
        "K00-K93",
        "L00-L99",
        "M00-M99",
        "N00-N99",
        "O00-O99",
        "P00-P96",
        "Q00-Q99",
        "R00-R99",
        "S00-S99",
        "T00-T98",
        "U00-U99",
        "V01-Y98",
        "Z00-Z99"
      ],
      "answer_label": null,
      "chunks_id": [
        14,
        4,
        11
      ],
      "chunks_str": [
        "L. Morey, “Physical activity intervention for women,” Am. J. Preventive\nMed., vol. 49, no. 3, pp. 414–418, 2015.\n[28] J. B. Wang et al. , “Wearable sensor/device (ﬁtbit one) and SMS text-\nmessaging prompts to increase physical activity in overweight and obese\nadults: A randomized controlled trial,” T elemedicine e-Health, vol. 21, no.\n10, pp. 18–23, 2014.\n[29] S. Benedetto, C. Caldato, E. Bazzan, D. C. Greenwood, V . Pensabene,\nand P . Actis, “Assessment of the ﬁtbit charge 2 for monitoring heart rate,”\nPLoS One , vol. 13, no. 2, 2018, Art. no. e0192691.\n[30] M. A. Tully, C. McBride, L. Heron, and R. F. Hunter, “The validation of\nFibit ZipTM physical activity monitor as a measure of free-living physical\nactivity,” BMC Res Notes , vol. 7, 2014, Art. no. 952.\n[31] K. M. Diaz et al. , “Fitbit: An accurate and reliable device for wireless\nphysical activity tracking,” Int. J. Cardiol. , vol. 185, pp. 138–140, 2015.\n[32] R. K. Reddy et al. , “Accuracy of wrist-worn activity monitors during com-\nmon daily physical activities and types of structured exercise: Evaluation\nstudy,” JMIR Mhealth Uhealth , vol. 6, 2018, Art. no. e10338.\n[33] E. Jo, K. Lewis, D. Directo, M. J. Kim, and B. A. Dolezal, “V alidation of\nbiofeedback wearables for photoplethysmographic heart rate tracking,” J.\nSports Sci. Med. , vol. 15, pp. 540–547, 2016.\n[34] A. Ghasemi and S. Zahediasl, “Normality tests for statistical analysis:\nA guide for non-statisticians,” Int. J. Endocrinol. Metab. , vol. 10, no. 2,\npp. 486–489, 2012.\n[35] R. D. Hays, J. B. Bjorner, D. A. Revicki, K. L. Spritzer, and D. Cella,\n“Development of physical and mental health summary scores from the\npatient-reported outcomes measurement information system (PROMIS)\nglobal items,” Qual. Life Res. , vol. 18, no. 7, pp. 873–880, 2009.\n[36] B. M. R. Spiegel et al. , “Development of the NIH patient-reported\noutcomes measurement information system (PROMIS) gastrointestinal\nsymptom scales,” Am. J. Gastroenterol. , vol. 109, no. 11, pp. 1804–1814,\n2014.\n[37] J. O. Ogutu, H. P . Piepho, and T. Schulz-Streeck, “A comparison of random\nforests, boosting and support vector machines for genomic selection,”\nBMC Proc. , vol. 5, no. Suppl. 3, pp. 3–7, 2011.\n[38] R. J. Petrella, J. J. Koval, and D. A. Cunningham, “A self-paced step test\nto predict aerobic ﬁtness in older adults in the primary",
        "a; Social Isolation-Short Form 4a; and\nSleep Disturbance-Short Form 4a. Each questionnaire either\nasks about current health or has a recall period of the previous\nseven days, so they are appropriate for weekly administration.\nThe T metric method was used to standardize scores for each\ntype to a mean of 50 and a standard deviation of 10, with a\nrange between 0 and 100 [15], [36]. Symptom (i.e., Fatigue,\nAnxiety, Depression, Social Isolation, and Sleep Disturbance)\nscores of 60 or higher are one standard deviation above the av-\nerage, which is deﬁned as moderate to severe symptom severity.\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 13,2025 at 13:07:47 UTC from IEEE Xplore.  Restrictions apply. \n\n880 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nFig. 1. Distribution of normal and abnormal (moderate to severe) class\nfor each PRO measure.\nFor function (i.e., Global Physical Health, Global Mental\nHealth, and Physical Function), scores less than 40 are classi-\nﬁed as moderate to severe, meaning less functional ability than\nnormal. For this study, PRO scores were predicted in two ways:\nregression was used to predict PRO scores from patient activity\ntracker data, and classiﬁcation was used to determine whether\nsubjects’ PRO scores were above the threshold for at least mod-\nerate severity. The distributions of PRO scores are shown in\nFig. 1 . Because of a lack of moderate or severe cases for social\nisolation (<2%), this variable was eliminated for analysis in our\nmodel.\nIII. M ETHODS\nMissing data is a common concern when dealing with activity\ntracker data and can result from subjects either forgetting to wear\ntheir devices or removing them for charging. Patients were asked\nto ﬁll out eight PROMIS questionnaires at the end of each week\nfor a 12-week monitoring period. In total, 19.1 percent of weeks\nhad missing PRO data and 16.6 percent of weeks had missing\nvalues from the activity tracker in four or more days. If data was\navailable for at least four days in a week, missing values were\npermuted by using the average value of the rest of the week for\nsteps or resting heart rate. Weeks with missing survey scores, as\nwell as those without step and resting heart rate data for more\nthan three days, were removed from the analysis.\nA correlation analysis between subjects’ missing Fitbit data\nand their average Global Physical Health and Global Mental\nHealth scores shows a slight negative relationship ( −0.11 and\n−0.09, respectively) that was not statistically signiﬁcant (p =\n0.13 and p = 0.23, respectively). The correlation coefﬁcient be-\ntween number of missing PROs and the average global health\nscores are −0.17 (p = 0.018) to −0.14 (p = 0.048), respec-\ntively, indicating that the missing PROs are signiﬁcantly related\nto patient health. Another correlation analysis was performed\nbetween subject’s age and number of missing values with\nr2 <0.001, which demonstrates no trend of more missing values\nfor elder subjects. Finally, subjects with only one week of data\nwere eliminated in order to ensure the continuity of transition\nof states from week to week when building the HMM model.\nAfter adopting this data preprocessing approach and using the\nclassiﬁcation criteria above, a total number of 182 subjects with\na total of 1,640 weeks were collected, where the number of\nFig",
        " future role in larger frameworks for remotely moni-\ntoring a patient’s health state in a clinically meaningful manner.\nREFERENCES\n[ 1 ] M .K .O n g et al. , “Effectiveness of remote patient monitoring after dis-\ncharge of hospitalized patients with heart failure the better effectiveness\nafter transition-heart failure (BEA T-HF) randomized clinical trial,” JAMA\nInternal Med. , vol. 176, no. 3, pp. 310–318, 2016.\n[2] R. J. Shaw et al. , “Mobile health devices: Will patients actually use\nthem?,” J .A m .M e d .I n f o r m .A s s o c ., vol. 23, no. 3, pp. 462–466, 2016.\n[3] J. J. T. Black et al. , “A remote monitoring and telephone nurse coaching\nintervention to reduce readmissions among patients with heart failure:\nstudy protocol for the better effectiveness after transition-heart failure\n(BEA T-HF) randomized controlled trial,” Trials, vol. 15, no. 1, pp. 124–\n135, 2014.\n[4] W. Speier et al. , “Evaluating utility and compliance in a patient-based\neHealth study using continuous-time heart rate and activity trackers,” J.\nAm. Med. Inform. Assoc. , vol. 25, pp. 1386–1391, 2018.\n[5] J. Meyer and A. Hein, “Live long and prosper: Potentials of low-cost\nconsumer devices for the prevention of cardiovascular diseases,” J. Med.\nInternet Res. , vol. 15, no. 8, pp. 1–9, 2013.\n[6] M. Alharbi, N. Straiton, and R. Gallagher, “Harnessing the potential of\nwearable activity trackers for heart failure self-care,” Current Heart F ail-\nure Rep. , vol. 14, no. 1, pp. 23–29, Feb. 2017.\n[7] T. Ferguson, A. V . Rowlands, T. Olds, and C. Maher, “The validity of\nconsumer-level, activity monitors in healthy adults worn in free-living\nconditions: A cross-sectional study,” Int. J. Behav . Nutrition Phys. Activity ,\nvol. 12, no. 1, pp. 1–9, 2015.\n[8] N. C. Franklin, C. J. Lavie, and R. A. Arena, “Personal health technology:\nA new era in cardiovascular disease prevention,” P ostgrad. Med., vol. 127,\nno. 2, pp. 150–158, 2015.\n[9] C. Smith-spangler, A. L. Gienger, N. Lin, R. Lewis, C. D. Stave, and I.\nOlkin, “Clinician’s corner using pedometers to increase physical activity a\nsystematic review,” Clin. Corner , vol. 298, no. 19, pp. 2296–2304, 2014.\n[10] S. L. Shuger et al. , “Electronic feedback in a diet- and physical activity-\nbased lifestyle intervention for weight loss: A randomized controlled trial,”\nInt. J. Behav . Nutrition Phys. Activity , vol. 8, no. 1, May 2011, Art. no. 41.\n[11] S. Zan, S. Agboola, S. A. Moore, K. A. Parks, J. C. Kvedar, and K.\nJethwani, “Patient engagement with a mobile web-based telemonitoring\nsystem for heart"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2700
    },
    {
      "id": "Q4",
      "question": "Does the predictive model perform regression or classification?",
      "answer": "Classification",
      "raw_answer": "Classification",
      "choices_ids": [
        "Regression",
        "Classification"
      ],
      "answer_label": "Classification",
      "chunks_id": [
        7,
        9,
        10
      ],
      "chunks_str": [
        "). The RF model was selected\nfor the remaining analyses because its performance was equiv-\nalent to or better than the other methods for classifying all PRO\nscores. Additionally, it was notable that the AUC related to self-\nreported physical health PROs such as Global Physical Health,\nFatigue, and Physical Function were higher than those related\nto mental health such as Global Mental Health, Anxiety, and\nDepression.\nWe then looked at the importance factor of each feature con-\ntributing to the classiﬁcation in the RF model. Table III displays\nthe importance factor for the 14 feature types summed over\nseven days. Features that were signiﬁcantly higher (p < 0.05)\nthan the average value for each classiﬁcation were determined.\nSteps, total distance, calories, and calories BMR contributed to\nmost of the PRO scores. The importance factor of light active\ndistance was signiﬁcantly better than other features for classify-\ning Global Physical Health and Physical Function, which were\nboth related to a subject’s physical health. On the other hand,\nresting heart rate contributed signiﬁcantly more than other fea-\ntures for classiﬁcation of mental health PROs such as Anxiety\nand Depression, while its importance factor was not signiﬁcantly\nhigher than other features in classiﬁcation of PROs related to\nphysical health.\nThe analysis was repeated using the RF classiﬁer and only the\nsigniﬁcant features from Table III and are shown in Table IV .\nBecause some studies such as [38] only used steps data to assess\nuser’s health status, we also compared the model performance\nin the same manner. The result suggested that the RF model\ncan generate signiﬁcantly better classiﬁcation accuracy with the\nselected features than all features from Fitbit for all PROMIS\nshort form survey scores except for Global Mental Health (p =\n0.37), with the highest AUC of 0.76 for classiﬁcation of Physical\nFunction.\nFig. 4 illustrates the results of sensitivity analysis on missing\nfeature data on RF classiﬁcation by randomly censoring data\nfrom one day to six days per a week. The results show that\nROCAUC decreased monotonically as days were removed. For\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 13,2025 at 13:07:47 UTC from IEEE Xplore.  Restrictions apply. \n\n882 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nT ABLE III\nIMPORT ANCEFACTOR OF EACH FEA TURE FOR CLASSIFYING VARIOUS HEALTH STAT U S\nV alue in parentheses is the standard deviation. Bold values are signiﬁcantly higher (p < 0.05) than the average value for a feature (1/14 = 0.0714).\nT ABLE IV\nMEAN AND STA N DA R DDEVIA TIONROCAUC OF DIFFERENT\nFEA TURESELECTION STRA TEGY\nBold values are the highest for a given PRO.\n∗Signiﬁcant improvement from Selected Feature over All Feature.\n†Signiﬁcant improvement from All Feature over Steps Only.\nGlobal Physical Health, the value at missing four days drops\nsigniﬁcantly compared to no missing data (p = 0.03), while\nthe difference at missing three days was not signiﬁcant (p =\n0.11). This was why that cutoff was chosen for inclusion in our\nanalysis.\nTable V displayed the comparison of means and standard\ndeviations of the AUC for each PRO measure using the inde-\npendent model and HMM. AUCs derived using the HMM were\nsigniﬁcantly",
        " used in this study, which lacks pre-\ncision as mental health is a broad and complicated ﬁeld. More\nthorough evaluations of subjects’ mental states could provide\nmore descriptive labels for training machine learning models,\nwhich could further improve performance in predicting mental\nhealth status.\nOur highest AUC was 0.79 from classiﬁcation of Physical\nFunction, which demonstrated the correlation between data col-\nlected from Fitbit and PROs. However, the AUC values also\nindicated that PROs cannot be completely determined by activ-\nity tracker data alone, suggesting that PROs, particularly those\npertaining to mental health such as depression, contain addi-\ntional information that was not captured in the tracking devices.\nWhile the current study demonstrates the use of activity track-\ners to capture information about patient’s health status, in some\ncases PROs could be a preferable method. Internet access en-\nables PRO data collection to be done outside of clinic through\nweb or mobile apps, which provides convenience and reduces\ntime commitment for patients.\nAccording to Table III , steps and total distance have signiﬁ-\ncantly higher importance for classifying the majority of survey\nscores, while calories BMR signiﬁcantly contributes to mental\nhealth scores, like Anxiety and Depression. Their importance\nfactor may due to data quality, as previous studies [5]–[7] have\nvalidated the data accuracy for step counts, distance travelled,\nand energy expenditure for activity trackers, while other fea-\ntures have not been validated in scientiﬁc work. As Fitbits are\nnot sold as medical devices, many of their features are not val-\nidated or regulated like other medical devices. In our study, we\nfound inconsistency in sleep data and sleeping stages for sub-\njects. It was likely that Fitbit was taken off for charging during\nnights. Therefore, future studies should notice user not always\ncharge it during nights to collect sleep data. Moreover, the data\nelements that have been validated are generally only tested in\nspeciﬁc devices, rather than across all activity trackers, so it is\nnot clear how these validation results translate to other devices.\nFuture studies should be conducted to validate these features.\nAs indicated by the correlation between subject’s average\nPRO scores and the number of missing PRO values, patients\nwith moderate to severe health status were less likely to com-\nplete PRO questionnaires routinely, which may have introduced\nbias for data collection in this study. Future studies could try\nto provide incentives for continued participation, which may\nmitigate study attrition. Eight PROMIS instruments were used\nin this study, and some redundancy existed between the speciﬁc\nshort forms such as Fatigue or Anxiety to the general Global-10\nshort form. Our current approach treated each score indepen-\ndently without considering this overlap. A possible future study\ncould predict PRO scores simultaneously in a joint model such\nas Bayesian network, which considers the correlations between\nPRO scores.\nIn our dataset of patients with SIHD based on adjudicated\nclinical data, HMMs achieved signiﬁcantly higher classiﬁcation\naccuracy than treating weeks independently because they took\nadvantage of correlations in subjects’ survey scores from week\nto week. In our data-driven approach, the model states were de-\ntermined based on the distribution of PRO scores in the clinical\nstudy [41]. Score bins for the states were deﬁned to limit the\nsparsity during training and make the number or states consistent\nacross all of the PROMIS PROs tested. However, this may not be\nthe optimal way to deﬁne the number of states for clinical rep-\nresentation of health status. Future studies could conduct some\nanalysis to ﬁnd out the optimum number of states, which may\nfurther increase the classiﬁcation accuracy. In addition, another\nfuture direction would approach",
        "iﬁcation\naccuracy than treating weeks independently because they took\nadvantage of correlations in subjects’ survey scores from week\nto week. In our data-driven approach, the model states were de-\ntermined based on the distribution of PRO scores in the clinical\nstudy [41]. Score bins for the states were deﬁned to limit the\nsparsity during training and make the number or states consistent\nacross all of the PROMIS PROs tested. However, this may not be\nthe optimal way to deﬁne the number of states for clinical rep-\nresentation of health status. Future studies could conduct some\nanalysis to ﬁnd out the optimum number of states, which may\nfurther increase the classiﬁcation accuracy. In addition, another\nfuture direction would approach this as a regression problem to\npredict actual PRO scores with high precision over time.\nSequential deep learning models, such as recurrent neural net-\nworks (RNNs) and long-short-term-memory (LSTM) networks\nhave also demonstrated strong performance when dealing with\nsequential data [42], [43]. Therefore, these techniques may hold\npotential for applications to sensor data to classify or predict\nhealth status. However, such methods generally require a large\namount of training data, which was not available in the cur-\nrent study. In future studies, deep learning methods could be\nexplored if a sufﬁciently large data set were collected.\nWhile activity trackers are able to produce patient informa-\ntion within seconds or minutes, the sampling periods for PROs\nlike PROMIS [13] are on the order of weeks, requiring down-\nsampling of the Fitbit data for comparison. Given that the PROs\nmeasured in this study are unlikely to vary signiﬁcantly from day\nto day, this temporal resolution is appropriate for the application\nof PRO prediction. However, predicting more acute events might\nrequire more temporal resolution, which could be addressed by\nusing the activity tracker data at a ﬁner time scale. Long term\nfollow-up with patients including recordings of clinical events\nsuch as rehospitalizations could also allow us to evaluate the\neffect of mHealth monitoring on clinical outcome, an important\nstep in determining the efﬁcacy of such an intervention.\nVI. C ONCLUSION\nA temporal machine learning model can be used to classify\nself-reported physical health in patients with SIHD using phys-\niological indices measured by activity trackers. By constructing\nan HMM with feature selection and an RF classiﬁer, the result-\ning model can achieve an AUC of 0.79 for classifying Physical\nFunction. Our result indicates data generated from activity track-\ners may be used in a machine learning framework to classify\nAuthorized licensed use limited to: Universiteit Leiden. Downloaded on May 13,2025 at 13:07:47 UTC from IEEE Xplore.  Restrictions apply. \n\n884 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 3, MARCH 2020\nvalidated self-reported health status variables. These techniques\ncould play a future role in larger frameworks for remotely moni-\ntoring a patient’s health state in a clinically meaningful manner.\nREFERENCES\n[ 1 ] M .K .O n g et al. , “Effectiveness of remote patient monitoring after dis-\ncharge of hospitalized patients with heart failure the better effectiveness\nafter transition-heart failure (BEA T-HF) randomized clinical trial,” JAMA\nInternal Med. , vol. 176, no. 3, pp. 310–318, 2016.\n[2] R. J. Shaw et al. , “Mobile health devices: Will patients actually use\nthem?,” J .A m .M e d .I n f o r m .A s s o c ., vol. 23, no. 3"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2527
    }
  ]
}