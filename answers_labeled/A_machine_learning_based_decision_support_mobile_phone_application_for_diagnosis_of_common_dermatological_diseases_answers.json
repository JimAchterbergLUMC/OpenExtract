{
  "paper": "A machine learning-based, decision support, mobile phone application for diagnosis of common dermatological diseases.pdf",
  "answers": [
    {
      "id": "Q1",
      "question": "Which data type is used in this study?",
      "answer": "images",
      "raw_answer": "images",
      "choices_ids": [
        "tabular",
        "time-series",
        "images",
        "text",
        "video",
        "audio"
      ],
      "answer_label": "images",
      "chunks_id": [
        11,
        16,
        14
      ],
      "chunks_str": [
        " diversity in the patient populations that\nconsult physicians in urban versus rural areas. The study was\napproved by the Ethics Committee of All India Institute of Med-\nical Sciences. We included consecutive patients presenting to a\nparticular investigator in the Outpatient Department, where the\ndermatologists were conﬁdent of the diagnosis, either by clinical\nexamination, laboratory investigation, and/or histopathological\nexamination. Dermatologists were blinded to the app results. A\nsingle representative image from each patient was tested on the\napp by a separate physician.\nResults\nThe overall scheme for this study is outlined in Figure 1.\nTable 2 shows th number of patients, AUC, Top‐1/Top‐3 sensitivity, speciﬁcity, positive predictive and negative predictive values for\ncombined clinical data from three different clinical settings.\nS.no. Disease class Number\nof patients\nAUC-\nclinic\nTop-1 sensitivity\n% (CI)\nTop-3\nsensitivity %\nTop-1\nspeciﬁcity %\nTop-1 PPV Top-1 NPV\n1 Acne 592 0.98 89.86 (87.15 –92.18) 97.97 98.19 86.92 98.64\n2 Alopecia 184 0.97 88.11 (82.55 –92.36) 96.22 99.28 82.32 99.54\n3 Anogenital warts 34 0.85 57.14 (39.35 –73.68) 71.43 99.70 57.14 99.70\n4 Basal cell carcinoma 123 0.98 93.55 (87.68 –97.17) 97.58 98.51 61.38 99.83\n5 Bowen ’s disease 11 0.77 45.45 (16.75 –76.62) 54.54 99.90 50.00 99.88\n6 Bullous pemphigoid 16 0.73 35.29 (14.21 –61.67) 47.06 100.00 100.00 99.78\n7 Candidiasis 16 0.81 41.18 (18.44 –67.10) 64.71 99.80 41.18 99.80\n8 Discoid lupus\nerythematosus\n47 0.90 60.42 (45.27 –74.23) 83.33 99.20 42.03 99.61\n9 Eczema 432 0.87 54.29 (49.46 –59.10) 81.90 97.58 67.83 95.78\n10 Fixed drug eruption 12 0.87 41.67 (15.16 –72.33) 75.00 99.70 25.00 99.86\n11 Herpes zoster 38 0.89 66.67 (49.78 –80.91) 79.49 99.60 56.52 99.74\n12 Hidradenitis suppurativa 32 0.97 93.94(79.78 –99.26) 93.94 99.62 62.00 99.96\n13 Ichthyosis 21 0.93 81.81 (59.72 –94.81) 86.36 99.78 62.07 99.92\n14 Impetigo and Pyodermas 109 0.89 57.27 (47.48 –66.66) 82.72 99.04 57.27 99.04\n15",
        "/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nFigure 4 (a) Confusion matrix from the top-1 prediction of clinical data by the app. The numbers in each row are normalized to 100. The\nactual patient numbers for each disease class are shown in parenthesis. The actual labels are depicted on the y-axis and predicted labels\nare on the x-axis. (b) Confusion matrix from the top-3 prediction of clinical data by the app. The numbers in each row are normalized to\n100. The actual patient numbers for each disease class are shown in parenthesis.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 543\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nto diagnose 26 common skin conditions from clinical images\nplus associated medical histories.25 During validation, Liuet al\nachieved a 71% top-1 accuracy and their algorithm surpassed\ndermatologists, PCPs and nurse practitioners in a clinical data-\nset.\n25 Our Top-1 accuracy was 77% and the mean AUC was 0.95\nfor algorithmic validation of 40 diseases.\nThere are no precedents for studies in which an AI-based, skin\ndisease diagnosis app has been tested in clinical settings. In our\nwork, a top-1 accuracy of 75% and a top-3 accuracy of 90% was\nachieved by the app for 35 skin diseases and was largely similar to\nour model validation results. Some differences in diagnostic per-\nformance (in terms of disease AUCs) between model and app\nwere noted and may be attributable to either fewer clinical valida-\ntion images for some diseases like Bowen’s disease, anogenital\nwarts, tinea pedis, rosacea, candidiasis, herpes zoster (Fig. 4a and\nSupplementary Figure S1) and/or differences in disease morphol-\nogy between white and pigmented skin. Eczema is a broad disease\ncategory, incorporating diseases with varied morphology such as\nlichen simplex chronicus, atopic dermatitis, nummular eczema\nand contact dermatitis. Training of the model with speciﬁc dis-\nease classes rather than a broad category of eczema may improve\nsensitivity. As shown in the confusion matrix, eczema was often\nconfused with psoriasis, lichen planus and tinea corporis, cruris\nor faciei (Figs 4a, b). To some extent, this mirrors the diagnostic\nconfusion faced by many physicians as well.\n2,25,26 A few melano-\ncytic nevi lesions were mistaken for BCC possibly because of their\nresemblance with pigmented BCC, which is more commonly seen\nin skin of colour. Besides, it was observed that diseases with dis-\ntinct morphology and predilection for certain sites (in a similar\nrecognizable background) such as melasma and tinea unguium\nhad better accuracies.\nIn this study, we found a high top-3 sensitivity for BCC\n(97.58%, n = 124) and SCC (92.86%,n = 14",
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2554
    },
    {
      "id": "Q2",
      "question": "Which type of digital health application is considered in this study?",
      "answer": "Unknown from this paper",
      "raw_answer": "Unknown from this paper",
      "choices_ids": [
        "Precision Medicine",
        "Health IT",
        "Digital Medicine",
        "Telehealth",
        "Wellness"
      ],
      "answer_label": null,
      "chunks_id": [
        11,
        2,
        9
      ],
      "chunks_str": [
        " diversity in the patient populations that\nconsult physicians in urban versus rural areas. The study was\napproved by the Ethics Committee of All India Institute of Med-\nical Sciences. We included consecutive patients presenting to a\nparticular investigator in the Outpatient Department, where the\ndermatologists were conﬁdent of the diagnosis, either by clinical\nexamination, laboratory investigation, and/or histopathological\nexamination. Dermatologists were blinded to the app results. A\nsingle representative image from each patient was tested on the\napp by a separate physician.\nResults\nThe overall scheme for this study is outlined in Figure 1.\nTable 2 shows th number of patients, AUC, Top‐1/Top‐3 sensitivity, speciﬁcity, positive predictive and negative predictive values for\ncombined clinical data from three different clinical settings.\nS.no. Disease class Number\nof patients\nAUC-\nclinic\nTop-1 sensitivity\n% (CI)\nTop-3\nsensitivity %\nTop-1\nspeciﬁcity %\nTop-1 PPV Top-1 NPV\n1 Acne 592 0.98 89.86 (87.15 –92.18) 97.97 98.19 86.92 98.64\n2 Alopecia 184 0.97 88.11 (82.55 –92.36) 96.22 99.28 82.32 99.54\n3 Anogenital warts 34 0.85 57.14 (39.35 –73.68) 71.43 99.70 57.14 99.70\n4 Basal cell carcinoma 123 0.98 93.55 (87.68 –97.17) 97.58 98.51 61.38 99.83\n5 Bowen ’s disease 11 0.77 45.45 (16.75 –76.62) 54.54 99.90 50.00 99.88\n6 Bullous pemphigoid 16 0.73 35.29 (14.21 –61.67) 47.06 100.00 100.00 99.78\n7 Candidiasis 16 0.81 41.18 (18.44 –67.10) 64.71 99.80 41.18 99.80\n8 Discoid lupus\nerythematosus\n47 0.90 60.42 (45.27 –74.23) 83.33 99.20 42.03 99.61\n9 Eczema 432 0.87 54.29 (49.46 –59.10) 81.90 97.58 67.83 95.78\n10 Fixed drug eruption 12 0.87 41.67 (15.16 –72.33) 75.00 99.70 25.00 99.86\n11 Herpes zoster 38 0.89 66.67 (49.78 –80.91) 79.49 99.60 56.52 99.74\n12 Hidradenitis suppurativa 32 0.97 93.94(79.78 –99.26) 93.94 99.62 62.00 99.96\n13 Ichthyosis 21 0.93 81.81 (59.72 –94.81) 86.36 99.78 62.07 99.92\n14 Impetigo and Pyodermas 109 0.89 57.27 (47.48 –66.66) 82.72 99.04 57.27 99.04\n15",
        " validation studies of AI-\nbased algorithms related to dermatology in clinical settings.\nMaterial and methods\nThe study aimed to develop a convolutional neural network\n(CNN)-based algorithm trained with clinical images of 40 differ-\nent skin diseases. A user-friendly, smartphone app was also gen-\nerated, and a clinical validation study on 5014 patients was done\nby physicians in urban, rural primary care and tertiary care set-\ntings. The app’s analysis of a single image of the lesion was com-\npared to the consensus diagnosis made by two board-certiﬁed\ndermatologists. Only patients, for whom the treating board-cer-\ntiﬁed dermatologist was conﬁdent of the diagnosis and the diag-\nnosis was cross-veriﬁed by another board-certiﬁed\ndermatologist, were included. If there was no consensus then the\npatient was excluded from the study.\nGeneration of the CNN-based algorithm\nThe CNN architecture used was a modiﬁed version of Densenet-\n161 with optimized augmentation and inference pipelines.\n16\nThese optimizations were derived through rigorous experiments\nand were attuned to clinical skin images. All training and testing\nimages were annotated and segmented so a bounding box sur-\nrounded lesion of interest and irrelevant features such as rulers\nand surgical markings were discarded. The 17 718 raw images\nwere sourced from public databases (http://www.hellenicderma\ntlas.com/en and http://www.danderm.dk/atlas), after obtaining\npermission from them, as well as images from dermatologists in\nIndia. Of these, 310 images were discarded during the\npreprocessing stage due to poor resolution or multiple lesions.\nOut of the remaining 17 408 images, 1990 images belonged to\nthe non-speciﬁc category and 15 418 images were within the 40\nselected disease categories (Table 1). These images were split\ninto ﬁve equal parts (folds) and ﬁve iterations of training and\nvalidation were performed in a manner so that within each itera-\ntion, a different fold of the data was held-out for validation while\nthe remaining fourfolds were used for learning. The training\nimages were 12 350 and testing images were 3068. Since the\ndataset was imbalanced, a custom modiﬁed version of the\nweighted focal loss function was used to train the network. The\nweights for each class were calculated using the inverse sample\nsize method. Our test images were either in-distribution images\ni.e. images within 40 training classes or out-of-distribution sets\nthat we named as non-speciﬁc set.\nWe initially used Inception-v4, which was one of the most\npopular CNN models at the time. For 10 diseases, a sensitivity of\naround 85% was achieved, but for the 20-disease class model,\nthis fell to around 65%. We experimented with many parameters\nlike learning rate and choice of optimizer etc. with no signiﬁcant\nimprovements. It was felt that as the architectures became dee-\nper, there could be problems related to over-ﬁtting. According\nto Huanget al.,convolutional networks can be substantially dee-\nper, more accurate and efﬁcient to train if they contain shorter\nconnections between layers close to the input and those close to\nthe output.\n17 Their implementation of this architecture is called\nDenseNet. In this architecture, to ensure maximum information\nﬂow between layers, each layer obtains additional inputs from all\npreceding layers and passes on its own feature-maps to all subse-\nquent layers.\n17 We found that the DenseNet architecture pro-\nvided better results than the other contemporary architectures\nsuch as Inception-Resnet-V2, Resnets-50, Resnet-101 and Res-\nnet-152. We tried several DenseNet variants",
        " to calculate the true positive rate (same as\nsensitivity) and the false-positive rate (1 – speciﬁcity). ROC\ncurve was the plot of the true positive rate versus the false-\npositive rate.\nClinical validation study\nWe tested our mobile app against dermatologists’ diagnosis in\nthree different clinical settings, namely, at a tertiary care centre\nData \ncollection\nAlgorithm \nfinetuning & \nvalidation\nApp \ndevelopment\nClinical \nvalidation of \nApp\nPublic database of annotated images for \n40 skin diseases + normal skin + nonspecific\nN = 9,203\nPrivate data classified by board certified \ndermatologists\nN = 8,205\nCNN training images N =12,350\nCNN testing images N =3,068\n(1990 nonspecific images not included)\nComparison of model diagnosis against \npredetermined classification\n15,418 images used for training of model to \ngenerate smartphone app\nApp tested by physicians and compared with \ndermatologists’ diagnosis. N = 5,014 \nDetermination of app’s overall sensitivity and \ndisease-specific sensitivity, specificity, PPV, \nNPV and AUC values\nApp testing on rural primary-care patients\nN = 932\nApp testing on urban, private clinic patients\nN = 383\nApp testing on urban tertiary hospital patients\nN = 3,699\nFigure 1 This ﬂowchart depicts the different steps in data collection, algorithm generation, algorithm testing, app generation and app\nvalidation in clinical studies.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 539\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosaceaMelasma\nAcne\nVitiligo/Leucoderma\nTinea pedis\nAnogenital wartsKeratoacanthoma\nMolluscum contagiosumHidradenitis suppurativa\nHerpes zosterTinea capitis\nImpetigo and Pyodermas\nAlopecia\nMilia\nBasal cell carcinoma\nMelanoma\nMelanocytic nevi/Mole\nIchthyosis\nPityriasis r\nosea\nActin\nic keratosis\nTinea cruris  corporis or faciei\nKeloid/Hype\nrtrophic scar\nSeborrheic\n keratosis\nFixed d\nrug eruption\nLichen sclerosus et atrophicus\nCh\nicken pox\nTinea ma\nnuum\nLichen planus\nUrticaria\nPityriasis ve\nrsicolorPsoriasis\nPe\nmphigus\nCandid\niasis\nBowens disease\nViral warts\nSquamous cell c\narcino\nma\nBullous pe\nmphigoidEcze\nma\nDis\ncoid lupus erythematosus\nPercentage\nSensitivity\nSpecificity\nPPV\nNPV\nSensitivity and specificity of five fold validation data(a)\n(b)\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosacea\nKeloid/Hypertrophic scar\nFixed drug eruption\nHerpes zoster\nVitiligo/Leucoderma\nIchthyosis\nHidradenitis suppurativa\nMelasma\nKeratoacanthoma\n"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2579
    },
    {
      "id": "Q3",
      "question": "To which ICD-10 code group does the digital health application in this study pertain?",
      "answer": "L00-L99",
      "raw_answer": "L00-L99",
      "choices_ids": [
        "A00-B99",
        "C00-D48",
        "D50-D89",
        "E00-E90",
        "F00-F99",
        "G00-G99",
        "H00-H59",
        "I00-I99",
        "J00-J99",
        "K00-K93",
        "L00-L99",
        "M00-M99",
        "N00-N99",
        "O00-O99",
        "P00-P96",
        "Q00-Q99",
        "R00-R99",
        "S00-S99",
        "T00-T98",
        "U00-U99",
        "V01-Y98",
        "Z00-Z99"
      ],
      "answer_label": "L00-L99",
      "chunks_id": [
        16,
        11,
        2
      ],
      "chunks_str": [
        "/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nFigure 4 (a) Confusion matrix from the top-1 prediction of clinical data by the app. The numbers in each row are normalized to 100. The\nactual patient numbers for each disease class are shown in parenthesis. The actual labels are depicted on the y-axis and predicted labels\nare on the x-axis. (b) Confusion matrix from the top-3 prediction of clinical data by the app. The numbers in each row are normalized to\n100. The actual patient numbers for each disease class are shown in parenthesis.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 543\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\nto diagnose 26 common skin conditions from clinical images\nplus associated medical histories.25 During validation, Liuet al\nachieved a 71% top-1 accuracy and their algorithm surpassed\ndermatologists, PCPs and nurse practitioners in a clinical data-\nset.\n25 Our Top-1 accuracy was 77% and the mean AUC was 0.95\nfor algorithmic validation of 40 diseases.\nThere are no precedents for studies in which an AI-based, skin\ndisease diagnosis app has been tested in clinical settings. In our\nwork, a top-1 accuracy of 75% and a top-3 accuracy of 90% was\nachieved by the app for 35 skin diseases and was largely similar to\nour model validation results. Some differences in diagnostic per-\nformance (in terms of disease AUCs) between model and app\nwere noted and may be attributable to either fewer clinical valida-\ntion images for some diseases like Bowen’s disease, anogenital\nwarts, tinea pedis, rosacea, candidiasis, herpes zoster (Fig. 4a and\nSupplementary Figure S1) and/or differences in disease morphol-\nogy between white and pigmented skin. Eczema is a broad disease\ncategory, incorporating diseases with varied morphology such as\nlichen simplex chronicus, atopic dermatitis, nummular eczema\nand contact dermatitis. Training of the model with speciﬁc dis-\nease classes rather than a broad category of eczema may improve\nsensitivity. As shown in the confusion matrix, eczema was often\nconfused with psoriasis, lichen planus and tinea corporis, cruris\nor faciei (Figs 4a, b). To some extent, this mirrors the diagnostic\nconfusion faced by many physicians as well.\n2,25,26 A few melano-\ncytic nevi lesions were mistaken for BCC possibly because of their\nresemblance with pigmented BCC, which is more commonly seen\nin skin of colour. Besides, it was observed that diseases with dis-\ntinct morphology and predilection for certain sites (in a similar\nrecognizable background) such as melasma and tinea unguium\nhad better accuracies.\nIn this study, we found a high top-3 sensitivity for BCC\n(97.58%, n = 124) and SCC (92.86%,n = 14",
        " diversity in the patient populations that\nconsult physicians in urban versus rural areas. The study was\napproved by the Ethics Committee of All India Institute of Med-\nical Sciences. We included consecutive patients presenting to a\nparticular investigator in the Outpatient Department, where the\ndermatologists were conﬁdent of the diagnosis, either by clinical\nexamination, laboratory investigation, and/or histopathological\nexamination. Dermatologists were blinded to the app results. A\nsingle representative image from each patient was tested on the\napp by a separate physician.\nResults\nThe overall scheme for this study is outlined in Figure 1.\nTable 2 shows th number of patients, AUC, Top‐1/Top‐3 sensitivity, speciﬁcity, positive predictive and negative predictive values for\ncombined clinical data from three different clinical settings.\nS.no. Disease class Number\nof patients\nAUC-\nclinic\nTop-1 sensitivity\n% (CI)\nTop-3\nsensitivity %\nTop-1\nspeciﬁcity %\nTop-1 PPV Top-1 NPV\n1 Acne 592 0.98 89.86 (87.15 –92.18) 97.97 98.19 86.92 98.64\n2 Alopecia 184 0.97 88.11 (82.55 –92.36) 96.22 99.28 82.32 99.54\n3 Anogenital warts 34 0.85 57.14 (39.35 –73.68) 71.43 99.70 57.14 99.70\n4 Basal cell carcinoma 123 0.98 93.55 (87.68 –97.17) 97.58 98.51 61.38 99.83\n5 Bowen ’s disease 11 0.77 45.45 (16.75 –76.62) 54.54 99.90 50.00 99.88\n6 Bullous pemphigoid 16 0.73 35.29 (14.21 –61.67) 47.06 100.00 100.00 99.78\n7 Candidiasis 16 0.81 41.18 (18.44 –67.10) 64.71 99.80 41.18 99.80\n8 Discoid lupus\nerythematosus\n47 0.90 60.42 (45.27 –74.23) 83.33 99.20 42.03 99.61\n9 Eczema 432 0.87 54.29 (49.46 –59.10) 81.90 97.58 67.83 95.78\n10 Fixed drug eruption 12 0.87 41.67 (15.16 –72.33) 75.00 99.70 25.00 99.86\n11 Herpes zoster 38 0.89 66.67 (49.78 –80.91) 79.49 99.60 56.52 99.74\n12 Hidradenitis suppurativa 32 0.97 93.94(79.78 –99.26) 93.94 99.62 62.00 99.96\n13 Ichthyosis 21 0.93 81.81 (59.72 –94.81) 86.36 99.78 62.07 99.92\n14 Impetigo and Pyodermas 109 0.89 57.27 (47.48 –66.66) 82.72 99.04 57.27 99.04\n15",
        " validation studies of AI-\nbased algorithms related to dermatology in clinical settings.\nMaterial and methods\nThe study aimed to develop a convolutional neural network\n(CNN)-based algorithm trained with clinical images of 40 differ-\nent skin diseases. A user-friendly, smartphone app was also gen-\nerated, and a clinical validation study on 5014 patients was done\nby physicians in urban, rural primary care and tertiary care set-\ntings. The app’s analysis of a single image of the lesion was com-\npared to the consensus diagnosis made by two board-certiﬁed\ndermatologists. Only patients, for whom the treating board-cer-\ntiﬁed dermatologist was conﬁdent of the diagnosis and the diag-\nnosis was cross-veriﬁed by another board-certiﬁed\ndermatologist, were included. If there was no consensus then the\npatient was excluded from the study.\nGeneration of the CNN-based algorithm\nThe CNN architecture used was a modiﬁed version of Densenet-\n161 with optimized augmentation and inference pipelines.\n16\nThese optimizations were derived through rigorous experiments\nand were attuned to clinical skin images. All training and testing\nimages were annotated and segmented so a bounding box sur-\nrounded lesion of interest and irrelevant features such as rulers\nand surgical markings were discarded. The 17 718 raw images\nwere sourced from public databases (http://www.hellenicderma\ntlas.com/en and http://www.danderm.dk/atlas), after obtaining\npermission from them, as well as images from dermatologists in\nIndia. Of these, 310 images were discarded during the\npreprocessing stage due to poor resolution or multiple lesions.\nOut of the remaining 17 408 images, 1990 images belonged to\nthe non-speciﬁc category and 15 418 images were within the 40\nselected disease categories (Table 1). These images were split\ninto ﬁve equal parts (folds) and ﬁve iterations of training and\nvalidation were performed in a manner so that within each itera-\ntion, a different fold of the data was held-out for validation while\nthe remaining fourfolds were used for learning. The training\nimages were 12 350 and testing images were 3068. Since the\ndataset was imbalanced, a custom modiﬁed version of the\nweighted focal loss function was used to train the network. The\nweights for each class were calculated using the inverse sample\nsize method. Our test images were either in-distribution images\ni.e. images within 40 training classes or out-of-distribution sets\nthat we named as non-speciﬁc set.\nWe initially used Inception-v4, which was one of the most\npopular CNN models at the time. For 10 diseases, a sensitivity of\naround 85% was achieved, but for the 20-disease class model,\nthis fell to around 65%. We experimented with many parameters\nlike learning rate and choice of optimizer etc. with no signiﬁcant\nimprovements. It was felt that as the architectures became dee-\nper, there could be problems related to over-ﬁtting. According\nto Huanget al.,convolutional networks can be substantially dee-\nper, more accurate and efﬁcient to train if they contain shorter\nconnections between layers close to the input and those close to\nthe output.\n17 Their implementation of this architecture is called\nDenseNet. In this architecture, to ensure maximum information\nﬂow between layers, each layer obtains additional inputs from all\npreceding layers and passes on its own feature-maps to all subse-\nquent layers.\n17 We found that the DenseNet architecture pro-\nvided better results than the other contemporary architectures\nsuch as Inception-Resnet-V2, Resnets-50, Resnet-101 and Res-\nnet-152. We tried several DenseNet variants"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2699
    },
    {
      "id": "Q4",
      "question": "Does the predictive model perform regression or classification?",
      "answer": "Classification",
      "raw_answer": "Classification",
      "choices_ids": [
        "Regression",
        "Classification"
      ],
      "answer_label": "Classification",
      "chunks_id": [
        14,
        9,
        0
      ],
      "chunks_str": [
        " of the CNN model for the diagnosis of 40 skin\ndiseases showed a top-1 overall accuracy of 76.93/C6 0.88% and\nAUC of 0.95/C6 0.02 (Table 1). High speciﬁcities and NPV were\nobserved for all disease classes (Table 1, Fig. 2a, and b). The sen-\nsitivities and PPV were more varied but 34/40 skin diseases\nshowed high PPVs in 80–99% range. AUC values and ROC plots\nfor different diseases in model validation and clinical study are\ngiven in Supplementary Figure S1.\nClinical validation\nThe app was tested on 5014 patients (3699 from tertiary care, 383\nfrom urban private practice, and 932 from rural primary care).\nOut of the 5014 patients, 760 patients’ images were in the nonspe-\nciﬁc (out-of-distribution) category. The mean AUC was\n0.90 /C6 0.07, top-1 overall accuracy 75.07% (CI= 73.75–76.36)\nand top-3 accuracy 89.62% (CI = 88.67–90.52) for combined\ndata from all centres (Table 2, Fig. 3a). The mean top-1 speciﬁcity\nwas 99.11% (CI= 99.06–99.15). Small differences were noted in\nthe overall accuracies of urban, rural primary and tertiary hospital\npatients, with the urban practice showing the highest and tertiary\ncare centres showing the lowest accuracy (Fig. 3a). We do not\npresent data for actinic keratosis, chickenpox, keratoacanthoma,\nmelanoma and tinea manuum because of less than 10 patients for\neach of these disease classes. The most signiﬁcant sensitivities were\nobserved for diagnosis of hidradenitis suppurativa, BCC, vitiligo,\nacne, alopecia, molluscum contagiosum, melasma, ichthyosis and\ntinea corporis, cruris or faciei. Bowen’s disease, bullous pem-\nphigoid, candidiasis, ﬁxed drug eruption, eczema, lichen sclero-\nsus, melanocytic naevus, rosacea and tinea pedis had lower\naccuracy across all sites (Figs 3b and 4a and b). The sensitivity of\ndiseases with larger sample sizes was generally greater except for\neczema and melanocytic nevi (Fig. 3b).\nThe top-3 sensitivity of most diseases, including eczema, was\nhigh (Figs 3b and 4b). Analyses of the confusion matrix showed\nthat many eczema lesions were misdiagnosed as psoriasis fol-\nlowed by lichen planus and tinea corporis, cruris or faciei (Fig. 3\na). Most of the skin cancers were detected in top-3 diagnoses as\nshown in the confusion matrix (Fig. 4b).\nDiscussion\nThis cross-sectional study is the ﬁrst, large-scale, clinical valida-\ntion study of an AI-driven app involving a wide spectrum of\ncommon dermatological diseases on the skin of colour. More-\nover, this work shows the potential of an app to be successfully\nincorporated into clinical workﬂows by physicians using ordi-\nnary smartphones.\nNearly all previously published work on automated skin dis-\nease detection has focused onin silico algorithmic validation.\n21\nThere is also little published literature demonstrating high-efﬁ-\nciency neural networks for multi-disease classiﬁcation. AI-based\nalgorithms, particularly CNN, have been successfully applied in\nskin lesion classiﬁcation,",
        " to calculate the true positive rate (same as\nsensitivity) and the false-positive rate (1 – speciﬁcity). ROC\ncurve was the plot of the true positive rate versus the false-\npositive rate.\nClinical validation study\nWe tested our mobile app against dermatologists’ diagnosis in\nthree different clinical settings, namely, at a tertiary care centre\nData \ncollection\nAlgorithm \nfinetuning & \nvalidation\nApp \ndevelopment\nClinical \nvalidation of \nApp\nPublic database of annotated images for \n40 skin diseases + normal skin + nonspecific\nN = 9,203\nPrivate data classified by board certified \ndermatologists\nN = 8,205\nCNN training images N =12,350\nCNN testing images N =3,068\n(1990 nonspecific images not included)\nComparison of model diagnosis against \npredetermined classification\n15,418 images used for training of model to \ngenerate smartphone app\nApp tested by physicians and compared with \ndermatologists’ diagnosis. N = 5,014 \nDetermination of app’s overall sensitivity and \ndisease-specific sensitivity, specificity, PPV, \nNPV and AUC values\nApp testing on rural primary-care patients\nN = 932\nApp testing on urban, private clinic patients\nN = 383\nApp testing on urban tertiary hospital patients\nN = 3,699\nFigure 1 This ﬂowchart depicts the different steps in data collection, algorithm generation, algorithm testing, app generation and app\nvalidation in clinical studies.\n© 2020 European Academy of Dermatology and VenereologyJEADV 2021, 35, 536–545\nAI-based mobile app for dermatology 539\n 14683083, 2021, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/jdv.16967 by Leiden University Libraries, Wiley Online Library on [23/05/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosaceaMelasma\nAcne\nVitiligo/Leucoderma\nTinea pedis\nAnogenital wartsKeratoacanthoma\nMolluscum contagiosumHidradenitis suppurativa\nHerpes zosterTinea capitis\nImpetigo and Pyodermas\nAlopecia\nMilia\nBasal cell carcinoma\nMelanoma\nMelanocytic nevi/Mole\nIchthyosis\nPityriasis r\nosea\nActin\nic keratosis\nTinea cruris  corporis or faciei\nKeloid/Hype\nrtrophic scar\nSeborrheic\n keratosis\nFixed d\nrug eruption\nLichen sclerosus et atrophicus\nCh\nicken pox\nTinea ma\nnuum\nLichen planus\nUrticaria\nPityriasis ve\nrsicolorPsoriasis\nPe\nmphigus\nCandid\niasis\nBowens disease\nViral warts\nSquamous cell c\narcino\nma\nBullous pe\nmphigoidEcze\nma\nDis\ncoid lupus erythematosus\nPercentage\nSensitivity\nSpecificity\nPPV\nNPV\nSensitivity and specificity of five fold validation data(a)\n(b)\n0\n25\n50\n75\n100\nNormal skin\nTinea unguium\nRosacea\nKeloid/Hypertrophic scar\nFixed drug eruption\nHerpes zoster\nVitiligo/Leucoderma\nIchthyosis\nHidradenitis suppurativa\nMelasma\nKeratoacanthoma\n",
        "ORIGINAL ARTICLE\nA machine learning-based, decision support, mobile phone\napplication for diagnosis of common dermatological\ndiseases\nR. Pangti,1 J. Mathur,2 V. Chouhan,2 S. Kumar,2 L. Rajput,1 S. Shah,1 A. Gupta,3 A. Dixit,1\nD. Dholakia,4,5 S. Gupta,6 S. Gupta,1 M. George,7 V.K. Sharma,1 S. Gupta1,*\n1Department of Dermatology and Venereology, All India Institute of Medical Science, New Delhi, India\n2Nurithm Labs Private Limited, Noida, India\n3Skin Aid Clinic, Cross Point Mall, Gurugram, India\n4Genomics and Molecular Medicine Unit, Academy of Scientiﬁc and Innovative Research, New Delhi, India\n5Academy of Scientiﬁc and Innovative Research, Ghaziabad, Uttar Pradesh, India\n6Maharishi Markandeshwar Institute of Medical Sciences and Research, Mullana, Ambala, India\n7Sahrudya Hospital, Alappuzha, India\n*Correspondence: S. Gupta. E-mail: someshgupta@hotmail.com\nAbstract\nBackground The integration of machine learning algorithms in decision support tools for physicians is gaining popular-\nity. These tools can tackle the disparities in healthcare access as the technology can be implemented on smartphones.\nWe present theﬁrst, large-scale study on patients with skin of colour, in which the feasibility of a novel mobile health\napplication (mHealth app) was investigated in actual clinical workﬂows.\nObjective To develop a mHealth app to diagnose 40 common skin diseases and test it in clinical settings.\nMethods A convolutional neural network-based algorithm was trained with clinical images of 40 skin diseases. A\nsmartphone app was generated and validated on 5014 patients, attending rural and urban outpatient dermatology\ndepartments in India. The results of this mHealth app were compared against the dermatologists’ diagnoses.\nResults The machine–learning model, in an in silico validation study, demonstrated an overall top-1 accuracy of\n76.93 /C6 0.88% and mean area-under-curve of 0.95/C6 0.02 on a set of clinical images. In the clinical study, on patients\nwith skin of colour, the app achieved an overall top-1 accuracy of 75.07% (95% CI= 73.75–76.36), top-3 accuracy of\n89.62% (95% CI= 88.67–90.52) and mean area-under-curve of 0.90/C6 0.07.\nConclusion This study underscores the utility of artiﬁcial intelligence-driven smartphone applications as a point-of-\ncare, clinical decision support tool for dermatological diagnosis for a wide spectrum of skin diseases in patients of the\nskin of colour.\nReceived: 11 April 2020; revised: 22 June 2020; Accepted: 5 August 2020\nConﬂict of interests\nJyoti Mathur and Sharad Kumar are direct beneﬁciaries of any proﬁts acquired by the smartphone application developed\nat Nurithm Labs Private Limited and Vikas Chouhan is a salaried employee at Nurithm Labs Private Limited.\nFunding sources\nNone.\nIntroduction\nSkin diseases are the fourth leading cause of non-fatal disease\nburden across 188 countries in both low and high-income coun-\ntries.\n1,2 There is less than one dermatologist per 100 000 people\nin India and less than three dermatologists per 100 000 of the\npopulation in the United States and the ratios are expected to\ndecline further.\n3,4 In a survey by the American Academy of Der-\nmatology, 33%"
      ],
      "sent_transformer": "kamalkraj/BioSimCSE-BioLinkBERT-BASE",
      "LLM": "deepseek/deepseek-chat-v3.1:free",
      "finish_reason": "stop",
      "total_len": 2538
    }
  ]
}